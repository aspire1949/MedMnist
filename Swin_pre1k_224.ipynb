{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1tw1eXZHrl0QNpyRO2LkZsmbboQe2ifqt",
      "authorship_tag": "ABX9TyN1mllyFw2km3u3oLPD5vD0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8b64d420e8f74bb3aeb215e196af9499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_591ae1867ad5496bbc8583c153aa4305",
              "IPY_MODEL_8170f7e6052d4e77bb6916838cef5a2d",
              "IPY_MODEL_6fbd2d60a0d646ca9d5d98e452773c77"
            ],
            "layout": "IPY_MODEL_321826c02b82475b93f84cdf79ecbfb2"
          }
        },
        "591ae1867ad5496bbc8583c153aa4305": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7038b1771aa4bd7a7e8677e499265b8",
            "placeholder": "​",
            "style": "IPY_MODEL_8c18b1c0e16443fa8ec10b6fa7adcafc",
            "value": "100%"
          }
        },
        "8170f7e6052d4e77bb6916838cef5a2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c22ce5a2951547a3a6fdb114be5b6704",
            "max": 19725078,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20e3a2a4581a41bb8384969c213530f8",
            "value": 19725078
          }
        },
        "6fbd2d60a0d646ca9d5d98e452773c77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e0c1ae2773a496abd7490e6f71c5c55",
            "placeholder": "​",
            "style": "IPY_MODEL_a3ebfda28649457b8ea6ba61ac345550",
            "value": " 19725078/19725078 [00:59&lt;00:00, 333840.77it/s]"
          }
        },
        "321826c02b82475b93f84cdf79ecbfb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7038b1771aa4bd7a7e8677e499265b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c18b1c0e16443fa8ec10b6fa7adcafc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c22ce5a2951547a3a6fdb114be5b6704": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20e3a2a4581a41bb8384969c213530f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e0c1ae2773a496abd7490e6f71c5c55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3ebfda28649457b8ea6ba61ac345550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yulinlina/MedMnist/blob/main/Swin_pre1k_224.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7jrRn7MsG7q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00655696-7e1e-4ddd-9c5e-33222a1c1de8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/MedMNIST/MedMNIST.git\n",
            "  Cloning https://github.com/MedMNIST/MedMNIST.git to /tmp/pip-req-build-kojdevan\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/MedMNIST/MedMNIST.git /tmp/pip-req-build-kojdevan\n",
            "  Resolved https://github.com/MedMNIST/MedMNIST.git to commit 16e3ead23ceb3e1c5f7b9b04032c30cea7a4b1d8\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from medmnist==2.1.0) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from medmnist==2.1.0) (1.4.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from medmnist==2.1.0) (1.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.9/dist-packages (from medmnist==2.1.0) (0.19.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from medmnist==2.1.0) (4.65.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from medmnist==2.1.0) (8.4.0)\n",
            "Collecting fire\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from medmnist==2.1.0) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from medmnist==2.1.0) (0.14.1+cu116)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from fire->medmnist==2.1.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.9/dist-packages (from fire->medmnist==2.1.0) (2.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->medmnist==2.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->medmnist==2.1.0) (2022.7.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image->medmnist==2.1.0) (23.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image->medmnist==2.1.0) (2023.3.21)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->medmnist==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->medmnist==2.1.0) (2.25.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image->medmnist==2.1.0) (3.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->medmnist==2.1.0) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->medmnist==2.1.0) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->medmnist==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->medmnist==2.1.0) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision->medmnist==2.1.0) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->medmnist==2.1.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->medmnist==2.1.0) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->medmnist==2.1.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->medmnist==2.1.0) (1.26.15)\n",
            "Building wheels for collected packages: medmnist, fire\n",
            "  Building wheel for medmnist (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for medmnist: filename=medmnist-2.1.0-py3-none-any.whl size=21734 sha256=ea34ddeb5b91e9736e39a132be7ee11ab6f11d7f4b2be572334cffa8901cf7c5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-b5g52yeg/wheels/1f/7d/20/8dfeeb0f22f7ed3a2ffb3c060cdd52e80690526979935b3fc7\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116952 sha256=c70211023c90c535b491ad9226e8f11cb648a858606e03faae4cea03eddb154a\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/f1/89/b9ea2bf8f80ec027a88fef1d354b3816b4d3d29530988972f6\n",
            "Successfully built medmnist fire\n",
            "Installing collected packages: fire, medmnist\n",
            "Successfully installed fire-0.5.0 medmnist-2.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade git+https://github.com/MedMNIST/MedMNIST.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator\n",
        "data_flag = 'dermamnist'\n",
        "# data_flag = 'breastmnist'\n",
        "download = True\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "# preprocessing\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "# load the data\n",
        "train_dataset = DataClass(split='train', transform=data_transform, download=download)\n",
        "test_dataset = DataClass(split='test', transform=data_transform, download=download)\n",
        "\n",
        "pil_dataset = DataClass(split='train', download=download)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "8b64d420e8f74bb3aeb215e196af9499",
            "591ae1867ad5496bbc8583c153aa4305",
            "8170f7e6052d4e77bb6916838cef5a2d",
            "6fbd2d60a0d646ca9d5d98e452773c77",
            "321826c02b82475b93f84cdf79ecbfb2",
            "a7038b1771aa4bd7a7e8677e499265b8",
            "8c18b1c0e16443fa8ec10b6fa7adcafc",
            "c22ce5a2951547a3a6fdb114be5b6704",
            "20e3a2a4581a41bb8384969c213530f8",
            "0e0c1ae2773a496abd7490e6f71c5c55",
            "a3ebfda28649457b8ea6ba61ac345550"
          ]
        },
        "id": "n9X3dxIksSLD",
        "outputId": "e490b4d0-5d55-4c6b-e4fd-2c2d4181f085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://zenodo.org/record/6496656/files/dermamnist.npz?download=1 to /root/.medmnist/dermamnist.npz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/19725078 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b64d420e8f74bb3aeb215e196af9499"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/dermamnist.npz\n",
            "Using downloaded and verified file: /root/.medmnist/dermamnist.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m medmnist save --flag=dermamnist --folder=MedMNIST/ --postfix=jpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKecTpa_sTUl",
        "outputId": "059da5ca-606d-4c6c-cdd3-e4fccb7d8b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dermamnist train...\n",
            "100% 7007/7007 [00:01<00:00, 6080.64it/s]\n",
            "Saving dermamnist val...\n",
            "100% 1003/1003 [00:00<00:00, 6362.33it/s]\n",
            "Saving dermamnist test...\n",
            "100% 2005/2005 [00:00<00:00, 6155.19it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/MedMNIST/dermamnist/\n",
        "%mkdir train val test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKRjN6-AuLjp",
        "outputId": "81f1e7ef-af3e-4299-8f8d-3e5b1935be0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MedMNIST/dermamnist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/MedMNIST/dermamnist/train/\n",
        "%mkdir class1 class2 class3 class4 class5 class6 class7\n",
        "%cd /content/MedMNIST/dermamnist/test/\n",
        "%mkdir class1 class2 class3 class4 class5 class6 class7\n",
        "%cd /content/MedMNIST/dermamnist/val/\n",
        "%mkdir class1 class2 class3 class4 class5 class6 class7\n",
        "%cd /content/MedMNIST/dermamnist/\n",
        "%mv train{0..7006}_0.jpeg /content/MedMNIST/dermamnist/train/class1/\n",
        "%mv train{0..7006}_1.jpeg /content/MedMNIST/dermamnist/train/class2/\n",
        "%mv train{0..7006}_2.jpeg /content/MedMNIST/dermamnist/train/class3/\n",
        "%mv train{0..7006}_3.jpeg /content/MedMNIST/dermamnist/train/class4/\n",
        "%mv train{0..7006}_4.jpeg /content/MedMNIST/dermamnist/train/class5/\n",
        "%mv train{0..7006}_5.jpeg /content/MedMNIST/dermamnist/train/class6/\n",
        "%mv train{0..7006}_6.jpeg /content/MedMNIST/dermamnist/train/class7/\n",
        "%cd /content/MedMNIST/dermamnist/\n",
        "%mv test{0..2004}_0.jpeg /content/MedMNIST/dermamnist/test/class1/\n",
        "%mv test{0..2004}_1.jpeg /content/MedMNIST/dermamnist/test/class2/\n",
        "%mv test{0..2004}_2.jpeg /content/MedMNIST/dermamnist/test/class3/\n",
        "%mv test{0..2004}_3.jpeg /content/MedMNIST/dermamnist/test/class4/\n",
        "%mv test{0..2004}_4.jpeg /content/MedMNIST/dermamnist/test/class5/\n",
        "%mv test{0..2004}_5.jpeg /content/MedMNIST/dermamnist/test/class6/\n",
        "%mv test{0..2004}_6.jpeg /content/MedMNIST/dermamnist/test/class7/\n",
        "%cd /content/MedMNIST/dermamnist/\n",
        "%mv val{0..1002}_0.jpeg /content/MedMNIST/dermamnist/val/class1/\n",
        "%mv val{0..1002}_1.jpeg /content/MedMNIST/dermamnist/val/class2/\n",
        "%mv val{0..1002}_2.jpeg /content/MedMNIST/dermamnist/val/class3/\n",
        "%mv val{0..1002}_3.jpeg /content/MedMNIST/dermamnist/val/class4/\n",
        "%mv val{0..1002}_4.jpeg /content/MedMNIST/dermamnist/val/class5/\n",
        "%mv val{0..1002}_5.jpeg /content/MedMNIST/dermamnist/val/class6/\n",
        "%mv val{0..1002}_6.jpeg /content/MedMNIST/dermamnist/val/class7/"
      ],
      "metadata": {
        "id": "pJdoGd6ssmu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/MedMNIST/dermamnist/\n",
        "%mv val validation\n",
        "%mv test val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4281C8pYByRl",
        "outputId": "47d1b4ee-ac63-47e4-8072-f0c619948255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MedMNIST/dermamnist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/microsoft/Swin-Transformer.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGqnZTpzv5fZ",
        "outputId": "165060e7-471f-4935-9f7e-40019a7d2dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'Swin-Transformer'...\n",
            "remote: Enumerating objects: 387, done.\u001b[K\n",
            "remote: Total 387 (delta 0), reused 0 (delta 0), pack-reused 387\u001b[K\n",
            "Receiving objects: 100% (387/387), 1.05 MiB | 19.26 MiB/s, done.\n",
            "Resolving deltas: 100% (225/225), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm==0.4.12\n",
        "!pip install opencv-python==4.4.0.46 termcolor==1.1.0 yacs==0.1.8 pyyaml scipy"
      ],
      "metadata": {
        "id": "FiVObQY_wDnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Swin-Transformer/kernels/window_process\n",
        "!python setup.py install"
      ],
      "metadata": {
        "id": "GJNIh9HBwHEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a13ae89-abf1-413d-a244-6a0c6b70e951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Swin-Transformer/kernels/window_process\n",
            "running install\n",
            "/usr/local/lib/python3.9/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/setuptools/command/easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
            "  warnings.warn(\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating swin_window_process.egg-info\n",
            "writing swin_window_process.egg-info/PKG-INFO\n",
            "writing dependency_links to swin_window_process.egg-info/dependency_links.txt\n",
            "writing top-level names to swin_window_process.egg-info/top_level.txt\n",
            "writing manifest file 'swin_window_process.egg-info/SOURCES.txt'\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "reading manifest file 'swin_window_process.egg-info/SOURCES.txt'\n",
            "writing manifest file 'swin_window_process.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_ext\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/cpp_extension.py:387: UserWarning: The detected CUDA version (11.8) has a minor version mismatch with the version that was used to compile PyTorch (11.6). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/cpp_extension.py:397: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 11.8\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "building 'swin_window_process' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.9\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c swin_window_process.cpp -o build/temp.linux-x86_64-3.9/swin_window_process.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=swin_window_process -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kswin_window_process.cpp:17\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kswin_window_process.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor roll_and_window_partition_forward(at::Tensor&, int, int, int, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kswin_window_process.cpp:64:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   64 | #define CHECK_CUDA(x) AT_ASSERTM(x.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.is_cuda(), #x \" must be a CUDA tensor\")\n",
            "      |                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/c10/util/Exception.h:264:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  264 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/c10/util/Exception.h:284:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  284 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/c10/util/Exception.h:336:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  336 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/c10/util/Exception.h:631:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  631 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process.cpp:64:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "   64 | #define CHECK_CUDA(x) \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "      |                       \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process.cpp:66:24:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CUDA\u001b[m\u001b[K’\n",
            "   66 | #define CHECK_INPUT(x) \u001b[01;36m\u001b[KCHECK_CUDA\u001b[m\u001b[K(x); CHECK_CONTIGUOUS(x)\n",
            "      |                        \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process.cpp:79:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   79 |     \u001b[01;36m\u001b[KCHECK_INPUT\u001b[m\u001b[K(input);\n",
            "      |     \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kswin_window_process.cpp:17\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kswin_window_process.cpp:17\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kswin_window_process.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor roll_and_window_partition_backward(at::Tensor&, int, int, int, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kswin_window_process.cpp:64:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   64 | #define CHECK_CUDA(x) AT_ASSERTM(x.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.is_cuda(), #x \" must be a CUDA tensor\")\n",
            "      |                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/c10/util/Exception.h:264:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  264 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/c10/util/Exception.h:284:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  284 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/c10/util/Exception.h:336:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  336 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/c10/util/Exception.h:631:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  631 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process.cpp:64:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "   64 | #define CHECK_CUDA(x) \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "      |                       \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process.cpp:66:24:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CUDA\u001b[m\u001b[K’\n",
            "   66 | #define CHECK_INPUT(x) \u001b[01;36m\u001b[KCHECK_CUDA\u001b[m\u001b[K(x); CHECK_CONTIGUOUS(x)\n",
            "      |                        \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process.cpp:93:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "   93 |     \u001b[01;36m\u001b[KCHECK_INPUT\u001b[m\u001b[K(grad_in);\n",
            "      |     \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kswin_window_process.cpp:17\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kswin_window_process.cpp:17\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kswin_window_process.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor window_merge_and_roll_forward(at::Tensor&, int, int, int, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kswin_window_process.cpp:64:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   64 | #define CHECK_CUDA(x) AT_ASSERTM(x.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.is_cuda(), #x \" must be a CUDA tensor\")\n",
            "      |                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/c10/util/Exception.h:264:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  264 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/c10/util/Exception.h:284:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  284 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/c10/util/Exception.h:336:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  336 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/c10/util/Exception.h:631:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  631 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process.cpp:64:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "   64 | #define CHECK_CUDA(x) \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "      |                       \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process.cpp:66:24:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CUDA\u001b[m\u001b[K’\n",
            "   66 | #define CHECK_INPUT(x) \u001b[01;36m\u001b[KCHECK_CUDA\u001b[m\u001b[K(x); CHECK_CONTIGUOUS(x)\n",
            "      |                        \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process.cpp:107:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "  107 |     \u001b[01;36m\u001b[KCHECK_INPUT\u001b[m\u001b[K(input);\n",
            "      |     \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kswin_window_process.cpp:17\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/c10/core/Device.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kswin_window_process.cpp:17\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kswin_window_process.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor window_merge_and_roll_backward(at::Tensor&, int, int, int, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kswin_window_process.cpp:64:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   64 | #define CHECK_CUDA(x) AT_ASSERTM(x.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.is_cuda(), #x \" must be a CUDA tensor\")\n",
            "      |                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/c10/util/Exception.h:264:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
            "  264 | #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
            "      |                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/c10/util/Exception.h:284:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
            "  284 | #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
            "      |                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/c10/util/Exception.h:336:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
            "  336 |   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {                                          \\\n",
            "      |       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/c10/util/Exception.h:631:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
            "  631 |     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__)); \\\n",
            "      |                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process.cpp:64:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
            "   64 | #define CHECK_CUDA(x) \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "      |                       \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process.cpp:66:24:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_CUDA\u001b[m\u001b[K’\n",
            "   66 | #define CHECK_INPUT(x) \u001b[01;36m\u001b[KCHECK_CUDA\u001b[m\u001b[K(x); CHECK_CONTIGUOUS(x)\n",
            "      |                        \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process.cpp:121:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_INPUT\u001b[m\u001b[K’\n",
            "  121 |     \u001b[01;36m\u001b[KCHECK_INPUT\u001b[m\u001b[K(grad_in);\n",
            "      |     \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kswin_window_process.cpp:17\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c swin_window_process_kernel.cu -o build/temp.linux-x86_64-3.9/swin_window_process_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=swin_window_process -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:177:43:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  177 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(in\u001b[01;35m\u001b[Kp\u001b[m\u001b[Kut.type(), \"roll_and_window_partition_forward_cuda_kernel\", ([&] {\n",
            "      |                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:177:190:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  177 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"roll_and_window_partition_forward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:132:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  132 | \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:177:190:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  177 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"roll_and_window_partition_forward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:132:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  132 | \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:177:1011:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  177 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"roll_and_window_partition_forward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:238:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:177:1038:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  177 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"roll_and_window_partition_forward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:238:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:177:1892:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  177 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"roll_and_window_partition_forward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:238:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:177:1918:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  177 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"roll_and_window_partition_forward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:238:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:177:2766:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  177 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"roll_and_window_partition_forward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:238:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:177:2796:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  177 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"roll_and_window_partition_forward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:238:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:221:45:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  221 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(grad\u001b[01;35m\u001b[K_\u001b[m\u001b[Kin.type(), \"roll_and_window_partition_backward_cuda_kernel\", ([&] {\n",
            "      |                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:221:193:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  221 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(grad_in.type(), \"roll_and_window_partition_backward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:132:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  132 | \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:221:193:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  221 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(grad_in.type(), \"roll_and_window_partition_backward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:132:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  132 | \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:221:1017:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  221 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(grad_in.type(), \"roll_and_window_partition_backward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:238:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:221:1046:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  221 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(grad_in.type(), \"roll_and_window_partition_backward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:238:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:221:1903:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  221 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(grad_in.type(), \"roll_and_window_partition_backward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:238:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:221:1931:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  221 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(grad_in.type(), \"roll_and_window_partition_backward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:238:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:221:2782:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  221 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(grad_in.type(), \"roll_and_window_partition_backward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:238:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:221:2814:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  221 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(grad_in.type(), \"roll_and_window_partition_backward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:238:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:267:43:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  267 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(in\u001b[01;35m\u001b[Kp\u001b[m\u001b[Kut.type(), \"window_merge_and_roll_forward_cuda_kernel\", ([&] {\n",
            "      |                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:267:186:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  267 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"window_merge_and_roll_forward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:132:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  132 | \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:267:186:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  267 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"window_merge_and_roll_forward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:132:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  132 | \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:267:1003:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  267 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"window_merge_and_roll_forward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:238:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:267:1030:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  267 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"window_merge_and_roll_forward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:238:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:267:1880:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  267 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"window_merge_and_roll_forward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:238:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:267:1906:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  267 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"window_merge_and_roll_forward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:238:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:267:2750:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  267 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"window_merge_and_roll_forward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:238:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:267:2780:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  267 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"window_merge_and_roll_forward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:238:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:309:45:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  309 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(grad\u001b[01;35m\u001b[K_\u001b[m\u001b[Kin.type(), \"window_merge_and_roll_backward_cuda_kernel\", ([&] {\n",
            "      |                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:216:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  216 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:309:189:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  309 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(grad_in.type(), \"window_merge_and_roll_backward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:132:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  132 | \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:309:189:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  309 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(grad_in.type(), \"window_merge_and_roll_backward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/Dispatch.h:132:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  132 | \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:309:1009:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  309 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(grad_in.type(), \"window_merge_and_roll_backward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:238:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:309:1038:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  309 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(grad_in.type(), \"window_merge_and_roll_backward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:238:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:309:1891:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  309 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(grad_in.type(), \"window_merge_and_roll_backward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:238:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:309:1919:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  309 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(grad_in.type(), \"window_merge_and_roll_backward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:238:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:309:2766:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  309 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(grad_in.type(), \"window_merge_and_roll_backward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:238:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kswin_window_process_kernel.cu:309:2798:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  309 |     AT_DISPATCH_FLOATING_TYPES_AND_HALF(grad_in.type(), \"window_merge_and_roll_backward_cuda_kernel\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/TensorBody.h:238:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  238 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-3.9\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.9/swin_window_process.o build/temp.linux-x86_64-3.9/swin_window_process_kernel.o -L/usr/local/lib/python3.9/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.9/swin_window_process.cpython-39-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.9/swin_window_process.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for swin_window_process.cpython-39-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/swin_window_process.py to swin_window_process.cpython-39.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying swin_window_process.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying swin_window_process.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying swin_window_process.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying swin_window_process.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.swin_window_process.cpython-39: module references __file__\n",
            "creating dist\n",
            "creating 'dist/swin_window_process-0.0.0-py3.9-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing swin_window_process-0.0.0-py3.9-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.9/dist-packages/swin_window_process-0.0.0-py3.9-linux-x86_64.egg\n",
            "Extracting swin_window_process-0.0.0-py3.9-linux-x86_64.egg to /usr/local/lib/python3.9/dist-packages\n",
            "Adding swin-window-process 0.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.9/dist-packages/swin_window_process-0.0.0-py3.9-linux-x86_64.egg\n",
            "Processing dependencies for swin-window-process==0.0.0\n",
            "Finished processing dependencies for swin-window-process==0.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P /content/Swin-Transformer https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window7_224.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bptB0k93w0bd",
        "outputId": "dfd94f43-5598-44ce-9b3c-49a03b00f256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-27 06:39:40--  https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window7_224.pth\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/357198522/01c51f80-9bd4-11eb-9134-11b858136ccc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230327%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230327T063758Z&X-Amz-Expires=300&X-Amz-Signature=ec43cc1c37bd5609167a279f9198b345ad3a3b295cf30502d7a7893741dc135c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=357198522&response-content-disposition=attachment%3B%20filename%3Dswin_base_patch4_window7_224.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-03-27 06:39:40--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/357198522/01c51f80-9bd4-11eb-9134-11b858136ccc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230327%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230327T063758Z&X-Amz-Expires=300&X-Amz-Signature=ec43cc1c37bd5609167a279f9198b345ad3a3b295cf30502d7a7893741dc135c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=357198522&response-content-disposition=attachment%3B%20filename%3Dswin_base_patch4_window7_224.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 352792251 (336M) [application/octet-stream]\n",
            "Saving to: ‘/content/Swin-Transformer/swin_base_patch4_window7_224.pth’\n",
            "\n",
            "swin_base_patch4_wi 100%[===================>] 336.45M   347MB/s    in 1.0s    \n",
            "\n",
            "2023-03-27 06:39:41 (347 MB/s) - ‘/content/Swin-Transformer/swin_base_patch4_window7_224.pth’ saved [352792251/352792251]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Swin-Transformer\n",
        "!python -m torch.distributed.launch --nproc_per_node 1 --master_port 12345  main.py \\\n",
        "--cfg configs/swin/swin_base_patch4_window7_224.yaml --data-path /content/MedMNIST/dermamnist --batch-size 64 --accumulation-steps 2 --pretrained swin_base_patch4_window7_224.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8_SIeQkwT-j",
        "outputId": "aeff53fa-f7e7-49bc-ce18-be5650d1be3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Swin-Transformer\n",
            "/usr/local/lib/python3.9/dist-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use_env is set by default in torchrun.\n",
            "If your script expects `--local_rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  warnings.warn(\n",
            "Tutel has not been installed. To use Swin-MoE, please install Tutel; otherwise, just ignore this.\n",
            "To use FusedLAMB or FusedAdam, please install apex.\n",
            "=> merge config from configs/swin/swin_base_patch4_window7_224.yaml\n",
            "RANK and WORLD_SIZE in environ: 0/1\n",
            "\u001b[32m[2023-03-27 06:40:26 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 342)\u001b[0m: INFO Full config saved to output/swin_base_patch4_window7_224/default/config.json\n",
            "\u001b[32m[2023-03-27 06:40:26 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 345)\u001b[0m: INFO AMP_ENABLE: true\n",
            "AMP_OPT_LEVEL: ''\n",
            "AUG:\n",
            "  AUTO_AUGMENT: rand-m9-mstd0.5-inc1\n",
            "  COLOR_JITTER: 0.4\n",
            "  CUTMIX: 1.0\n",
            "  CUTMIX_MINMAX: null\n",
            "  MIXUP: 0.8\n",
            "  MIXUP_MODE: batch\n",
            "  MIXUP_PROB: 1.0\n",
            "  MIXUP_SWITCH_PROB: 0.5\n",
            "  RECOUNT: 1\n",
            "  REMODE: pixel\n",
            "  REPROB: 0.25\n",
            "BASE:\n",
            "- ''\n",
            "DATA:\n",
            "  BATCH_SIZE: 64\n",
            "  CACHE_MODE: part\n",
            "  DATASET: imagenet\n",
            "  DATA_PATH: /content/MedMNIST/dermamnist\n",
            "  IMG_SIZE: 224\n",
            "  INTERPOLATION: bicubic\n",
            "  MASK_PATCH_SIZE: 32\n",
            "  MASK_RATIO: 0.6\n",
            "  NUM_WORKERS: 8\n",
            "  PIN_MEMORY: true\n",
            "  ZIP_MODE: false\n",
            "ENABLE_AMP: false\n",
            "EVAL_MODE: false\n",
            "FUSED_LAYERNORM: false\n",
            "FUSED_WINDOW_PROCESS: false\n",
            "LOCAL_RANK: 0\n",
            "MODEL:\n",
            "  DROP_PATH_RATE: 0.5\n",
            "  DROP_RATE: 0.0\n",
            "  LABEL_SMOOTHING: 0.1\n",
            "  NAME: swin_base_patch4_window7_224\n",
            "  NUM_CLASSES: 1000\n",
            "  PRETRAINED: swin_base_patch4_window7_224.pth\n",
            "  RESUME: ''\n",
            "  SIMMIM:\n",
            "    NORM_TARGET:\n",
            "      ENABLE: false\n",
            "      PATCH_SIZE: 47\n",
            "  SWIN:\n",
            "    APE: false\n",
            "    DEPTHS:\n",
            "    - 2\n",
            "    - 2\n",
            "    - 18\n",
            "    - 2\n",
            "    EMBED_DIM: 128\n",
            "    IN_CHANS: 3\n",
            "    MLP_RATIO: 4.0\n",
            "    NUM_HEADS:\n",
            "    - 4\n",
            "    - 8\n",
            "    - 16\n",
            "    - 32\n",
            "    PATCH_NORM: true\n",
            "    PATCH_SIZE: 4\n",
            "    QKV_BIAS: true\n",
            "    QK_SCALE: null\n",
            "    WINDOW_SIZE: 7\n",
            "  SWINV2:\n",
            "    APE: false\n",
            "    DEPTHS:\n",
            "    - 2\n",
            "    - 2\n",
            "    - 6\n",
            "    - 2\n",
            "    EMBED_DIM: 96\n",
            "    IN_CHANS: 3\n",
            "    MLP_RATIO: 4.0\n",
            "    NUM_HEADS:\n",
            "    - 3\n",
            "    - 6\n",
            "    - 12\n",
            "    - 24\n",
            "    PATCH_NORM: true\n",
            "    PATCH_SIZE: 4\n",
            "    PRETRAINED_WINDOW_SIZES:\n",
            "    - 0\n",
            "    - 0\n",
            "    - 0\n",
            "    - 0\n",
            "    QKV_BIAS: true\n",
            "    WINDOW_SIZE: 7\n",
            "  SWIN_MLP:\n",
            "    APE: false\n",
            "    DEPTHS:\n",
            "    - 2\n",
            "    - 2\n",
            "    - 6\n",
            "    - 2\n",
            "    EMBED_DIM: 96\n",
            "    IN_CHANS: 3\n",
            "    MLP_RATIO: 4.0\n",
            "    NUM_HEADS:\n",
            "    - 3\n",
            "    - 6\n",
            "    - 12\n",
            "    - 24\n",
            "    PATCH_NORM: true\n",
            "    PATCH_SIZE: 4\n",
            "    WINDOW_SIZE: 7\n",
            "  SWIN_MOE:\n",
            "    APE: false\n",
            "    AUX_LOSS_WEIGHT: 0.01\n",
            "    CAPACITY_FACTOR: 1.25\n",
            "    COSINE_ROUTER: false\n",
            "    COSINE_ROUTER_DIM: 256\n",
            "    COSINE_ROUTER_INIT_T: 0.5\n",
            "    DEPTHS:\n",
            "    - 2\n",
            "    - 2\n",
            "    - 6\n",
            "    - 2\n",
            "    EMBED_DIM: 96\n",
            "    GATE_NOISE: 1.0\n",
            "    INIT_STD: 0.02\n",
            "    IN_CHANS: 3\n",
            "    IS_GSHARD_LOSS: false\n",
            "    MLP_FC2_BIAS: true\n",
            "    MLP_RATIO: 4.0\n",
            "    MOE_BLOCKS:\n",
            "    - - -1\n",
            "    - - -1\n",
            "    - - -1\n",
            "    - - -1\n",
            "    MOE_DROP: 0.0\n",
            "    NORMALIZE_GATE: false\n",
            "    NUM_HEADS:\n",
            "    - 3\n",
            "    - 6\n",
            "    - 12\n",
            "    - 24\n",
            "    NUM_LOCAL_EXPERTS: 1\n",
            "    PATCH_NORM: true\n",
            "    PATCH_SIZE: 4\n",
            "    PRETRAINED_WINDOW_SIZES:\n",
            "    - 0\n",
            "    - 0\n",
            "    - 0\n",
            "    - 0\n",
            "    QKV_BIAS: true\n",
            "    QK_SCALE: null\n",
            "    TOP_VALUE: 1\n",
            "    USE_BPR: true\n",
            "    WINDOW_SIZE: 7\n",
            "  TYPE: swin\n",
            "OUTPUT: output/swin_base_patch4_window7_224/default\n",
            "PRINT_FREQ: 10\n",
            "SAVE_FREQ: 1\n",
            "SEED: 0\n",
            "TAG: default\n",
            "TEST:\n",
            "  CROP: true\n",
            "  SEQUENTIAL: false\n",
            "  SHUFFLE: false\n",
            "THROUGHPUT_MODE: false\n",
            "TRAIN:\n",
            "  ACCUMULATION_STEPS: 2\n",
            "  AUTO_RESUME: true\n",
            "  BASE_LR: 0.000125\n",
            "  CLIP_GRAD: 5.0\n",
            "  EPOCHS: 300\n",
            "  LAYER_DECAY: 1.0\n",
            "  LR_SCHEDULER:\n",
            "    DECAY_EPOCHS: 30\n",
            "    DECAY_RATE: 0.1\n",
            "    GAMMA: 0.1\n",
            "    MULTISTEPS: []\n",
            "    NAME: cosine\n",
            "    WARMUP_PREFIX: true\n",
            "  MIN_LR: 1.25e-06\n",
            "  MOE:\n",
            "    SAVE_MASTER: false\n",
            "  OPTIMIZER:\n",
            "    BETAS:\n",
            "    - 0.9\n",
            "    - 0.999\n",
            "    EPS: 1.0e-08\n",
            "    MOMENTUM: 0.9\n",
            "    NAME: adamw\n",
            "  START_EPOCH: 0\n",
            "  USE_CHECKPOINT: false\n",
            "  WARMUP_EPOCHS: 20\n",
            "  WARMUP_LR: 1.25e-07\n",
            "  WEIGHT_DECAY: 0.05\n",
            "\n",
            "\u001b[32m[2023-03-27 06:40:26 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 346)\u001b[0m: INFO {\"cfg\": \"configs/swin/swin_base_patch4_window7_224.yaml\", \"opts\": null, \"batch_size\": 64, \"data_path\": \"/content/MedMNIST/dermamnist\", \"zip\": false, \"cache_mode\": \"part\", \"pretrained\": \"swin_base_patch4_window7_224.pth\", \"resume\": null, \"accumulation_steps\": 2, \"use_checkpoint\": false, \"disable_amp\": false, \"amp_opt_level\": null, \"output\": \"output\", \"tag\": null, \"eval\": false, \"throughput\": false, \"local_rank\": 0, \"fused_window_process\": false, \"fused_layernorm\": false, \"optim\": null}\n",
            "local rank 0 / global rank 0 successfully build train dataset\n",
            "local rank 0 / global rank 0 successfully build val dataset\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\u001b[32m[2023-03-27 06:40:26 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 87)\u001b[0m: INFO Creating model:swin/swin_base_patch4_window7_224\n",
            "/usr/local/lib/python3.9/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\u001b[32m[2023-03-27 06:40:28 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 89)\u001b[0m: INFO SwinTransformer(\n",
            "  (patch_embed): PatchEmbed(\n",
            "    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
            "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
            "  (layers): ModuleList(\n",
            "    (0): BasicLayer(\n",
            "      dim=128, input_resolution=(56, 56), depth=2\n",
            "      (blocks): ModuleList(\n",
            "        (0): SwinTransformerBlock(\n",
            "          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=0, mlp_ratio=4.0\n",
            "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            dim=128, window_size=(7, 7), num_heads=4\n",
            "            (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): Identity()\n",
            "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): SwinTransformerBlock(\n",
            "          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=3, mlp_ratio=4.0\n",
            "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            dim=128, window_size=(7, 7), num_heads=4\n",
            "            (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (downsample): PatchMerging(\n",
            "        input_resolution=(56, 56), dim=128\n",
            "        (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
            "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicLayer(\n",
            "      dim=256, input_resolution=(28, 28), depth=2\n",
            "      (blocks): ModuleList(\n",
            "        (0): SwinTransformerBlock(\n",
            "          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=0, mlp_ratio=4.0\n",
            "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            dim=256, window_size=(7, 7), num_heads=8\n",
            "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): SwinTransformerBlock(\n",
            "          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=3, mlp_ratio=4.0\n",
            "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            dim=256, window_size=(7, 7), num_heads=8\n",
            "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (downsample): PatchMerging(\n",
            "        input_resolution=(28, 28), dim=256\n",
            "        (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
            "        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (2): BasicLayer(\n",
            "      dim=512, input_resolution=(14, 14), depth=18\n",
            "      (blocks): ModuleList(\n",
            "        (0): SwinTransformerBlock(\n",
            "          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            dim=512, window_size=(7, 7), num_heads=16\n",
            "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): SwinTransformerBlock(\n",
            "          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            dim=512, window_size=(7, 7), num_heads=16\n",
            "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): SwinTransformerBlock(\n",
            "          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            dim=512, window_size=(7, 7), num_heads=16\n",
            "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): SwinTransformerBlock(\n",
            "          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            dim=512, window_size=(7, 7), num_heads=16\n",
            "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): SwinTransformerBlock(\n",
            "          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            dim=512, window_size=(7, 7), num_heads=16\n",
            "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): SwinTransformerBlock(\n",
            "          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            dim=512, window_size=(7, 7), num_heads=16\n",
            "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): SwinTransformerBlock(\n",
            "          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            dim=512, window_size=(7, 7), num_heads=16\n",
            "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): SwinTransformerBlock(\n",
            "          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            dim=512, window_size=(7, 7), num_heads=16\n",
            "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): SwinTransformerBlock(\n",
            "          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            dim=512, window_size=(7, 7), num_heads=16\n",
            "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): SwinTransformerBlock(\n",
            "          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            dim=512, window_size=(7, 7), num_heads=16\n",
            "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): SwinTransformerBlock(\n",
            "          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            dim=512, window_size=(7, 7), num_heads=16\n",
            "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): SwinTransformerBlock(\n",
            "          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            dim=512, window_size=(7, 7), num_heads=16\n",
            "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (12): SwinTransformerBlock(\n",
            "          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            dim=512, window_size=(7, 7), num_heads=16\n",
            "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (13): SwinTransformerBlock(\n",
            "          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            dim=512, window_size=(7, 7), num_heads=16\n",
            "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (14): SwinTransformerBlock(\n",
            "          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            dim=512, window_size=(7, 7), num_heads=16\n",
            "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (15): SwinTransformerBlock(\n",
            "          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            dim=512, window_size=(7, 7), num_heads=16\n",
            "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (16): SwinTransformerBlock(\n",
            "          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            dim=512, window_size=(7, 7), num_heads=16\n",
            "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (17): SwinTransformerBlock(\n",
            "          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            dim=512, window_size=(7, 7), num_heads=16\n",
            "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (downsample): PatchMerging(\n",
            "        input_resolution=(14, 14), dim=512\n",
            "        (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
            "        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (3): BasicLayer(\n",
            "      dim=1024, input_resolution=(7, 7), depth=2\n",
            "      (blocks): ModuleList(\n",
            "        (0): SwinTransformerBlock(\n",
            "          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0\n",
            "          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            dim=1024, window_size=(7, 7), num_heads=32\n",
            "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): SwinTransformerBlock(\n",
            "          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0\n",
            "          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            dim=1024, window_size=(7, 7), num_heads=32\n",
            "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path): DropPath()\n",
            "          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
            "  (head): Linear(in_features=1024, out_features=1000, bias=True)\n",
            ")\n",
            "\u001b[32m[2023-03-27 06:40:28 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 92)\u001b[0m: INFO number of params: 87768224\n",
            "\u001b[32m[2023-03-27 06:40:28 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 95)\u001b[0m: INFO number of GFLOPs: 15.438473216\n",
            "All checkpoints founded in output/swin_base_patch4_window7_224/default: []\n",
            "\u001b[32m[2023-03-27 06:40:29 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 129)\u001b[0m: INFO no checkpoint found in output/swin_base_patch4_window7_224/default, ignoring auto resume\n",
            "\u001b[32m[2023-03-27 06:40:29 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 42)\u001b[0m: INFO ==============> Loading weight swin_base_patch4_window7_224.pth for fine-tuning......\n",
            "\u001b[32m[2023-03-27 06:40:29 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 123)\u001b[0m: WARNING _IncompatibleKeys(missing_keys=['layers.0.blocks.0.attn.relative_position_index', 'layers.0.blocks.1.attn_mask', 'layers.0.blocks.1.attn.relative_position_index', 'layers.1.blocks.0.attn.relative_position_index', 'layers.1.blocks.1.attn_mask', 'layers.1.blocks.1.attn.relative_position_index', 'layers.2.blocks.0.attn.relative_position_index', 'layers.2.blocks.1.attn_mask', 'layers.2.blocks.1.attn.relative_position_index', 'layers.2.blocks.2.attn.relative_position_index', 'layers.2.blocks.3.attn_mask', 'layers.2.blocks.3.attn.relative_position_index', 'layers.2.blocks.4.attn.relative_position_index', 'layers.2.blocks.5.attn_mask', 'layers.2.blocks.5.attn.relative_position_index', 'layers.2.blocks.6.attn.relative_position_index', 'layers.2.blocks.7.attn_mask', 'layers.2.blocks.7.attn.relative_position_index', 'layers.2.blocks.8.attn.relative_position_index', 'layers.2.blocks.9.attn_mask', 'layers.2.blocks.9.attn.relative_position_index', 'layers.2.blocks.10.attn.relative_position_index', 'layers.2.blocks.11.attn_mask', 'layers.2.blocks.11.attn.relative_position_index', 'layers.2.blocks.12.attn.relative_position_index', 'layers.2.blocks.13.attn_mask', 'layers.2.blocks.13.attn.relative_position_index', 'layers.2.blocks.14.attn.relative_position_index', 'layers.2.blocks.15.attn_mask', 'layers.2.blocks.15.attn.relative_position_index', 'layers.2.blocks.16.attn.relative_position_index', 'layers.2.blocks.17.attn_mask', 'layers.2.blocks.17.attn.relative_position_index', 'layers.3.blocks.0.attn.relative_position_index', 'layers.3.blocks.1.attn.relative_position_index'], unexpected_keys=[])\n",
            "\u001b[32m[2023-03-27 06:40:29 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 125)\u001b[0m: INFO => loaded successfully 'swin_base_patch4_window7_224.pth'\n",
            "\u001b[32m[2023-03-27 06:40:40 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 10.658 (10.658)\tLoss 8.4062 (8.4062)\tAcc@1 0.000 (0.000)\tAcc@5 0.000 (0.000)\tMem 1725MB\n",
            "\u001b[32m[2023-03-27 06:40:43 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.291 (1.237)\tLoss 5.8242 (8.1832)\tAcc@1 0.000 (0.000)\tAcc@5 4.688 (0.426)\tMem 1726MB\n",
            "\u001b[32m[2023-03-27 06:40:46 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.292 (0.789)\tLoss 5.7266 (7.0327)\tAcc@1 0.000 (0.000)\tAcc@5 4.688 (2.232)\tMem 1726MB\n",
            "\u001b[32m[2023-03-27 06:40:49 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.292 (0.630)\tLoss 6.1445 (6.6541)\tAcc@1 0.000 (0.000)\tAcc@5 6.250 (3.427)\tMem 1726MB\n",
            "\u001b[32m[2023-03-27 06:40:49 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 0.000 Acc@5 3.392\n",
            "\u001b[32m[2023-03-27 06:40:49 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 141)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 0.0%\n",
            "\u001b[32m[2023-03-27 06:40:49 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 147)\u001b[0m: INFO Start training\n",
            "\u001b[32m[2023-03-27 06:40:53 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [0/300][0/109]\teta 0:07:41 lr 0.000000\t wd 0.0500\ttime 4.2317 (4.2317)\tloss 3.3868 (3.3868)\tgrad_norm 0.0000 (0.0000)\tloss_scale 65536.0000 (65536.0000)\tmem 9978MB\n",
            "\u001b[32m[2023-03-27 06:41:02 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [0/300][10/109]\teta 0:01:55 lr 0.000001\t wd 0.0500\ttime 0.8408 (1.1713)\tloss 3.4332 (3.3749)\tgrad_norm inf (inf)\tloss_scale 16384.0000 (32768.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:41:11 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [0/300][20/109]\teta 0:01:31 lr 0.000001\t wd 0.0500\ttime 0.8556 (1.0311)\tloss 3.3555 (3.3757)\tgrad_norm 23.8924 (inf)\tloss_scale 16384.0000 (24966.0952)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:41:20 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [0/300][30/109]\teta 0:01:17 lr 0.000002\t wd 0.0500\ttime 0.8578 (0.9845)\tloss 3.2397 (3.3186)\tgrad_norm 28.5589 (inf)\tloss_scale 16384.0000 (22197.6774)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:41:28 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [0/300][40/109]\teta 0:01:06 lr 0.000002\t wd 0.0500\ttime 0.8623 (0.9620)\tloss 2.9288 (3.2412)\tgrad_norm 25.4807 (inf)\tloss_scale 16384.0000 (20779.7073)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:41:37 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [0/300][50/109]\teta 0:00:56 lr 0.000003\t wd 0.0500\ttime 0.8745 (0.9499)\tloss 2.4863 (3.1514)\tgrad_norm 30.1651 (inf)\tloss_scale 16384.0000 (19917.8039)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:41:47 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [0/300][60/109]\teta 0:00:46 lr 0.000003\t wd 0.0500\ttime 0.8865 (0.9444)\tloss 2.3601 (3.0296)\tgrad_norm 30.7217 (inf)\tloss_scale 16384.0000 (19338.4918)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:41:56 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [0/300][70/109]\teta 0:00:36 lr 0.000004\t wd 0.0500\ttime 0.8960 (0.9411)\tloss 1.8794 (2.8912)\tgrad_norm 21.3184 (inf)\tloss_scale 16384.0000 (18922.3662)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:42:05 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [0/300][80/109]\teta 0:00:27 lr 0.000005\t wd 0.0500\ttime 0.9023 (0.9401)\tloss 1.8947 (2.7467)\tgrad_norm 23.4352 (inf)\tloss_scale 16384.0000 (18608.9877)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:42:15 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [0/300][90/109]\teta 0:00:17 lr 0.000005\t wd 0.0500\ttime 0.9210 (0.9404)\tloss 1.5418 (2.6109)\tgrad_norm 10.3776 (inf)\tloss_scale 16384.0000 (18364.4835)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:42:24 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [0/300][100/109]\teta 0:00:08 lr 0.000006\t wd 0.0500\ttime 0.9289 (0.9417)\tloss 1.2796 (2.4979)\tgrad_norm 8.4335 (inf)\tloss_scale 16384.0000 (18168.3960)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:42:32 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 0 training takes 0:01:42\n",
            "\u001b[32m[2023-03-27 06:42:32 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_0.pth saving......\n",
            "\u001b[32m[2023-03-27 06:42:36 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_0.pth saved !!!\n",
            "\u001b[32m[2023-03-27 06:42:37 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 1.427 (1.427)\tLoss 8.1094 (8.1094)\tAcc@1 0.000 (0.000)\tAcc@5 0.000 (0.000)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:42:41 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.332 (0.506)\tLoss 0.2878 (5.2176)\tAcc@1 100.000 (9.801)\tAcc@5 100.000 (43.466)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:42:45 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.329 (0.423)\tLoss 0.2817 (2.8849)\tAcc@1 100.000 (52.083)\tAcc@5 100.000 (70.387)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:42:48 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.328 (0.393)\tLoss 0.8496 (2.0776)\tAcc@1 87.500 (66.583)\tAcc@5 90.625 (79.637)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:42:48 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 65.885 Acc@5 79.401\n",
            "\u001b[32m[2023-03-27 06:42:48 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 65.9%\n",
            "\u001b[32m[2023-03-27 06:42:48 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 65.89%\n",
            "\u001b[32m[2023-03-27 06:42:52 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [1/300][0/109]\teta 0:05:58 lr 0.000006\t wd 0.0500\ttime 3.2850 (3.2850)\tloss 1.3428 (1.3428)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:43:01 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [1/300][10/109]\teta 0:01:56 lr 0.000007\t wd 0.0500\ttime 0.9192 (1.1734)\tloss 1.6097 (1.3655)\tgrad_norm 9.3124 (10.2617)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:43:11 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [1/300][20/109]\teta 0:01:34 lr 0.000008\t wd 0.0500\ttime 0.9191 (1.0651)\tloss 1.2550 (1.3310)\tgrad_norm 8.2814 (10.3814)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:43:20 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [1/300][30/109]\teta 0:01:21 lr 0.000008\t wd 0.0500\ttime 0.9194 (1.0275)\tloss 1.2869 (1.2960)\tgrad_norm 8.7198 (9.4312)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:43:30 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [1/300][40/109]\teta 0:01:09 lr 0.000009\t wd 0.0500\ttime 0.9232 (1.0084)\tloss 1.3084 (1.2681)\tgrad_norm 9.2079 (8.8787)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:43:39 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [1/300][50/109]\teta 0:00:58 lr 0.000009\t wd 0.0500\ttime 0.9147 (0.9961)\tloss 1.1136 (1.2465)\tgrad_norm 7.0310 (8.5113)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:43:49 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [1/300][60/109]\teta 0:00:48 lr 0.000010\t wd 0.0500\ttime 0.9197 (0.9885)\tloss 0.9817 (1.2288)\tgrad_norm 6.2152 (8.4133)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:43:58 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [1/300][70/109]\teta 0:00:38 lr 0.000010\t wd 0.0500\ttime 0.9212 (0.9828)\tloss 1.1339 (1.2115)\tgrad_norm 9.9279 (8.4816)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:44:08 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [1/300][80/109]\teta 0:00:28 lr 0.000011\t wd 0.0500\ttime 0.9182 (0.9784)\tloss 1.1007 (1.2016)\tgrad_norm 6.2726 (8.3229)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:44:17 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [1/300][90/109]\teta 0:00:18 lr 0.000012\t wd 0.0500\ttime 0.9200 (0.9753)\tloss 1.1120 (1.1903)\tgrad_norm 6.7521 (8.4907)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:44:27 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [1/300][100/109]\teta 0:00:08 lr 0.000012\t wd 0.0500\ttime 0.9185 (0.9725)\tloss 1.0703 (1.1754)\tgrad_norm 6.0201 (8.2861)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:44:34 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 1 training takes 0:01:45\n",
            "\u001b[32m[2023-03-27 06:44:34 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_1.pth saving......\n",
            "\u001b[32m[2023-03-27 06:44:38 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_1.pth saved !!!\n",
            "\u001b[32m[2023-03-27 06:44:40 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 2.257 (2.257)\tLoss 2.5527 (2.5527)\tAcc@1 0.000 (0.000)\tAcc@5 96.875 (96.875)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:44:44 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.341 (0.551)\tLoss 0.3982 (2.2487)\tAcc@1 100.000 (13.636)\tAcc@5 100.000 (95.881)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:44:47 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.329 (0.445)\tLoss 0.3945 (1.3652)\tAcc@1 100.000 (54.539)\tAcc@5 100.000 (97.842)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:44:51 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.329 (0.407)\tLoss 0.8887 (1.0726)\tAcc@1 87.500 (68.599)\tAcc@5 93.750 (98.337)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:44:51 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 67.880 Acc@5 97.905\n",
            "\u001b[32m[2023-03-27 06:44:51 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 67.9%\n",
            "\u001b[32m[2023-03-27 06:44:51 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 67.88%\n",
            "\u001b[32m[2023-03-27 06:44:54 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [2/300][0/109]\teta 0:05:39 lr 0.000013\t wd 0.0500\ttime 3.1124 (3.1124)\tloss 1.1466 (1.1466)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:45:04 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [2/300][10/109]\teta 0:01:55 lr 0.000013\t wd 0.0500\ttime 0.9243 (1.1633)\tloss 1.1072 (1.0606)\tgrad_norm 5.5320 (8.9973)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:45:13 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [2/300][20/109]\teta 0:01:34 lr 0.000014\t wd 0.0500\ttime 0.9282 (1.0636)\tloss 1.0173 (1.0520)\tgrad_norm 8.6727 (7.7785)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:45:23 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [2/300][30/109]\teta 0:01:21 lr 0.000014\t wd 0.0500\ttime 0.9245 (1.0286)\tloss 1.0782 (1.0454)\tgrad_norm 4.5662 (7.0576)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:45:32 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [2/300][40/109]\teta 0:01:09 lr 0.000015\t wd 0.0500\ttime 0.9247 (1.0109)\tloss 1.0502 (1.0391)\tgrad_norm 9.0433 (6.7239)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:45:42 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [2/300][50/109]\teta 0:00:58 lr 0.000016\t wd 0.0500\ttime 0.9240 (0.9993)\tloss 0.9882 (1.0292)\tgrad_norm 7.1876 (6.4743)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:45:51 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [2/300][60/109]\teta 0:00:48 lr 0.000016\t wd 0.0500\ttime 0.9172 (0.9905)\tloss 1.1468 (1.0278)\tgrad_norm 4.3934 (6.1932)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:46:01 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [2/300][70/109]\teta 0:00:38 lr 0.000017\t wd 0.0500\ttime 0.9175 (0.9841)\tloss 0.9841 (1.0245)\tgrad_norm 3.5704 (6.0741)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:46:10 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [2/300][80/109]\teta 0:00:28 lr 0.000017\t wd 0.0500\ttime 0.9191 (0.9790)\tloss 0.9836 (1.0179)\tgrad_norm 5.4563 (5.9973)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:46:20 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [2/300][90/109]\teta 0:00:18 lr 0.000018\t wd 0.0500\ttime 0.9159 (0.9754)\tloss 1.0578 (1.0156)\tgrad_norm 4.8351 (5.8472)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:46:29 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [2/300][100/109]\teta 0:00:08 lr 0.000018\t wd 0.0500\ttime 0.9201 (0.9725)\tloss 0.9760 (1.0157)\tgrad_norm 4.9737 (5.9191)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:46:37 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 2 training takes 0:01:45\n",
            "\u001b[32m[2023-03-27 06:46:37 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_2.pth saving......\n",
            "\u001b[32m[2023-03-27 06:46:41 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_2.pth saved !!!\n",
            "\u001b[32m[2023-03-27 06:46:44 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 2.797 (2.797)\tLoss 2.7363 (2.7363)\tAcc@1 0.000 (0.000)\tAcc@5 95.312 (95.312)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:46:47 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.326 (0.552)\tLoss 0.2224 (2.4350)\tAcc@1 100.000 (10.511)\tAcc@5 100.000 (96.307)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:46:50 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.325 (0.444)\tLoss 0.2197 (1.3745)\tAcc@1 100.000 (53.125)\tAcc@5 100.000 (98.065)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:46:53 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.327 (0.407)\tLoss 0.6807 (1.0175)\tAcc@1 87.500 (67.843)\tAcc@5 98.438 (98.639)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:46:54 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 67.132 Acc@5 98.404\n",
            "\u001b[32m[2023-03-27 06:46:54 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 67.1%\n",
            "\u001b[32m[2023-03-27 06:46:54 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 67.88%\n",
            "\u001b[32m[2023-03-27 06:46:58 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [3/300][0/109]\teta 0:07:43 lr 0.000019\t wd 0.0500\ttime 4.2558 (4.2558)\tloss 1.0776 (1.0776)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:47:08 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [3/300][10/109]\teta 0:02:03 lr 0.000020\t wd 0.0500\ttime 0.9249 (1.2523)\tloss 1.0433 (1.0033)\tgrad_norm 3.9837 (4.8665)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:47:17 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [3/300][20/109]\teta 0:01:38 lr 0.000020\t wd 0.0500\ttime 0.9261 (1.1108)\tloss 0.9701 (1.0015)\tgrad_norm 3.8467 (4.6704)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:47:27 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [3/300][30/109]\teta 0:01:23 lr 0.000021\t wd 0.0500\ttime 0.9249 (1.0610)\tloss 0.9936 (0.9978)\tgrad_norm 7.0514 (4.8436)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:47:36 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [3/300][40/109]\teta 0:01:11 lr 0.000021\t wd 0.0500\ttime 0.9236 (1.0344)\tloss 1.0329 (0.9974)\tgrad_norm 2.9909 (4.6177)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:47:46 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [3/300][50/109]\teta 0:01:00 lr 0.000022\t wd 0.0500\ttime 0.9176 (1.0179)\tloss 0.9493 (0.9948)\tgrad_norm 3.1325 (4.4880)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:47:55 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [3/300][60/109]\teta 0:00:49 lr 0.000022\t wd 0.0500\ttime 0.9197 (1.0063)\tloss 1.0121 (0.9952)\tgrad_norm 4.9270 (4.3977)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:48:05 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [3/300][70/109]\teta 0:00:38 lr 0.000023\t wd 0.0500\ttime 0.9138 (0.9973)\tloss 1.0421 (0.9984)\tgrad_norm 5.7376 (4.4610)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:48:14 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [3/300][80/109]\teta 0:00:28 lr 0.000024\t wd 0.0500\ttime 0.9145 (0.9909)\tloss 1.0249 (0.9959)\tgrad_norm 4.1765 (4.4396)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:48:24 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [3/300][90/109]\teta 0:00:18 lr 0.000024\t wd 0.0500\ttime 0.9170 (0.9856)\tloss 0.9616 (0.9938)\tgrad_norm 4.9804 (4.4344)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:48:33 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [3/300][100/109]\teta 0:00:08 lr 0.000025\t wd 0.0500\ttime 0.9167 (0.9815)\tloss 1.0553 (0.9955)\tgrad_norm 4.3212 (4.3858)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:48:41 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 3 training takes 0:01:46\n",
            "\u001b[32m[2023-03-27 06:48:41 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_3.pth saving......\n",
            "\u001b[32m[2023-03-27 06:48:45 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_3.pth saved !!!\n",
            "\u001b[32m[2023-03-27 06:48:47 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 2.254 (2.254)\tLoss 2.5508 (2.5508)\tAcc@1 3.125 (3.125)\tAcc@5 95.312 (95.312)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:48:50 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.328 (0.502)\tLoss 0.2717 (2.0911)\tAcc@1 98.438 (17.330)\tAcc@5 100.000 (96.307)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:48:53 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.324 (0.418)\tLoss 0.2764 (1.2175)\tAcc@1 100.000 (56.473)\tAcc@5 100.000 (98.065)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:48:57 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.325 (0.389)\tLoss 0.7090 (0.9289)\tAcc@1 87.500 (69.960)\tAcc@5 98.438 (98.639)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:48:57 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 69.227 Acc@5 98.404\n",
            "\u001b[32m[2023-03-27 06:48:57 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 69.2%\n",
            "\u001b[32m[2023-03-27 06:48:57 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 69.23%\n",
            "\u001b[32m[2023-03-27 06:49:01 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [4/300][0/109]\teta 0:06:23 lr 0.000025\t wd 0.0500\ttime 3.5160 (3.5160)\tloss 0.9750 (0.9750)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:49:10 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [4/300][10/109]\teta 0:01:57 lr 0.000026\t wd 0.0500\ttime 0.9221 (1.1844)\tloss 0.9663 (0.9733)\tgrad_norm 3.8132 (3.6540)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:49:20 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [4/300][20/109]\teta 0:01:35 lr 0.000026\t wd 0.0500\ttime 0.9297 (1.0764)\tloss 0.9790 (0.9815)\tgrad_norm 4.3411 (3.7257)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:49:29 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [4/300][30/109]\teta 0:01:22 lr 0.000027\t wd 0.0500\ttime 0.9246 (1.0390)\tloss 1.0178 (0.9787)\tgrad_norm 3.4338 (4.1241)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:49:39 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [4/300][40/109]\teta 0:01:10 lr 0.000028\t wd 0.0500\ttime 0.9275 (1.0186)\tloss 0.9933 (0.9890)\tgrad_norm 4.7530 (4.4224)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:49:48 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [4/300][50/109]\teta 0:00:59 lr 0.000028\t wd 0.0500\ttime 0.9187 (1.0048)\tloss 0.9387 (0.9833)\tgrad_norm 3.3104 (4.8723)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:49:58 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [4/300][60/109]\teta 0:00:48 lr 0.000029\t wd 0.0500\ttime 0.9190 (0.9953)\tloss 0.9995 (0.9840)\tgrad_norm 5.6153 (4.8358)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:50:07 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [4/300][70/109]\teta 0:00:38 lr 0.000029\t wd 0.0500\ttime 0.9143 (0.9878)\tloss 0.9754 (0.9850)\tgrad_norm 3.6120 (4.6904)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:50:17 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [4/300][80/109]\teta 0:00:28 lr 0.000030\t wd 0.0500\ttime 0.9098 (0.9825)\tloss 0.8995 (0.9839)\tgrad_norm 3.9492 (4.6734)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:50:26 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [4/300][90/109]\teta 0:00:18 lr 0.000030\t wd 0.0500\ttime 0.9145 (0.9784)\tloss 0.9618 (0.9825)\tgrad_norm 6.1284 (4.7184)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:50:35 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [4/300][100/109]\teta 0:00:08 lr 0.000031\t wd 0.0500\ttime 0.9173 (0.9749)\tloss 0.9324 (0.9842)\tgrad_norm 4.2814 (4.6594)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:50:43 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 4 training takes 0:01:46\n",
            "\u001b[32m[2023-03-27 06:50:43 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_4.pth saving......\n",
            "\u001b[32m[2023-03-27 06:50:47 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_4.pth saved !!!\n",
            "\u001b[32m[2023-03-27 06:50:49 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 1.629 (1.629)\tLoss 2.1562 (2.1562)\tAcc@1 1.562 (1.562)\tAcc@5 98.438 (98.438)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:50:52 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.332 (0.477)\tLoss 0.4072 (1.7402)\tAcc@1 98.438 (28.267)\tAcc@5 100.000 (96.591)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:50:56 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.325 (0.407)\tLoss 0.4102 (1.0903)\tAcc@1 100.000 (61.682)\tAcc@5 100.000 (98.214)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:50:59 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.325 (0.381)\tLoss 0.7217 (0.8822)\tAcc@1 84.375 (72.480)\tAcc@5 95.312 (98.639)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:50:59 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 71.721 Acc@5 98.404\n",
            "\u001b[32m[2023-03-27 06:50:59 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 71.7%\n",
            "\u001b[32m[2023-03-27 06:50:59 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 71.72%\n",
            "\u001b[32m[2023-03-27 06:51:02 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [5/300][0/109]\teta 0:05:54 lr 0.000031\t wd 0.0500\ttime 3.2531 (3.2531)\tloss 0.8610 (0.8610)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:51:12 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [5/300][10/109]\teta 0:01:55 lr 0.000032\t wd 0.0500\ttime 0.9275 (1.1681)\tloss 1.0652 (1.0108)\tgrad_norm 3.3415 (4.9437)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:51:22 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [5/300][20/109]\teta 0:01:34 lr 0.000033\t wd 0.0500\ttime 0.9333 (1.0663)\tloss 0.9115 (0.9888)\tgrad_norm 4.0295 (4.3120)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:51:31 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [5/300][30/109]\teta 0:01:21 lr 0.000033\t wd 0.0500\ttime 0.9297 (1.0310)\tloss 0.9562 (0.9765)\tgrad_norm 2.2528 (3.9625)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:51:41 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [5/300][40/109]\teta 0:01:09 lr 0.000034\t wd 0.0500\ttime 0.9214 (1.0124)\tloss 0.9965 (0.9799)\tgrad_norm 4.6050 (3.8234)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:51:50 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [5/300][50/109]\teta 0:00:58 lr 0.000034\t wd 0.0500\ttime 0.9201 (0.9999)\tloss 1.1071 (0.9866)\tgrad_norm 3.4672 (3.7150)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:52:00 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [5/300][60/109]\teta 0:00:48 lr 0.000035\t wd 0.0500\ttime 0.9170 (0.9913)\tloss 0.9788 (0.9847)\tgrad_norm 4.7157 (3.7214)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:52:09 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [5/300][70/109]\teta 0:00:38 lr 0.000036\t wd 0.0500\ttime 0.9156 (0.9847)\tloss 1.0091 (0.9849)\tgrad_norm 2.5109 (3.6582)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:52:18 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [5/300][80/109]\teta 0:00:28 lr 0.000036\t wd 0.0500\ttime 0.9123 (0.9792)\tloss 0.9953 (0.9885)\tgrad_norm 5.1966 (3.7153)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:52:28 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [5/300][90/109]\teta 0:00:18 lr 0.000037\t wd 0.0500\ttime 0.9160 (0.9754)\tloss 1.0653 (0.9862)\tgrad_norm 3.9864 (3.6481)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:52:37 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [5/300][100/109]\teta 0:00:08 lr 0.000037\t wd 0.0500\ttime 0.9145 (0.9723)\tloss 1.0343 (0.9830)\tgrad_norm 5.8289 (3.7059)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:52:45 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 5 training takes 0:01:45\n",
            "\u001b[32m[2023-03-27 06:52:45 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_5.pth saving......\n",
            "\u001b[32m[2023-03-27 06:52:49 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_5.pth saved !!!\n",
            "\u001b[32m[2023-03-27 06:52:52 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 3.063 (3.063)\tLoss 2.5098 (2.5098)\tAcc@1 3.125 (3.125)\tAcc@5 89.062 (89.062)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:52:56 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.326 (0.612)\tLoss 0.2617 (1.9845)\tAcc@1 100.000 (22.017)\tAcc@5 100.000 (95.739)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:52:59 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.328 (0.476)\tLoss 0.2683 (1.1596)\tAcc@1 100.000 (58.631)\tAcc@5 100.000 (97.768)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:53:02 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.328 (0.429)\tLoss 0.4905 (0.8826)\tAcc@1 87.500 (70.968)\tAcc@5 100.000 (98.488)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:53:02 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 70.224 Acc@5 98.404\n",
            "\u001b[32m[2023-03-27 06:53:02 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 70.2%\n",
            "\u001b[32m[2023-03-27 06:53:02 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 71.72%\n",
            "\u001b[32m[2023-03-27 06:53:07 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [6/300][0/109]\teta 0:07:23 lr 0.000038\t wd 0.0500\ttime 4.0654 (4.0654)\tloss 1.1250 (1.1250)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:53:17 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [6/300][10/109]\teta 0:02:06 lr 0.000038\t wd 0.0500\ttime 0.9243 (1.2789)\tloss 0.9385 (0.9715)\tgrad_norm 3.1847 (4.2942)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:53:26 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [6/300][20/109]\teta 0:01:40 lr 0.000039\t wd 0.0500\ttime 0.9238 (1.1254)\tloss 0.9442 (0.9574)\tgrad_norm 6.0144 (4.3459)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:53:36 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [6/300][30/109]\teta 0:01:24 lr 0.000040\t wd 0.0500\ttime 0.9268 (1.0697)\tloss 0.9286 (0.9455)\tgrad_norm 4.3835 (4.2513)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:53:45 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [6/300][40/109]\teta 0:01:11 lr 0.000040\t wd 0.0500\ttime 0.9170 (1.0414)\tloss 1.0770 (0.9575)\tgrad_norm 3.0766 (4.2386)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:53:55 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [6/300][50/109]\teta 0:01:00 lr 0.000041\t wd 0.0500\ttime 0.9159 (1.0229)\tloss 0.9846 (0.9584)\tgrad_norm 2.4891 (4.0228)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:54:04 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [6/300][60/109]\teta 0:00:49 lr 0.000041\t wd 0.0500\ttime 0.9103 (1.0098)\tloss 0.9995 (0.9608)\tgrad_norm 5.9794 (4.0925)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:54:14 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [6/300][70/109]\teta 0:00:39 lr 0.000042\t wd 0.0500\ttime 0.9142 (1.0007)\tloss 0.8968 (0.9628)\tgrad_norm 4.2323 (4.0751)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:54:23 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [6/300][80/109]\teta 0:00:28 lr 0.000042\t wd 0.0500\ttime 0.9231 (0.9938)\tloss 1.0350 (0.9661)\tgrad_norm 3.7525 (4.0539)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:54:32 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [6/300][90/109]\teta 0:00:18 lr 0.000043\t wd 0.0500\ttime 0.9159 (0.9885)\tloss 1.0458 (0.9685)\tgrad_norm 4.2914 (4.0191)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:54:42 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [6/300][100/109]\teta 0:00:08 lr 0.000044\t wd 0.0500\ttime 0.9144 (0.9842)\tloss 0.8541 (0.9655)\tgrad_norm 4.1709 (3.9529)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:54:50 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 6 training takes 0:01:47\n",
            "\u001b[32m[2023-03-27 06:54:50 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_6.pth saving......\n",
            "\u001b[32m[2023-03-27 06:54:54 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_6.pth saved !!!\n",
            "\u001b[32m[2023-03-27 06:54:56 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 2.185 (2.185)\tLoss 2.5918 (2.5918)\tAcc@1 0.000 (0.000)\tAcc@5 93.750 (93.750)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:54:59 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.325 (0.495)\tLoss 0.3330 (1.7827)\tAcc@1 98.438 (26.705)\tAcc@5 100.000 (96.307)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:55:02 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.322 (0.414)\tLoss 0.3369 (1.0770)\tAcc@1 98.438 (60.938)\tAcc@5 100.000 (98.065)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:55:06 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.325 (0.386)\tLoss 0.4031 (0.8396)\tAcc@1 93.750 (72.429)\tAcc@5 100.000 (98.690)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:55:06 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 72.170 Acc@5 98.703\n",
            "\u001b[32m[2023-03-27 06:55:06 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 72.2%\n",
            "\u001b[32m[2023-03-27 06:55:06 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 72.17%\n",
            "\u001b[32m[2023-03-27 06:55:09 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [7/300][0/109]\teta 0:06:15 lr 0.000044\t wd 0.0500\ttime 3.4410 (3.4410)\tloss 0.9476 (0.9476)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:55:19 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [7/300][10/109]\teta 0:01:56 lr 0.000045\t wd 0.0500\ttime 0.9294 (1.1817)\tloss 0.9266 (0.9301)\tgrad_norm 3.5128 (3.5533)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:55:29 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [7/300][20/109]\teta 0:01:35 lr 0.000045\t wd 0.0500\ttime 0.9356 (1.0769)\tloss 0.8965 (0.9446)\tgrad_norm 5.0621 (4.1244)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:55:38 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [7/300][30/109]\teta 0:01:22 lr 0.000046\t wd 0.0500\ttime 0.9229 (1.0391)\tloss 0.9683 (0.9478)\tgrad_norm 2.7551 (4.0197)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:55:48 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [7/300][40/109]\teta 0:01:10 lr 0.000046\t wd 0.0500\ttime 0.9183 (1.0179)\tloss 1.0221 (0.9546)\tgrad_norm 4.0183 (4.0757)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:55:57 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [7/300][50/109]\teta 0:00:59 lr 0.000047\t wd 0.0500\ttime 0.9184 (1.0046)\tloss 0.8924 (0.9508)\tgrad_norm 4.6913 (4.1154)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:56:07 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [7/300][60/109]\teta 0:00:48 lr 0.000048\t wd 0.0500\ttime 0.9170 (0.9947)\tloss 0.9504 (0.9574)\tgrad_norm 3.8999 (4.0725)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:56:16 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [7/300][70/109]\teta 0:00:38 lr 0.000048\t wd 0.0500\ttime 0.9143 (0.9871)\tloss 0.9350 (0.9554)\tgrad_norm 6.5554 (4.1620)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:56:25 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [7/300][80/109]\teta 0:00:28 lr 0.000049\t wd 0.0500\ttime 0.9168 (0.9819)\tloss 0.9159 (0.9534)\tgrad_norm 5.4209 (4.2225)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:56:35 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [7/300][90/109]\teta 0:00:18 lr 0.000049\t wd 0.0500\ttime 0.9184 (0.9778)\tloss 0.9404 (0.9533)\tgrad_norm 4.4767 (4.2950)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:56:44 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [7/300][100/109]\teta 0:00:08 lr 0.000050\t wd 0.0500\ttime 0.9134 (0.9744)\tloss 1.0104 (0.9553)\tgrad_norm 4.6889 (4.3046)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:56:52 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 7 training takes 0:01:46\n",
            "\u001b[32m[2023-03-27 06:56:52 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_7.pth saving......\n",
            "\u001b[32m[2023-03-27 06:56:56 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_7.pth saved !!!\n",
            "\u001b[32m[2023-03-27 06:56:58 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 1.842 (1.842)\tLoss 1.6113 (1.6113)\tAcc@1 32.812 (32.812)\tAcc@5 100.000 (100.000)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:57:01 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.325 (0.472)\tLoss 0.3276 (1.7525)\tAcc@1 98.438 (29.261)\tAcc@5 100.000 (96.591)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:57:04 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.327 (0.403)\tLoss 0.3159 (1.0592)\tAcc@1 98.438 (61.979)\tAcc@5 100.000 (98.214)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:57:08 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.328 (0.378)\tLoss 0.3696 (0.8217)\tAcc@1 93.750 (73.185)\tAcc@5 100.000 (98.790)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:57:08 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 73.067 Acc@5 98.653\n",
            "\u001b[32m[2023-03-27 06:57:08 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 73.1%\n",
            "\u001b[32m[2023-03-27 06:57:08 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 73.07%\n",
            "\u001b[32m[2023-03-27 06:57:11 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [8/300][0/109]\teta 0:05:24 lr 0.000050\t wd 0.0500\ttime 2.9801 (2.9801)\tloss 0.8763 (0.8763)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:57:21 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [8/300][10/109]\teta 0:01:53 lr 0.000051\t wd 0.0500\ttime 0.9223 (1.1426)\tloss 0.9793 (0.9298)\tgrad_norm 4.6230 (3.8332)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:57:30 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [8/300][20/109]\teta 0:01:33 lr 0.000052\t wd 0.0500\ttime 0.9326 (1.0525)\tloss 1.0402 (0.9450)\tgrad_norm 5.0549 (3.8691)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:57:40 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [8/300][30/109]\teta 0:01:20 lr 0.000052\t wd 0.0500\ttime 0.9233 (1.0212)\tloss 0.9732 (0.9526)\tgrad_norm 3.3604 (4.1577)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:57:49 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [8/300][40/109]\teta 0:01:09 lr 0.000053\t wd 0.0500\ttime 0.9200 (1.0041)\tloss 0.9767 (0.9466)\tgrad_norm 4.2072 (4.3218)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:57:59 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [8/300][50/109]\teta 0:00:58 lr 0.000053\t wd 0.0500\ttime 0.9145 (0.9923)\tloss 0.9112 (0.9517)\tgrad_norm 3.1634 (4.1137)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:58:08 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [8/300][60/109]\teta 0:00:48 lr 0.000054\t wd 0.0500\ttime 0.9124 (0.9843)\tloss 0.9349 (0.9529)\tgrad_norm 3.9905 (3.9817)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:58:17 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [8/300][70/109]\teta 0:00:38 lr 0.000054\t wd 0.0500\ttime 0.9113 (0.9785)\tloss 0.9020 (0.9556)\tgrad_norm 3.4597 (3.9413)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:58:27 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [8/300][80/109]\teta 0:00:28 lr 0.000055\t wd 0.0500\ttime 0.9133 (0.9741)\tloss 0.9790 (0.9538)\tgrad_norm 4.2747 (3.9017)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:58:36 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [8/300][90/109]\teta 0:00:18 lr 0.000056\t wd 0.0500\ttime 0.9163 (0.9713)\tloss 1.0397 (0.9555)\tgrad_norm 3.4627 (3.8844)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:58:46 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [8/300][100/109]\teta 0:00:08 lr 0.000056\t wd 0.0500\ttime 0.9184 (0.9689)\tloss 1.0519 (0.9566)\tgrad_norm 5.2773 (3.9992)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:58:54 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 8 training takes 0:01:45\n",
            "\u001b[32m[2023-03-27 06:58:54 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_8.pth saving......\n",
            "\u001b[32m[2023-03-27 06:58:57 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_8.pth saved !!!\n",
            "\u001b[32m[2023-03-27 06:59:00 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 2.178 (2.178)\tLoss 2.0586 (2.0586)\tAcc@1 21.875 (21.875)\tAcc@5 98.438 (98.438)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:59:03 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.325 (0.522)\tLoss 0.3713 (1.5482)\tAcc@1 96.875 (40.199)\tAcc@5 100.000 (96.591)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:59:06 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.327 (0.429)\tLoss 0.3870 (0.9696)\tAcc@1 95.312 (66.518)\tAcc@5 100.000 (98.214)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:59:10 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.325 (0.396)\tLoss 0.3550 (0.7738)\tAcc@1 93.750 (75.252)\tAcc@5 100.000 (98.790)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 06:59:10 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 75.162 Acc@5 98.703\n",
            "\u001b[32m[2023-03-27 06:59:10 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 75.2%\n",
            "\u001b[32m[2023-03-27 06:59:10 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 75.16%\n",
            "\u001b[32m[2023-03-27 06:59:13 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [9/300][0/109]\teta 0:05:39 lr 0.000057\t wd 0.0500\ttime 3.1122 (3.1122)\tloss 0.8757 (0.8757)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:59:23 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [9/300][10/109]\teta 0:01:53 lr 0.000057\t wd 0.0500\ttime 0.9235 (1.1467)\tloss 0.9936 (0.9321)\tgrad_norm 2.7747 (3.7220)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:59:32 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [9/300][20/109]\teta 0:01:33 lr 0.000058\t wd 0.0500\ttime 0.9307 (1.0554)\tloss 0.9524 (0.9488)\tgrad_norm 3.4118 (3.7329)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:59:42 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [9/300][30/109]\teta 0:01:20 lr 0.000059\t wd 0.0500\ttime 0.9211 (1.0228)\tloss 0.9717 (0.9527)\tgrad_norm 2.6574 (3.5686)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 06:59:51 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [9/300][40/109]\teta 0:01:09 lr 0.000059\t wd 0.0500\ttime 0.9226 (1.0060)\tloss 0.9578 (0.9498)\tgrad_norm 3.5002 (3.6044)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:00:01 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [9/300][50/109]\teta 0:00:58 lr 0.000060\t wd 0.0500\ttime 0.9258 (0.9948)\tloss 0.9615 (0.9482)\tgrad_norm 3.1520 (3.8285)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:00:10 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [9/300][60/109]\teta 0:00:48 lr 0.000060\t wd 0.0500\ttime 0.9165 (0.9871)\tloss 1.0390 (0.9570)\tgrad_norm 3.5700 (3.8055)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:00:20 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [9/300][70/109]\teta 0:00:38 lr 0.000061\t wd 0.0500\ttime 0.9165 (0.9814)\tloss 0.9549 (0.9536)\tgrad_norm 4.7288 (3.7469)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:00:29 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [9/300][80/109]\teta 0:00:28 lr 0.000061\t wd 0.0500\ttime 0.9154 (0.9764)\tloss 0.8887 (0.9536)\tgrad_norm 4.8694 (3.7137)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:00:38 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [9/300][90/109]\teta 0:00:18 lr 0.000062\t wd 0.0500\ttime 0.9096 (0.9728)\tloss 0.9524 (0.9524)\tgrad_norm 3.0026 (3.7280)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:00:48 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [9/300][100/109]\teta 0:00:08 lr 0.000063\t wd 0.0500\ttime 0.9124 (0.9699)\tloss 0.8859 (0.9518)\tgrad_norm 3.5567 (3.7560)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:00:56 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 9 training takes 0:01:45\n",
            "\u001b[32m[2023-03-27 07:00:56 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_9.pth saving......\n",
            "\u001b[32m[2023-03-27 07:00:59 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_9.pth saved !!!\n",
            "\u001b[32m[2023-03-27 07:01:03 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 3.220 (3.220)\tLoss 1.9375 (1.9375)\tAcc@1 25.000 (25.000)\tAcc@5 100.000 (100.000)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:01:06 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.328 (0.596)\tLoss 0.3806 (1.5785)\tAcc@1 95.312 (38.068)\tAcc@5 100.000 (96.733)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:01:09 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.328 (0.468)\tLoss 0.3914 (0.9967)\tAcc@1 96.875 (65.774)\tAcc@5 100.000 (98.289)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:01:13 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.330 (0.422)\tLoss 0.4417 (0.8016)\tAcc@1 95.312 (75.252)\tAcc@5 100.000 (98.841)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:01:13 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 75.062 Acc@5 98.703\n",
            "\u001b[32m[2023-03-27 07:01:13 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 75.1%\n",
            "\u001b[32m[2023-03-27 07:01:13 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 75.16%\n",
            "\u001b[32m[2023-03-27 07:01:17 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [10/300][0/109]\teta 0:08:29 lr 0.000063\t wd 0.0500\ttime 4.6785 (4.6785)\tloss 0.9849 (0.9849)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:01:27 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [10/300][10/109]\teta 0:02:10 lr 0.000064\t wd 0.0500\ttime 0.9255 (1.3227)\tloss 0.8916 (0.9369)\tgrad_norm 3.5593 (3.9197)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:01:37 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [10/300][20/109]\teta 0:01:42 lr 0.000064\t wd 0.0500\ttime 0.9277 (1.1488)\tloss 0.9524 (0.9350)\tgrad_norm 5.1687 (3.8793)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:01:47 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [10/300][30/109]\teta 0:01:25 lr 0.000065\t wd 0.0500\ttime 0.9268 (1.0870)\tloss 0.8913 (0.9410)\tgrad_norm 4.0397 (4.0369)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:01:56 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [10/300][40/109]\teta 0:01:12 lr 0.000065\t wd 0.0500\ttime 0.9271 (1.0541)\tloss 0.9647 (0.9428)\tgrad_norm 5.2570 (4.0987)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:02:06 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [10/300][50/109]\teta 0:01:00 lr 0.000066\t wd 0.0500\ttime 0.9197 (1.0337)\tloss 0.9315 (0.9463)\tgrad_norm 2.6064 (3.9207)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:02:15 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [10/300][60/109]\teta 0:00:49 lr 0.000066\t wd 0.0500\ttime 0.9175 (1.0188)\tloss 0.9687 (0.9456)\tgrad_norm 3.0157 (3.7949)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:02:24 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [10/300][70/109]\teta 0:00:39 lr 0.000067\t wd 0.0500\ttime 0.9144 (1.0082)\tloss 0.9466 (0.9456)\tgrad_norm 3.8227 (3.7418)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:02:34 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [10/300][80/109]\teta 0:00:29 lr 0.000068\t wd 0.0500\ttime 0.9141 (1.0002)\tloss 1.0141 (0.9470)\tgrad_norm 3.1886 (3.8539)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:02:43 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [10/300][90/109]\teta 0:00:18 lr 0.000068\t wd 0.0500\ttime 0.9172 (0.9940)\tloss 0.9311 (0.9516)\tgrad_norm 3.2606 (3.8310)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:02:53 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [10/300][100/109]\teta 0:00:08 lr 0.000069\t wd 0.0500\ttime 0.9167 (0.9893)\tloss 0.9690 (0.9514)\tgrad_norm 2.5271 (3.7144)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:03:01 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 10 training takes 0:01:47\n",
            "\u001b[32m[2023-03-27 07:03:01 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_10.pth saving......\n",
            "\u001b[32m[2023-03-27 07:03:04 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_10.pth saved !!!\n",
            "\u001b[32m[2023-03-27 07:03:07 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 2.286 (2.286)\tLoss 1.6436 (1.6436)\tAcc@1 31.250 (31.250)\tAcc@5 100.000 (100.000)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:03:10 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.325 (0.504)\tLoss 0.3552 (1.6205)\tAcc@1 100.000 (32.244)\tAcc@5 100.000 (97.727)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:03:13 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.326 (0.419)\tLoss 0.3564 (1.0058)\tAcc@1 100.000 (63.616)\tAcc@5 100.000 (98.810)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:03:17 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.326 (0.390)\tLoss 0.4395 (0.7989)\tAcc@1 93.750 (74.496)\tAcc@5 100.000 (99.194)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:03:17 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 74.314 Acc@5 99.052\n",
            "\u001b[32m[2023-03-27 07:03:17 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 74.3%\n",
            "\u001b[32m[2023-03-27 07:03:17 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 75.16%\n",
            "\u001b[32m[2023-03-27 07:03:20 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [11/300][0/109]\teta 0:05:46 lr 0.000069\t wd 0.0500\ttime 3.1816 (3.1816)\tloss 1.0039 (1.0039)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:03:30 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [11/300][10/109]\teta 0:01:54 lr 0.000070\t wd 0.0500\ttime 0.9271 (1.1586)\tloss 1.0076 (0.9509)\tgrad_norm 3.2811 (2.8413)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:03:39 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [11/300][20/109]\teta 0:01:34 lr 0.000071\t wd 0.0500\ttime 0.9223 (1.0611)\tloss 1.0034 (0.9516)\tgrad_norm 4.6096 (3.4531)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:03:49 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [11/300][30/109]\teta 0:01:21 lr 0.000071\t wd 0.0500\ttime 0.9238 (1.0269)\tloss 0.9046 (0.9451)\tgrad_norm 4.5640 (3.6151)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:03:58 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [11/300][40/109]\teta 0:01:09 lr 0.000072\t wd 0.0500\ttime 0.9238 (1.0088)\tloss 1.0086 (0.9472)\tgrad_norm 2.5624 (3.5044)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:04:08 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [11/300][50/109]\teta 0:00:58 lr 0.000072\t wd 0.0500\ttime 0.9165 (0.9968)\tloss 0.8696 (0.9388)\tgrad_norm 4.8350 (3.5598)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:04:17 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [11/300][60/109]\teta 0:00:48 lr 0.000073\t wd 0.0500\ttime 0.9156 (0.9889)\tloss 0.9233 (0.9387)\tgrad_norm 3.3883 (3.4911)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:04:27 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [11/300][70/109]\teta 0:00:38 lr 0.000073\t wd 0.0500\ttime 0.9181 (0.9826)\tloss 0.9273 (0.9391)\tgrad_norm 3.2178 (3.4359)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:04:36 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [11/300][80/109]\teta 0:00:28 lr 0.000074\t wd 0.0500\ttime 0.9117 (0.9779)\tloss 0.9264 (0.9417)\tgrad_norm 4.0191 (3.4034)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:04:45 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [11/300][90/109]\teta 0:00:18 lr 0.000075\t wd 0.0500\ttime 0.9118 (0.9742)\tloss 0.8797 (0.9438)\tgrad_norm 4.2146 (3.4144)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:04:55 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [11/300][100/109]\teta 0:00:08 lr 0.000075\t wd 0.0500\ttime 0.9150 (0.9709)\tloss 0.9477 (0.9452)\tgrad_norm 3.2488 (3.4135)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:05:03 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 11 training takes 0:01:45\n",
            "\u001b[32m[2023-03-27 07:05:03 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_11.pth saving......\n",
            "\u001b[32m[2023-03-27 07:05:06 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_11.pth saved !!!\n",
            "\u001b[32m[2023-03-27 07:05:08 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 1.353 (1.353)\tLoss 1.6357 (1.6357)\tAcc@1 14.062 (14.062)\tAcc@5 100.000 (100.000)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:05:11 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.333 (0.443)\tLoss 0.4592 (1.5149)\tAcc@1 90.625 (45.312)\tAcc@5 100.000 (97.869)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:05:15 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.327 (0.390)\tLoss 0.4834 (0.9985)\tAcc@1 87.500 (66.815)\tAcc@5 100.000 (98.884)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:05:18 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.327 (0.369)\tLoss 0.5146 (0.8341)\tAcc@1 87.500 (72.883)\tAcc@5 100.000 (99.244)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:05:18 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 72.718 Acc@5 99.052\n",
            "\u001b[32m[2023-03-27 07:05:18 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 72.7%\n",
            "\u001b[32m[2023-03-27 07:05:18 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 75.16%\n",
            "\u001b[32m[2023-03-27 07:05:21 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [12/300][0/109]\teta 0:04:53 lr 0.000076\t wd 0.0500\ttime 2.6911 (2.6911)\tloss 0.9638 (0.9638)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:05:31 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [12/300][10/109]\teta 0:01:51 lr 0.000076\t wd 0.0500\ttime 0.9232 (1.1310)\tloss 0.9174 (0.9100)\tgrad_norm 2.3585 (3.7535)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:05:40 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [12/300][20/109]\teta 0:01:33 lr 0.000077\t wd 0.0500\ttime 0.9293 (1.0486)\tloss 0.9176 (0.9247)\tgrad_norm 4.3691 (3.9652)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:05:50 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [12/300][30/109]\teta 0:01:20 lr 0.000077\t wd 0.0500\ttime 0.9236 (1.0183)\tloss 1.0163 (0.9355)\tgrad_norm 3.2494 (3.7541)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:05:59 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [12/300][40/109]\teta 0:01:09 lr 0.000078\t wd 0.0500\ttime 0.9205 (1.0019)\tloss 0.9106 (0.9364)\tgrad_norm 2.8066 (3.6367)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:06:09 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [12/300][50/109]\teta 0:00:58 lr 0.000079\t wd 0.0500\ttime 0.9169 (0.9904)\tloss 0.9480 (0.9455)\tgrad_norm 2.8910 (3.5226)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:06:18 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [12/300][60/109]\teta 0:00:48 lr 0.000079\t wd 0.0500\ttime 0.9122 (0.9827)\tloss 0.8886 (0.9478)\tgrad_norm 4.4619 (3.4181)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:06:28 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [12/300][70/109]\teta 0:00:38 lr 0.000080\t wd 0.0500\ttime 0.9268 (0.9770)\tloss 0.9383 (0.9434)\tgrad_norm 2.5232 (3.3617)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:06:37 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [12/300][80/109]\teta 0:00:28 lr 0.000080\t wd 0.0500\ttime 0.9147 (0.9725)\tloss 1.0252 (0.9457)\tgrad_norm 2.6713 (3.3316)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:06:46 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [12/300][90/109]\teta 0:00:18 lr 0.000081\t wd 0.0500\ttime 0.9188 (0.9697)\tloss 1.0259 (0.9471)\tgrad_norm 2.5041 (3.3334)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:06:56 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [12/300][100/109]\teta 0:00:08 lr 0.000081\t wd 0.0500\ttime 0.9182 (0.9672)\tloss 0.9079 (0.9458)\tgrad_norm 2.2074 (3.2518)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:07:04 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 12 training takes 0:01:45\n",
            "\u001b[32m[2023-03-27 07:07:04 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_12.pth saving......\n",
            "\u001b[32m[2023-03-27 07:07:07 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_12.pth saved !!!\n",
            "\u001b[32m[2023-03-27 07:07:10 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 2.942 (2.942)\tLoss 2.2441 (2.2441)\tAcc@1 7.812 (7.812)\tAcc@5 96.875 (96.875)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:07:14 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.322 (0.619)\tLoss 0.3269 (1.6423)\tAcc@1 98.438 (30.966)\tAcc@5 100.000 (97.301)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:07:17 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.324 (0.480)\tLoss 0.3560 (1.0136)\tAcc@1 98.438 (62.946)\tAcc@5 100.000 (98.586)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:07:21 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.330 (0.431)\tLoss 0.3228 (0.7969)\tAcc@1 95.312 (73.790)\tAcc@5 100.000 (99.042)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:07:21 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 73.766 Acc@5 99.052\n",
            "\u001b[32m[2023-03-27 07:07:21 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 73.8%\n",
            "\u001b[32m[2023-03-27 07:07:21 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 75.16%\n",
            "\u001b[32m[2023-03-27 07:07:25 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [13/300][0/109]\teta 0:06:48 lr 0.000082\t wd 0.0500\ttime 3.7484 (3.7484)\tloss 0.9366 (0.9366)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:07:35 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [13/300][10/109]\teta 0:02:07 lr 0.000083\t wd 0.0500\ttime 0.9240 (1.2879)\tloss 0.8544 (0.9298)\tgrad_norm 4.8471 (3.5121)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:07:45 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [13/300][20/109]\teta 0:01:40 lr 0.000083\t wd 0.0500\ttime 0.9196 (1.1313)\tloss 0.9205 (0.9385)\tgrad_norm 3.2502 (3.3529)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:07:54 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [13/300][30/109]\teta 0:01:24 lr 0.000084\t wd 0.0500\ttime 0.9261 (1.0730)\tloss 0.9750 (0.9415)\tgrad_norm 2.6513 (3.2245)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:08:04 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [13/300][40/109]\teta 0:01:11 lr 0.000084\t wd 0.0500\ttime 0.9180 (1.0430)\tloss 0.9659 (0.9422)\tgrad_norm 3.3346 (3.4554)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:08:13 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [13/300][50/109]\teta 0:01:00 lr 0.000085\t wd 0.0500\ttime 0.9149 (1.0240)\tloss 0.8580 (0.9391)\tgrad_norm 4.7936 (3.4499)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:08:23 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [13/300][60/109]\teta 0:00:49 lr 0.000085\t wd 0.0500\ttime 0.9138 (1.0105)\tloss 0.9942 (0.9349)\tgrad_norm 3.9779 (3.4329)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:08:32 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [13/300][70/109]\teta 0:00:39 lr 0.000086\t wd 0.0500\ttime 0.9131 (1.0010)\tloss 0.9706 (0.9309)\tgrad_norm 3.2218 (3.5790)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:08:42 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [13/300][80/109]\teta 0:00:28 lr 0.000087\t wd 0.0500\ttime 0.9201 (0.9940)\tloss 1.0363 (0.9331)\tgrad_norm 5.4559 (3.7582)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:08:51 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [13/300][90/109]\teta 0:00:18 lr 0.000087\t wd 0.0500\ttime 0.9129 (0.9881)\tloss 1.0542 (0.9340)\tgrad_norm 2.4477 (3.7148)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:09:00 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [13/300][100/109]\teta 0:00:08 lr 0.000088\t wd 0.0500\ttime 0.9184 (0.9840)\tloss 0.9668 (0.9353)\tgrad_norm 2.8094 (3.8922)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:09:08 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 13 training takes 0:01:47\n",
            "\u001b[32m[2023-03-27 07:09:08 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_13.pth saving......\n",
            "\u001b[32m[2023-03-27 07:09:12 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_13.pth saved !!!\n",
            "\u001b[32m[2023-03-27 07:09:14 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 2.077 (2.077)\tLoss 2.0430 (2.0430)\tAcc@1 9.375 (9.375)\tAcc@5 98.438 (98.438)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:09:17 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.327 (0.488)\tLoss 0.2959 (1.6718)\tAcc@1 100.000 (28.977)\tAcc@5 100.000 (97.443)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:09:21 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.328 (0.411)\tLoss 0.3030 (1.0113)\tAcc@1 100.000 (62.277)\tAcc@5 100.000 (98.661)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:09:24 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.330 (0.384)\tLoss 0.4070 (0.7864)\tAcc@1 92.188 (73.639)\tAcc@5 100.000 (99.093)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:09:24 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 73.367 Acc@5 99.002\n",
            "\u001b[32m[2023-03-27 07:09:24 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 73.4%\n",
            "\u001b[32m[2023-03-27 07:09:24 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 75.16%\n",
            "\u001b[32m[2023-03-27 07:09:28 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [14/300][0/109]\teta 0:06:19 lr 0.000088\t wd 0.0500\ttime 3.4774 (3.4774)\tloss 0.8585 (0.8585)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:09:37 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [14/300][10/109]\teta 0:01:57 lr 0.000089\t wd 0.0500\ttime 0.9304 (1.1819)\tloss 0.9947 (0.9225)\tgrad_norm 2.8547 (3.3799)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:09:47 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [14/300][20/109]\teta 0:01:35 lr 0.000089\t wd 0.0500\ttime 0.9235 (1.0746)\tloss 0.8132 (0.9312)\tgrad_norm 3.9020 (3.5645)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:09:57 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [14/300][30/109]\teta 0:01:21 lr 0.000090\t wd 0.0500\ttime 0.9308 (1.0364)\tloss 0.9128 (0.9262)\tgrad_norm 2.4134 (3.4883)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:10:06 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [14/300][40/109]\teta 0:01:10 lr 0.000091\t wd 0.0500\ttime 0.9220 (1.0153)\tloss 0.9971 (0.9208)\tgrad_norm 3.9220 (3.6215)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:10:16 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [14/300][50/109]\teta 0:00:59 lr 0.000091\t wd 0.0500\ttime 0.9139 (1.0020)\tloss 1.0221 (0.9204)\tgrad_norm 3.4267 (3.5659)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:10:25 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [14/300][60/109]\teta 0:00:48 lr 0.000092\t wd 0.0500\ttime 0.9160 (0.9923)\tloss 0.9364 (0.9308)\tgrad_norm 3.2115 (3.7129)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:10:34 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [14/300][70/109]\teta 0:00:38 lr 0.000092\t wd 0.0500\ttime 0.9139 (0.9848)\tloss 0.9018 (0.9354)\tgrad_norm 2.7000 (3.5612)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:10:44 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [14/300][80/109]\teta 0:00:28 lr 0.000093\t wd 0.0500\ttime 0.9157 (0.9797)\tloss 0.9380 (0.9360)\tgrad_norm 2.8003 (3.4844)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:10:53 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [14/300][90/109]\teta 0:00:18 lr 0.000093\t wd 0.0500\ttime 0.9224 (0.9758)\tloss 0.9296 (0.9342)\tgrad_norm 3.6883 (3.4213)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:11:03 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [14/300][100/109]\teta 0:00:08 lr 0.000094\t wd 0.0500\ttime 0.9192 (0.9729)\tloss 1.0395 (0.9395)\tgrad_norm 3.4861 (3.4507)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:11:10 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 14 training takes 0:01:46\n",
            "\u001b[32m[2023-03-27 07:11:10 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_14.pth saving......\n",
            "\u001b[32m[2023-03-27 07:11:14 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_14.pth saved !!!\n",
            "\u001b[32m[2023-03-27 07:11:16 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 1.712 (1.712)\tLoss 1.4062 (1.4062)\tAcc@1 45.312 (45.312)\tAcc@5 100.000 (100.000)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:11:19 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.329 (0.455)\tLoss 0.3430 (1.5550)\tAcc@1 98.438 (37.358)\tAcc@5 100.000 (97.727)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:11:23 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.328 (0.395)\tLoss 0.3401 (0.9647)\tAcc@1 100.000 (65.997)\tAcc@5 100.000 (98.810)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:11:26 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.327 (0.373)\tLoss 0.3381 (0.7641)\tAcc@1 93.750 (75.605)\tAcc@5 100.000 (99.194)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:11:26 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 75.511 Acc@5 99.152\n",
            "\u001b[32m[2023-03-27 07:11:26 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 75.5%\n",
            "\u001b[32m[2023-03-27 07:11:26 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 75.51%\n",
            "\u001b[32m[2023-03-27 07:11:30 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [15/300][0/109]\teta 0:06:20 lr 0.000094\t wd 0.0500\ttime 3.4918 (3.4918)\tloss 0.9852 (0.9852)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:11:39 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [15/300][10/109]\teta 0:01:57 lr 0.000095\t wd 0.0500\ttime 0.9191 (1.1861)\tloss 0.8021 (0.9175)\tgrad_norm 2.5789 (3.2598)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:11:49 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [15/300][20/109]\teta 0:01:35 lr 0.000096\t wd 0.0500\ttime 0.9259 (1.0746)\tloss 0.9789 (0.9176)\tgrad_norm 3.9627 (3.4622)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:11:58 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [15/300][30/109]\teta 0:01:21 lr 0.000096\t wd 0.0500\ttime 0.9182 (1.0351)\tloss 0.7868 (0.9158)\tgrad_norm 2.8473 (3.4521)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:12:08 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [15/300][40/109]\teta 0:01:09 lr 0.000097\t wd 0.0500\ttime 0.9186 (1.0144)\tloss 1.0857 (0.9263)\tgrad_norm 3.6655 (3.5110)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:12:17 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [15/300][50/109]\teta 0:00:59 lr 0.000097\t wd 0.0500\ttime 0.9181 (1.0008)\tloss 0.8912 (0.9262)\tgrad_norm 3.6610 (3.6030)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:12:27 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [15/300][60/109]\teta 0:00:48 lr 0.000098\t wd 0.0500\ttime 0.9140 (0.9924)\tloss 0.9394 (0.9312)\tgrad_norm 4.9115 (3.6020)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:12:36 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [15/300][70/109]\teta 0:00:38 lr 0.000099\t wd 0.0500\ttime 0.9178 (0.9856)\tloss 0.9539 (0.9352)\tgrad_norm 3.3304 (3.5212)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:12:45 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [15/300][80/109]\teta 0:00:28 lr 0.000099\t wd 0.0500\ttime 0.9104 (0.9802)\tloss 1.0162 (0.9362)\tgrad_norm 3.0769 (3.4923)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:12:55 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [15/300][90/109]\teta 0:00:18 lr 0.000100\t wd 0.0500\ttime 0.9121 (0.9764)\tloss 0.9969 (0.9379)\tgrad_norm 5.1005 (3.4635)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:13:04 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [15/300][100/109]\teta 0:00:08 lr 0.000100\t wd 0.0500\ttime 0.9160 (0.9730)\tloss 0.9862 (0.9367)\tgrad_norm 4.8526 (3.4315)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:13:12 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 15 training takes 0:01:46\n",
            "\u001b[32m[2023-03-27 07:13:12 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_15.pth saving......\n",
            "\u001b[32m[2023-03-27 07:13:16 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_15.pth saved !!!\n",
            "\u001b[32m[2023-03-27 07:13:19 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 3.193 (3.193)\tLoss 1.5312 (1.5312)\tAcc@1 54.688 (54.688)\tAcc@5 98.438 (98.438)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:13:23 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.327 (0.615)\tLoss 0.3154 (1.5912)\tAcc@1 96.875 (42.188)\tAcc@5 100.000 (98.295)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:13:26 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.324 (0.476)\tLoss 0.3438 (0.9805)\tAcc@1 95.312 (67.634)\tAcc@5 100.000 (99.107)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:13:29 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.327 (0.428)\tLoss 0.3333 (0.7740)\tAcc@1 95.312 (76.210)\tAcc@5 100.000 (99.395)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:13:29 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 76.110 Acc@5 99.401\n",
            "\u001b[32m[2023-03-27 07:13:29 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 76.1%\n",
            "\u001b[32m[2023-03-27 07:13:29 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 76.11%\n",
            "\u001b[32m[2023-03-27 07:13:33 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [16/300][0/109]\teta 0:06:21 lr 0.000101\t wd 0.0500\ttime 3.4964 (3.4964)\tloss 0.9939 (0.9939)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:13:43 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [16/300][10/109]\teta 0:02:04 lr 0.000101\t wd 0.0500\ttime 0.9259 (1.2552)\tloss 0.8980 (0.9388)\tgrad_norm 4.2786 (3.8592)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:13:53 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [16/300][20/109]\teta 0:01:39 lr 0.000102\t wd 0.0500\ttime 0.9268 (1.1154)\tloss 0.8357 (0.9521)\tgrad_norm 3.1975 (3.6251)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:14:02 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [16/300][30/109]\teta 0:01:23 lr 0.000103\t wd 0.0500\ttime 0.9189 (1.0625)\tloss 0.9569 (0.9399)\tgrad_norm 2.8529 (3.4874)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:14:12 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [16/300][40/109]\teta 0:01:11 lr 0.000103\t wd 0.0500\ttime 0.9181 (1.0351)\tloss 0.9627 (0.9415)\tgrad_norm 4.5781 (3.4604)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:14:21 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [16/300][50/109]\teta 0:01:00 lr 0.000104\t wd 0.0500\ttime 0.9155 (1.0181)\tloss 0.8968 (0.9446)\tgrad_norm 2.4183 (3.3478)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:14:31 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [16/300][60/109]\teta 0:00:49 lr 0.000104\t wd 0.0500\ttime 0.9134 (1.0056)\tloss 0.8781 (0.9408)\tgrad_norm 3.9259 (3.3112)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:14:40 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [16/300][70/109]\teta 0:00:38 lr 0.000105\t wd 0.0500\ttime 0.9157 (0.9971)\tloss 0.8734 (0.9403)\tgrad_norm 2.8248 (3.2970)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:14:50 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [16/300][80/109]\teta 0:00:28 lr 0.000105\t wd 0.0500\ttime 0.9193 (0.9907)\tloss 0.9337 (0.9381)\tgrad_norm 3.4677 (3.2683)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:14:59 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [16/300][90/109]\teta 0:00:18 lr 0.000106\t wd 0.0500\ttime 0.9112 (0.9853)\tloss 0.9004 (0.9385)\tgrad_norm 4.5060 (3.2783)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:15:09 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [16/300][100/109]\teta 0:00:08 lr 0.000107\t wd 0.0500\ttime 0.9170 (0.9813)\tloss 0.8647 (0.9342)\tgrad_norm 2.0702 (3.2687)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:15:16 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 16 training takes 0:01:46\n",
            "\u001b[32m[2023-03-27 07:15:16 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_16.pth saving......\n",
            "\u001b[32m[2023-03-27 07:15:20 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_16.pth saved !!!\n",
            "\u001b[32m[2023-03-27 07:15:22 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 1.845 (1.845)\tLoss 1.8096 (1.8096)\tAcc@1 28.125 (28.125)\tAcc@5 98.438 (98.438)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:15:25 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.322 (0.466)\tLoss 0.4326 (1.3875)\tAcc@1 95.312 (48.295)\tAcc@5 100.000 (99.148)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:15:29 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.325 (0.399)\tLoss 0.4534 (0.9217)\tAcc@1 95.312 (70.238)\tAcc@5 100.000 (99.554)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:15:32 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.327 (0.375)\tLoss 0.3901 (0.7673)\tAcc@1 95.312 (77.319)\tAcc@5 100.000 (99.698)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:15:32 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 77.307 Acc@5 99.551\n",
            "\u001b[32m[2023-03-27 07:15:32 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 77.3%\n",
            "\u001b[32m[2023-03-27 07:15:32 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 77.31%\n",
            "\u001b[32m[2023-03-27 07:15:36 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [17/300][0/109]\teta 0:05:36 lr 0.000107\t wd 0.0500\ttime 3.0856 (3.0856)\tloss 0.9028 (0.9028)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:15:45 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [17/300][10/109]\teta 0:01:54 lr 0.000108\t wd 0.0500\ttime 0.9375 (1.1559)\tloss 0.9378 (0.9188)\tgrad_norm 3.2060 (3.2916)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:15:55 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [17/300][20/109]\teta 0:01:34 lr 0.000108\t wd 0.0500\ttime 0.9282 (1.0631)\tloss 0.9216 (0.9194)\tgrad_norm 3.9567 (3.3341)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:16:04 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [17/300][30/109]\teta 0:01:21 lr 0.000109\t wd 0.0500\ttime 0.9210 (1.0283)\tloss 1.0313 (0.9266)\tgrad_norm 4.5850 (3.3263)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:16:14 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [17/300][40/109]\teta 0:01:09 lr 0.000110\t wd 0.0500\ttime 0.9231 (1.0086)\tloss 1.0119 (0.9261)\tgrad_norm 3.6995 (3.4571)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:16:23 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [17/300][50/109]\teta 0:00:58 lr 0.000110\t wd 0.0500\ttime 0.9082 (0.9958)\tloss 1.0277 (0.9295)\tgrad_norm 4.1621 (3.4910)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:16:33 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [17/300][60/109]\teta 0:00:48 lr 0.000111\t wd 0.0500\ttime 0.9116 (0.9870)\tloss 0.8079 (0.9309)\tgrad_norm 3.0759 (3.8279)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:16:42 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [17/300][70/109]\teta 0:00:38 lr 0.000111\t wd 0.0500\ttime 0.9079 (0.9803)\tloss 0.9090 (0.9297)\tgrad_norm 3.5262 (3.7573)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:16:51 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [17/300][80/109]\teta 0:00:28 lr 0.000112\t wd 0.0500\ttime 0.9133 (0.9759)\tloss 0.9782 (0.9307)\tgrad_norm 4.4994 (3.8100)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:17:01 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [17/300][90/109]\teta 0:00:18 lr 0.000112\t wd 0.0500\ttime 0.9204 (0.9727)\tloss 0.9603 (0.9284)\tgrad_norm 3.0715 (3.7042)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:17:10 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [17/300][100/109]\teta 0:00:08 lr 0.000113\t wd 0.0500\ttime 0.9201 (0.9700)\tloss 0.9840 (0.9299)\tgrad_norm 3.3293 (3.6650)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:17:18 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 17 training takes 0:01:45\n",
            "\u001b[32m[2023-03-27 07:17:18 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_17.pth saving......\n",
            "\u001b[32m[2023-03-27 07:17:22 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_17.pth saved !!!\n",
            "\u001b[32m[2023-03-27 07:17:24 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 1.822 (1.822)\tLoss 2.4219 (2.4219)\tAcc@1 9.375 (9.375)\tAcc@5 95.312 (95.312)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:17:27 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.328 (0.484)\tLoss 0.2629 (1.6309)\tAcc@1 98.438 (38.210)\tAcc@5 100.000 (98.580)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:17:31 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.329 (0.410)\tLoss 0.3008 (0.9776)\tAcc@1 95.312 (65.997)\tAcc@5 100.000 (99.256)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:17:34 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.327 (0.383)\tLoss 0.2944 (0.7544)\tAcc@1 90.625 (75.403)\tAcc@5 100.000 (99.496)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:17:34 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 75.362 Acc@5 99.501\n",
            "\u001b[32m[2023-03-27 07:17:34 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 75.4%\n",
            "\u001b[32m[2023-03-27 07:17:34 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 77.31%\n",
            "\u001b[32m[2023-03-27 07:17:37 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [18/300][0/109]\teta 0:04:56 lr 0.000113\t wd 0.0500\ttime 2.7181 (2.7181)\tloss 0.9877 (0.9877)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:17:47 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [18/300][10/109]\teta 0:01:51 lr 0.000114\t wd 0.0500\ttime 0.9220 (1.1262)\tloss 0.8897 (0.9381)\tgrad_norm 2.5986 (4.7120)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:17:56 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [18/300][20/109]\teta 0:01:32 lr 0.000115\t wd 0.0500\ttime 0.9306 (1.0428)\tloss 0.9367 (0.9235)\tgrad_norm 2.5405 (3.7454)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:18:06 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [18/300][30/109]\teta 0:01:20 lr 0.000115\t wd 0.0500\ttime 0.9191 (1.0133)\tloss 0.8000 (0.9193)\tgrad_norm 2.7279 (3.4715)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:18:15 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [18/300][40/109]\teta 0:01:08 lr 0.000116\t wd 0.0500\ttime 0.9129 (0.9991)\tloss 1.0174 (0.9194)\tgrad_norm 3.6414 (3.3589)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:18:25 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [18/300][50/109]\teta 0:00:58 lr 0.000116\t wd 0.0500\ttime 0.9177 (0.9887)\tloss 0.9806 (0.9278)\tgrad_norm 2.4676 (3.2117)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:18:34 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [18/300][60/109]\teta 0:00:48 lr 0.000117\t wd 0.0500\ttime 0.9146 (0.9822)\tloss 0.9984 (0.9264)\tgrad_norm 2.1348 (3.2223)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:18:43 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [18/300][70/109]\teta 0:00:38 lr 0.000117\t wd 0.0500\ttime 0.9157 (0.9767)\tloss 1.0269 (0.9316)\tgrad_norm 2.7028 (3.1665)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:18:53 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [18/300][80/109]\teta 0:00:28 lr 0.000118\t wd 0.0500\ttime 0.9109 (0.9723)\tloss 0.9529 (0.9335)\tgrad_norm 3.0302 (3.1676)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:19:02 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [18/300][90/109]\teta 0:00:18 lr 0.000119\t wd 0.0500\ttime 0.9155 (0.9694)\tloss 1.0047 (0.9320)\tgrad_norm 2.4194 (3.1338)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:19:12 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [18/300][100/109]\teta 0:00:08 lr 0.000119\t wd 0.0500\ttime 0.9158 (0.9669)\tloss 0.9795 (0.9342)\tgrad_norm 3.5300 (3.1738)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:19:20 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 18 training takes 0:01:45\n",
            "\u001b[32m[2023-03-27 07:19:20 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_18.pth saving......\n",
            "\u001b[32m[2023-03-27 07:19:23 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_18.pth saved !!!\n",
            "\u001b[32m[2023-03-27 07:19:26 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 2.954 (2.954)\tLoss 3.1055 (3.1055)\tAcc@1 0.000 (0.000)\tAcc@5 89.062 (89.062)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:19:30 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.321 (0.586)\tLoss 0.3171 (1.5828)\tAcc@1 98.438 (38.920)\tAcc@5 100.000 (98.011)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:19:33 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.322 (0.461)\tLoss 0.3506 (0.9821)\tAcc@1 98.438 (66.443)\tAcc@5 100.000 (98.958)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:19:36 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.327 (0.418)\tLoss 0.3079 (0.7799)\tAcc@1 96.875 (75.806)\tAcc@5 100.000 (99.294)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:19:37 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 75.661 Acc@5 99.302\n",
            "\u001b[32m[2023-03-27 07:19:37 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 75.7%\n",
            "\u001b[32m[2023-03-27 07:19:37 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 77.31%\n",
            "\u001b[32m[2023-03-27 07:19:41 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [19/300][0/109]\teta 0:08:06 lr 0.000120\t wd 0.0500\ttime 4.4674 (4.4674)\tloss 0.9990 (0.9990)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:19:51 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [19/300][10/109]\teta 0:02:11 lr 0.000120\t wd 0.0500\ttime 0.9223 (1.3288)\tloss 0.8665 (0.9398)\tgrad_norm 3.4143 (3.7002)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:20:01 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [19/300][20/109]\teta 0:01:42 lr 0.000121\t wd 0.0500\ttime 0.9306 (1.1526)\tloss 0.9030 (0.9600)\tgrad_norm 3.3626 (3.5055)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:20:10 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [19/300][30/109]\teta 0:01:26 lr 0.000122\t wd 0.0500\ttime 0.9267 (1.0889)\tloss 1.0035 (0.9629)\tgrad_norm 5.6505 (3.5826)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:20:20 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [19/300][40/109]\teta 0:01:12 lr 0.000122\t wd 0.0500\ttime 0.9203 (1.0556)\tloss 0.8170 (0.9539)\tgrad_norm 2.5571 (3.3321)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:20:29 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [19/300][50/109]\teta 0:01:01 lr 0.000123\t wd 0.0500\ttime 0.9189 (1.0352)\tloss 1.0118 (0.9530)\tgrad_norm 2.5284 (3.3080)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:20:39 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [19/300][60/109]\teta 0:00:49 lr 0.000123\t wd 0.0500\ttime 0.9215 (1.0202)\tloss 0.9897 (0.9493)\tgrad_norm 1.9291 (3.2222)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:20:48 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [19/300][70/109]\teta 0:00:39 lr 0.000124\t wd 0.0500\ttime 0.9141 (1.0093)\tloss 0.9700 (0.9504)\tgrad_norm 2.7766 (3.1407)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:20:58 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [19/300][80/109]\teta 0:00:29 lr 0.000124\t wd 0.0500\ttime 0.9076 (1.0009)\tloss 1.0412 (0.9487)\tgrad_norm 3.5248 (3.1526)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:21:07 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [19/300][90/109]\teta 0:00:18 lr 0.000125\t wd 0.0500\ttime 0.9134 (0.9942)\tloss 0.8903 (0.9473)\tgrad_norm 2.6691 (3.1069)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:21:17 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [19/300][100/109]\teta 0:00:08 lr 0.000125\t wd 0.0500\ttime 0.9141 (0.9892)\tloss 0.9223 (0.9461)\tgrad_norm 2.5774 (3.0666)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:21:24 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 19 training takes 0:01:47\n",
            "\u001b[32m[2023-03-27 07:21:24 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_19.pth saving......\n",
            "\u001b[32m[2023-03-27 07:21:28 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_19.pth saved !!!\n",
            "\u001b[32m[2023-03-27 07:21:30 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 1.474 (1.474)\tLoss 2.0215 (2.0215)\tAcc@1 17.188 (17.188)\tAcc@5 98.438 (98.438)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:21:33 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.327 (0.472)\tLoss 0.3340 (1.4644)\tAcc@1 100.000 (42.188)\tAcc@5 100.000 (98.580)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:21:37 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.327 (0.403)\tLoss 0.3711 (0.9297)\tAcc@1 96.875 (68.155)\tAcc@5 100.000 (99.256)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:21:40 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.329 (0.379)\tLoss 0.3228 (0.7492)\tAcc@1 93.750 (76.764)\tAcc@5 100.000 (99.496)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:21:40 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 76.758 Acc@5 99.501\n",
            "\u001b[32m[2023-03-27 07:21:40 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 76.8%\n",
            "\u001b[32m[2023-03-27 07:21:40 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 77.31%\n",
            "\u001b[32m[2023-03-27 07:21:43 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [20/300][0/109]\teta 0:05:04 lr 0.000125\t wd 0.0500\ttime 2.7918 (2.7918)\tloss 0.9574 (0.9574)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:21:53 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [20/300][10/109]\teta 0:01:51 lr 0.000125\t wd 0.0500\ttime 0.9286 (1.1286)\tloss 1.0744 (0.9767)\tgrad_norm 3.7994 (3.1048)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:22:02 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [20/300][20/109]\teta 0:01:32 lr 0.000125\t wd 0.0500\ttime 0.9241 (1.0447)\tloss 0.9214 (0.9452)\tgrad_norm 4.5440 (3.1748)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:22:12 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [20/300][30/109]\teta 0:01:20 lr 0.000125\t wd 0.0500\ttime 0.9222 (1.0151)\tloss 0.8089 (0.9270)\tgrad_norm 2.5805 (3.1761)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:22:21 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [20/300][40/109]\teta 0:01:08 lr 0.000125\t wd 0.0500\ttime 0.9270 (0.9991)\tloss 0.8791 (0.9295)\tgrad_norm 3.9988 (3.2256)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:22:31 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [20/300][50/109]\teta 0:00:58 lr 0.000125\t wd 0.0500\ttime 0.9149 (0.9891)\tloss 0.9585 (0.9269)\tgrad_norm 3.6705 (3.2204)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:22:40 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [20/300][60/109]\teta 0:00:48 lr 0.000125\t wd 0.0500\ttime 0.9103 (0.9817)\tloss 0.9128 (0.9231)\tgrad_norm 2.8465 (3.3429)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:22:50 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [20/300][70/109]\teta 0:00:38 lr 0.000125\t wd 0.0500\ttime 0.9106 (0.9759)\tloss 0.9218 (0.9232)\tgrad_norm 4.1922 (3.3488)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:22:59 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [20/300][80/109]\teta 0:00:28 lr 0.000125\t wd 0.0500\ttime 0.9105 (0.9720)\tloss 0.9389 (0.9206)\tgrad_norm 2.7761 (3.3325)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:23:08 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [20/300][90/109]\teta 0:00:18 lr 0.000125\t wd 0.0500\ttime 0.9189 (0.9692)\tloss 0.9733 (0.9227)\tgrad_norm 3.4221 (3.2776)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:23:18 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [20/300][100/109]\teta 0:00:08 lr 0.000125\t wd 0.0500\ttime 0.9203 (0.9667)\tloss 0.8728 (0.9226)\tgrad_norm 3.3821 (3.2438)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:23:26 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 20 training takes 0:01:45\n",
            "\u001b[32m[2023-03-27 07:23:26 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_20.pth saving......\n",
            "\u001b[32m[2023-03-27 07:23:29 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_20.pth saved !!!\n",
            "\u001b[32m[2023-03-27 07:23:32 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 2.334 (2.334)\tLoss 2.3984 (2.3984)\tAcc@1 10.938 (10.938)\tAcc@5 98.438 (98.438)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:23:35 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.324 (0.510)\tLoss 0.2883 (1.4913)\tAcc@1 96.875 (42.756)\tAcc@5 100.000 (98.722)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:23:38 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.326 (0.423)\tLoss 0.3181 (0.9217)\tAcc@1 96.875 (68.601)\tAcc@5 100.000 (99.330)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:23:42 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.327 (0.392)\tLoss 0.2883 (0.7272)\tAcc@1 92.188 (76.815)\tAcc@5 100.000 (99.546)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:23:42 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 76.808 Acc@5 99.501\n",
            "\u001b[32m[2023-03-27 07:23:42 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 76.8%\n",
            "\u001b[32m[2023-03-27 07:23:42 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 77.31%\n",
            "\u001b[32m[2023-03-27 07:23:45 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [21/300][0/109]\teta 0:05:39 lr 0.000125\t wd 0.0500\ttime 3.1111 (3.1111)\tloss 0.9216 (0.9216)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:23:55 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [21/300][10/109]\teta 0:01:53 lr 0.000125\t wd 0.0500\ttime 0.9222 (1.1503)\tloss 1.0120 (0.9220)\tgrad_norm 3.1604 (3.2141)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:24:04 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [21/300][20/109]\teta 0:01:34 lr 0.000125\t wd 0.0500\ttime 0.9254 (1.0575)\tloss 0.9041 (0.9136)\tgrad_norm 3.7161 (3.9304)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:24:14 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [21/300][30/109]\teta 0:01:20 lr 0.000125\t wd 0.0500\ttime 0.9223 (1.0246)\tloss 1.0232 (0.9271)\tgrad_norm 2.7469 (3.7327)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:24:23 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [21/300][40/109]\teta 0:01:09 lr 0.000125\t wd 0.0500\ttime 0.9201 (1.0060)\tloss 0.9331 (0.9329)\tgrad_norm 3.0493 (3.5807)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:24:33 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [21/300][50/109]\teta 0:00:58 lr 0.000125\t wd 0.0500\ttime 0.9134 (0.9933)\tloss 0.7829 (0.9344)\tgrad_norm 2.3097 (3.4966)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:24:42 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [21/300][60/109]\teta 0:00:48 lr 0.000125\t wd 0.0500\ttime 0.9167 (0.9852)\tloss 0.8411 (0.9384)\tgrad_norm 2.5359 (3.3159)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:24:51 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [21/300][70/109]\teta 0:00:38 lr 0.000125\t wd 0.0500\ttime 0.9161 (0.9796)\tloss 0.8855 (0.9352)\tgrad_norm 3.2035 (3.2701)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:25:01 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [21/300][80/109]\teta 0:00:28 lr 0.000125\t wd 0.0500\ttime 0.9183 (0.9756)\tloss 0.8466 (0.9323)\tgrad_norm 3.2019 (3.1833)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:25:10 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [21/300][90/109]\teta 0:00:18 lr 0.000125\t wd 0.0500\ttime 0.9207 (0.9729)\tloss 1.0033 (0.9362)\tgrad_norm 4.1233 (3.1555)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:25:20 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [21/300][100/109]\teta 0:00:08 lr 0.000125\t wd 0.0500\ttime 0.9163 (0.9706)\tloss 0.8103 (0.9331)\tgrad_norm 3.8625 (3.1417)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:25:28 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 21 training takes 0:01:45\n",
            "\u001b[32m[2023-03-27 07:25:28 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_21.pth saving......\n",
            "\u001b[32m[2023-03-27 07:25:31 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_21.pth saved !!!\n",
            "\u001b[32m[2023-03-27 07:25:34 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 2.979 (2.979)\tLoss 1.9932 (1.9932)\tAcc@1 34.375 (34.375)\tAcc@5 96.875 (96.875)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:25:38 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.321 (0.608)\tLoss 0.4766 (1.3584)\tAcc@1 89.062 (50.426)\tAcc@5 100.000 (98.438)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:25:41 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.323 (0.473)\tLoss 0.5576 (0.9355)\tAcc@1 82.812 (68.452)\tAcc@5 100.000 (99.182)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:25:45 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.324 (0.426)\tLoss 0.4138 (0.8003)\tAcc@1 92.188 (73.639)\tAcc@5 100.000 (99.446)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:25:45 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 73.666 Acc@5 99.451\n",
            "\u001b[32m[2023-03-27 07:25:45 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 73.7%\n",
            "\u001b[32m[2023-03-27 07:25:45 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 77.31%\n",
            "\u001b[32m[2023-03-27 07:25:48 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [22/300][0/109]\teta 0:06:28 lr 0.000125\t wd 0.0500\ttime 3.5658 (3.5658)\tloss 0.9687 (0.9687)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:25:59 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [22/300][10/109]\teta 0:02:03 lr 0.000125\t wd 0.0500\ttime 0.9224 (1.2472)\tloss 0.8849 (0.9129)\tgrad_norm 4.9286 (3.0723)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:26:08 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [22/300][20/109]\teta 0:01:38 lr 0.000125\t wd 0.0500\ttime 0.9233 (1.1088)\tloss 0.9380 (0.8947)\tgrad_norm 4.9978 (3.6418)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:26:18 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [22/300][30/109]\teta 0:01:23 lr 0.000125\t wd 0.0500\ttime 0.9217 (1.0587)\tloss 0.9692 (0.9085)\tgrad_norm 2.7256 (3.5366)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:26:27 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [22/300][40/109]\teta 0:01:11 lr 0.000125\t wd 0.0500\ttime 0.9196 (1.0319)\tloss 0.9781 (0.9151)\tgrad_norm 2.9073 (3.3956)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:26:37 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [22/300][50/109]\teta 0:00:59 lr 0.000125\t wd 0.0500\ttime 0.9186 (1.0152)\tloss 0.9458 (0.9172)\tgrad_norm 2.1646 (3.2706)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:26:46 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [22/300][60/109]\teta 0:00:49 lr 0.000125\t wd 0.0500\ttime 0.9111 (1.0034)\tloss 0.8787 (0.9175)\tgrad_norm 1.9495 (3.0704)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:26:56 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [22/300][70/109]\teta 0:00:38 lr 0.000125\t wd 0.0500\ttime 0.9178 (0.9954)\tloss 0.9352 (0.9201)\tgrad_norm 2.7869 (3.0435)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:27:05 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [22/300][80/109]\teta 0:00:28 lr 0.000125\t wd 0.0500\ttime 0.9225 (0.9895)\tloss 0.9793 (0.9209)\tgrad_norm 2.5712 (3.0419)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:27:15 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [22/300][90/109]\teta 0:00:18 lr 0.000125\t wd 0.0500\ttime 0.9188 (0.9845)\tloss 0.9629 (0.9213)\tgrad_norm 2.1056 (2.9838)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:27:24 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [22/300][100/109]\teta 0:00:08 lr 0.000125\t wd 0.0500\ttime 0.9117 (0.9804)\tloss 0.9507 (0.9212)\tgrad_norm 4.0064 (3.0145)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:27:32 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 22 training takes 0:01:46\n",
            "\u001b[32m[2023-03-27 07:27:32 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_22.pth saving......\n",
            "\u001b[32m[2023-03-27 07:27:36 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_22.pth saved !!!\n",
            "\u001b[32m[2023-03-27 07:27:38 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 2.359 (2.359)\tLoss 1.6797 (1.6797)\tAcc@1 34.375 (34.375)\tAcc@5 96.875 (96.875)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:27:41 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.325 (0.511)\tLoss 0.4709 (1.2664)\tAcc@1 90.625 (53.409)\tAcc@5 100.000 (98.011)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:27:45 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.325 (0.423)\tLoss 0.5352 (0.8809)\tAcc@1 84.375 (70.610)\tAcc@5 100.000 (98.958)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:27:48 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.326 (0.392)\tLoss 0.4163 (0.7557)\tAcc@1 89.062 (76.361)\tAcc@5 100.000 (99.294)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:27:48 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 76.359 Acc@5 99.302\n",
            "\u001b[32m[2023-03-27 07:27:48 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 76.4%\n",
            "\u001b[32m[2023-03-27 07:27:48 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 77.31%\n",
            "\u001b[32m[2023-03-27 07:27:52 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [23/300][0/109]\teta 0:06:23 lr 0.000125\t wd 0.0500\ttime 3.5149 (3.5149)\tloss 0.9266 (0.9266)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:28:01 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [23/300][10/109]\teta 0:01:57 lr 0.000125\t wd 0.0500\ttime 0.9277 (1.1897)\tloss 0.9032 (0.9411)\tgrad_norm 2.2728 (2.5716)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:28:11 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [23/300][20/109]\teta 0:01:35 lr 0.000125\t wd 0.0500\ttime 0.9255 (1.0773)\tloss 0.9275 (0.9333)\tgrad_norm 2.5473 (2.6040)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:28:20 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [23/300][30/109]\teta 0:01:21 lr 0.000125\t wd 0.0500\ttime 0.9214 (1.0373)\tloss 1.0240 (0.9506)\tgrad_norm 3.6658 (2.7032)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:28:30 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [23/300][40/109]\teta 0:01:10 lr 0.000125\t wd 0.0500\ttime 0.9323 (1.0163)\tloss 0.9839 (0.9388)\tgrad_norm 2.3852 (2.6205)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:28:39 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [23/300][50/109]\teta 0:00:59 lr 0.000125\t wd 0.0500\ttime 0.9176 (1.0036)\tloss 0.8957 (0.9381)\tgrad_norm 2.5556 (2.6115)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:28:49 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [23/300][60/109]\teta 0:00:48 lr 0.000125\t wd 0.0500\ttime 0.9103 (0.9941)\tloss 0.9374 (0.9356)\tgrad_norm 2.2657 (2.5431)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:28:58 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [23/300][70/109]\teta 0:00:38 lr 0.000125\t wd 0.0500\ttime 0.9060 (0.9863)\tloss 0.8730 (0.9345)\tgrad_norm 2.6641 (2.5401)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:29:08 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [23/300][80/109]\teta 0:00:28 lr 0.000125\t wd 0.0500\ttime 0.9060 (0.9808)\tloss 0.8808 (0.9339)\tgrad_norm 2.3848 (2.6364)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:29:17 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [23/300][90/109]\teta 0:00:18 lr 0.000125\t wd 0.0500\ttime 0.9175 (0.9767)\tloss 1.0406 (0.9345)\tgrad_norm 2.7511 (2.6610)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:29:27 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [23/300][100/109]\teta 0:00:08 lr 0.000125\t wd 0.0500\ttime 0.9206 (0.9735)\tloss 0.9308 (0.9350)\tgrad_norm 2.7212 (2.6837)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:29:34 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 23 training takes 0:01:46\n",
            "\u001b[32m[2023-03-27 07:29:34 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_23.pth saving......\n",
            "\u001b[32m[2023-03-27 07:29:38 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_23.pth saved !!!\n",
            "\u001b[32m[2023-03-27 07:29:39 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 1.302 (1.302)\tLoss 1.9717 (1.9717)\tAcc@1 29.688 (29.688)\tAcc@5 96.875 (96.875)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:29:44 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.330 (0.503)\tLoss 0.3345 (1.4513)\tAcc@1 95.312 (42.898)\tAcc@5 100.000 (98.295)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:29:47 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.323 (0.420)\tLoss 0.3835 (0.9184)\tAcc@1 92.188 (67.783)\tAcc@5 100.000 (99.107)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:29:50 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.328 (0.390)\tLoss 0.3220 (0.7412)\tAcc@1 95.312 (76.159)\tAcc@5 100.000 (99.395)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:29:50 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 76.160 Acc@5 99.401\n",
            "\u001b[32m[2023-03-27 07:29:50 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 76.2%\n",
            "\u001b[32m[2023-03-27 07:29:50 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 77.31%\n",
            "\u001b[32m[2023-03-27 07:29:53 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [24/300][0/109]\teta 0:05:24 lr 0.000125\t wd 0.0500\ttime 2.9807 (2.9807)\tloss 0.9530 (0.9530)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:30:03 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [24/300][10/109]\teta 0:01:53 lr 0.000125\t wd 0.0500\ttime 0.9216 (1.1474)\tloss 1.0006 (0.9257)\tgrad_norm 2.7932 (2.6049)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:30:13 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [24/300][20/109]\teta 0:01:33 lr 0.000125\t wd 0.0500\ttime 0.9254 (1.0543)\tloss 0.8928 (0.9132)\tgrad_norm 2.5406 (2.4988)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:30:22 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [24/300][30/109]\teta 0:01:20 lr 0.000125\t wd 0.0500\ttime 0.9251 (1.0208)\tloss 0.9782 (0.9312)\tgrad_norm 2.6923 (2.6191)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:30:32 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [24/300][40/109]\teta 0:01:09 lr 0.000125\t wd 0.0500\ttime 0.9238 (1.0038)\tloss 0.9282 (0.9277)\tgrad_norm 3.5588 (2.7683)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:30:41 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [24/300][50/109]\teta 0:00:58 lr 0.000125\t wd 0.0500\ttime 0.9122 (0.9918)\tloss 0.9355 (0.9335)\tgrad_norm 3.2888 (2.7746)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:30:50 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [24/300][60/109]\teta 0:00:48 lr 0.000125\t wd 0.0500\ttime 0.9090 (0.9838)\tloss 0.9289 (0.9350)\tgrad_norm 2.3964 (2.7778)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:31:00 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [24/300][70/109]\teta 0:00:38 lr 0.000125\t wd 0.0500\ttime 0.9183 (0.9778)\tloss 1.0094 (0.9413)\tgrad_norm 2.6814 (2.8095)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:31:09 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [24/300][80/109]\teta 0:00:28 lr 0.000125\t wd 0.0500\ttime 0.9159 (0.9734)\tloss 0.8475 (0.9409)\tgrad_norm 2.6068 (2.8338)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:31:19 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [24/300][90/109]\teta 0:00:18 lr 0.000125\t wd 0.0500\ttime 0.9231 (0.9707)\tloss 0.9206 (0.9405)\tgrad_norm 2.3934 (2.8232)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:31:28 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [24/300][100/109]\teta 0:00:08 lr 0.000125\t wd 0.0500\ttime 0.9205 (0.9685)\tloss 0.7790 (0.9374)\tgrad_norm 2.5064 (2.8038)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:31:36 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 24 training takes 0:01:45\n",
            "\u001b[32m[2023-03-27 07:31:36 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_24.pth saving......\n",
            "\u001b[32m[2023-03-27 07:31:40 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_24.pth saved !!!\n",
            "\u001b[32m[2023-03-27 07:31:41 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 1.523 (1.523)\tLoss 1.7812 (1.7812)\tAcc@1 37.500 (37.500)\tAcc@5 98.438 (98.438)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:31:46 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.371 (0.531)\tLoss 0.3940 (1.4134)\tAcc@1 92.188 (44.460)\tAcc@5 100.000 (97.727)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:31:49 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.324 (0.434)\tLoss 0.4502 (0.9212)\tAcc@1 93.750 (68.452)\tAcc@5 100.000 (98.810)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:31:52 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.326 (0.399)\tLoss 0.3879 (0.7594)\tAcc@1 95.312 (76.411)\tAcc@5 100.000 (99.194)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:31:52 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 76.309 Acc@5 99.052\n",
            "\u001b[32m[2023-03-27 07:31:52 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 76.3%\n",
            "\u001b[32m[2023-03-27 07:31:52 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 77.31%\n",
            "\u001b[32m[2023-03-27 07:31:55 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [25/300][0/109]\teta 0:05:08 lr 0.000125\t wd 0.0500\ttime 2.8258 (2.8258)\tloss 0.9126 (0.9126)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:32:05 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [25/300][10/109]\teta 0:01:53 lr 0.000125\t wd 0.0500\ttime 0.9180 (1.1439)\tloss 0.7604 (0.9089)\tgrad_norm 2.8192 (2.7606)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:32:15 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [25/300][20/109]\teta 0:01:33 lr 0.000125\t wd 0.0500\ttime 0.9318 (1.0539)\tloss 0.9759 (0.9118)\tgrad_norm 2.9564 (3.1002)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:32:24 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [25/300][30/109]\teta 0:01:20 lr 0.000125\t wd 0.0500\ttime 0.9198 (1.0214)\tloss 0.9779 (0.9247)\tgrad_norm 2.9715 (3.2684)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:32:34 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [25/300][40/109]\teta 0:01:09 lr 0.000125\t wd 0.0500\ttime 0.9194 (1.0043)\tloss 0.9421 (0.9168)\tgrad_norm 2.3038 (3.1099)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:32:43 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [25/300][50/109]\teta 0:00:58 lr 0.000125\t wd 0.0500\ttime 0.9145 (0.9922)\tloss 0.9197 (0.9140)\tgrad_norm 1.8733 (2.9323)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:32:53 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [25/300][60/109]\teta 0:00:48 lr 0.000125\t wd 0.0500\ttime 0.9122 (0.9843)\tloss 0.8799 (0.9169)\tgrad_norm 4.2809 (2.9687)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:33:02 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [25/300][70/109]\teta 0:00:38 lr 0.000125\t wd 0.0500\ttime 0.9106 (0.9784)\tloss 0.8901 (0.9154)\tgrad_norm 2.6796 (3.0100)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:33:11 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [25/300][80/109]\teta 0:00:28 lr 0.000125\t wd 0.0500\ttime 0.9177 (0.9740)\tloss 0.9766 (0.9164)\tgrad_norm 2.7258 (2.9556)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:33:21 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [25/300][90/109]\teta 0:00:18 lr 0.000125\t wd 0.0500\ttime 0.9120 (0.9711)\tloss 0.9603 (0.9184)\tgrad_norm 2.3610 (2.9539)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:33:30 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [25/300][100/109]\teta 0:00:08 lr 0.000125\t wd 0.0500\ttime 0.9172 (0.9686)\tloss 0.9502 (0.9179)\tgrad_norm 2.4556 (2.8980)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:33:38 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 25 training takes 0:01:45\n",
            "\u001b[32m[2023-03-27 07:33:38 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_25.pth saving......\n",
            "\u001b[32m[2023-03-27 07:33:42 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_25.pth saved !!!\n",
            "\u001b[32m[2023-03-27 07:33:45 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 2.671 (2.671)\tLoss 1.4434 (1.4434)\tAcc@1 50.000 (50.000)\tAcc@5 98.438 (98.438)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:33:48 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.327 (0.564)\tLoss 0.3411 (1.3230)\tAcc@1 95.312 (48.153)\tAcc@5 100.000 (98.438)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:33:51 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.328 (0.451)\tLoss 0.3762 (0.8512)\tAcc@1 95.312 (70.685)\tAcc@5 100.000 (99.182)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:33:55 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.327 (0.412)\tLoss 0.3032 (0.6934)\tAcc@1 96.875 (78.175)\tAcc@5 100.000 (99.446)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:33:55 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 78.204 Acc@5 99.352\n",
            "\u001b[32m[2023-03-27 07:33:55 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 78.2%\n",
            "\u001b[32m[2023-03-27 07:33:55 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 78.20%\n",
            "\u001b[32m[2023-03-27 07:34:00 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [26/300][0/109]\teta 0:08:15 lr 0.000125\t wd 0.0500\ttime 4.5439 (4.5439)\tloss 0.9133 (0.9133)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:34:09 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [26/300][10/109]\teta 0:02:07 lr 0.000125\t wd 0.0500\ttime 0.9230 (1.2835)\tloss 0.9311 (0.9041)\tgrad_norm 6.6445 (3.3340)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:34:19 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [26/300][20/109]\teta 0:01:40 lr 0.000125\t wd 0.0500\ttime 0.9273 (1.1260)\tloss 0.8546 (0.8900)\tgrad_norm 2.4868 (3.2911)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:34:28 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [26/300][30/109]\teta 0:01:24 lr 0.000125\t wd 0.0500\ttime 0.9272 (1.0703)\tloss 0.8945 (0.8820)\tgrad_norm 3.5061 (3.4338)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:34:38 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [26/300][40/109]\teta 0:01:11 lr 0.000125\t wd 0.0500\ttime 0.9192 (1.0406)\tloss 0.9190 (0.8898)\tgrad_norm 2.6685 (3.5365)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:34:47 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [26/300][50/109]\teta 0:01:00 lr 0.000125\t wd 0.0500\ttime 0.9174 (1.0223)\tloss 0.9171 (0.8960)\tgrad_norm 4.4616 (3.7082)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:34:57 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [26/300][60/109]\teta 0:00:49 lr 0.000125\t wd 0.0500\ttime 0.9176 (1.0095)\tloss 0.9395 (0.9010)\tgrad_norm 3.3311 (3.6897)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:35:06 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [26/300][70/109]\teta 0:00:39 lr 0.000125\t wd 0.0500\ttime 0.9131 (1.0002)\tloss 0.8776 (0.9086)\tgrad_norm 2.9901 (3.6319)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:35:16 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [26/300][80/109]\teta 0:00:28 lr 0.000125\t wd 0.0500\ttime 0.9155 (0.9936)\tloss 0.9306 (0.9135)\tgrad_norm 2.8721 (3.5720)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:35:25 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [26/300][90/109]\teta 0:00:18 lr 0.000125\t wd 0.0500\ttime 0.9189 (0.9885)\tloss 0.7681 (0.9120)\tgrad_norm 2.1348 (3.5023)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:35:35 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [26/300][100/109]\teta 0:00:08 lr 0.000125\t wd 0.0500\ttime 0.9180 (0.9846)\tloss 0.9552 (0.9124)\tgrad_norm 1.9833 (3.4057)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:35:42 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 26 training takes 0:01:47\n",
            "\u001b[32m[2023-03-27 07:35:43 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_26.pth saving......\n",
            "\u001b[32m[2023-03-27 07:35:46 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_26.pth saved !!!\n",
            "\u001b[32m[2023-03-27 07:35:48 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 1.967 (1.967)\tLoss 2.2031 (2.2031)\tAcc@1 20.312 (20.312)\tAcc@5 95.312 (95.312)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:35:52 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.325 (0.476)\tLoss 0.3442 (1.3625)\tAcc@1 95.312 (49.858)\tAcc@5 100.000 (98.722)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:35:55 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.325 (0.404)\tLoss 0.4089 (0.8789)\tAcc@1 95.312 (71.131)\tAcc@5 100.000 (99.330)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:35:58 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.325 (0.379)\tLoss 0.3442 (0.7230)\tAcc@1 95.312 (78.075)\tAcc@5 100.000 (99.546)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:35:58 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 77.955 Acc@5 99.501\n",
            "\u001b[32m[2023-03-27 07:35:58 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 78.0%\n",
            "\u001b[32m[2023-03-27 07:35:58 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 78.20%\n",
            "\u001b[32m[2023-03-27 07:36:02 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [27/300][0/109]\teta 0:06:34 lr 0.000125\t wd 0.0500\ttime 3.6157 (3.6157)\tloss 0.9363 (0.9363)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:36:11 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [27/300][10/109]\teta 0:01:57 lr 0.000125\t wd 0.0500\ttime 0.9261 (1.1884)\tloss 0.8611 (0.8943)\tgrad_norm 3.6467 (3.5786)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:36:21 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [27/300][20/109]\teta 0:01:35 lr 0.000125\t wd 0.0500\ttime 0.9234 (1.0762)\tloss 0.8726 (0.9243)\tgrad_norm 3.1054 (3.3891)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:36:31 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [27/300][30/109]\teta 0:01:21 lr 0.000125\t wd 0.0500\ttime 0.9253 (1.0365)\tloss 0.9972 (0.9288)\tgrad_norm 2.5752 (3.0890)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:36:40 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [27/300][40/109]\teta 0:01:10 lr 0.000125\t wd 0.0500\ttime 0.9201 (1.0147)\tloss 1.1057 (0.9287)\tgrad_norm 3.1485 (2.9794)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:36:49 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [27/300][50/109]\teta 0:00:59 lr 0.000125\t wd 0.0500\ttime 0.9137 (1.0013)\tloss 0.9231 (0.9287)\tgrad_norm 2.8016 (2.9980)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:36:59 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [27/300][60/109]\teta 0:00:48 lr 0.000125\t wd 0.0500\ttime 0.9119 (0.9923)\tloss 0.9641 (0.9284)\tgrad_norm 3.5782 (3.0825)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:37:08 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [27/300][70/109]\teta 0:00:38 lr 0.000125\t wd 0.0500\ttime 0.9161 (0.9852)\tloss 0.8540 (0.9269)\tgrad_norm 2.9114 (3.0511)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:37:18 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [27/300][80/109]\teta 0:00:28 lr 0.000125\t wd 0.0500\ttime 0.9118 (0.9799)\tloss 0.8097 (0.9227)\tgrad_norm 2.2290 (2.9748)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:37:27 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [27/300][90/109]\teta 0:00:18 lr 0.000125\t wd 0.0500\ttime 0.9226 (0.9763)\tloss 0.9717 (0.9207)\tgrad_norm 2.6217 (2.9428)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:37:37 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [27/300][100/109]\teta 0:00:08 lr 0.000125\t wd 0.0500\ttime 0.9154 (0.9731)\tloss 1.0197 (0.9219)\tgrad_norm 3.7737 (2.9799)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "\u001b[32m[2023-03-27 07:37:44 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 225)\u001b[0m: INFO EPOCH 27 training takes 0:01:46\n",
            "\u001b[32m[2023-03-27 07:37:44 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 141)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_27.pth saving......\n",
            "\u001b[32m[2023-03-27 07:37:48 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(utils.py 143)\u001b[0m: INFO output/swin_base_patch4_window7_224/default/ckpt_epoch_27.pth saved !!!\n",
            "\u001b[32m[2023-03-27 07:37:50 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [0/32]\tTime 1.828 (1.828)\tLoss 1.4590 (1.4590)\tAcc@1 51.562 (51.562)\tAcc@5 98.438 (98.438)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:37:53 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [10/32]\tTime 0.328 (0.469)\tLoss 0.2496 (1.5045)\tAcc@1 96.875 (40.767)\tAcc@5 100.000 (98.153)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:37:57 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [20/32]\tTime 0.327 (0.402)\tLoss 0.2690 (0.9077)\tAcc@1 96.875 (67.932)\tAcc@5 100.000 (99.033)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:38:00 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 265)\u001b[0m: INFO Test: [30/32]\tTime 0.327 (0.378)\tLoss 0.2590 (0.7066)\tAcc@1 96.875 (76.865)\tAcc@5 100.000 (99.345)\tMem 11003MB\n",
            "\u001b[32m[2023-03-27 07:38:00 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 272)\u001b[0m: INFO  * Acc@1 76.908 Acc@5 99.352\n",
            "\u001b[32m[2023-03-27 07:38:00 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 159)\u001b[0m: INFO Accuracy of the network on the 2005 test images: 76.9%\n",
            "\u001b[32m[2023-03-27 07:38:00 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 161)\u001b[0m: INFO Max accuracy: 78.20%\n",
            "\u001b[32m[2023-03-27 07:38:03 swin_base_patch4_window7_224]\u001b[0m\u001b[33m(main.py 216)\u001b[0m: INFO Train: [28/300][0/109]\teta 0:05:09 lr 0.000125\t wd 0.0500\ttime 2.8388 (2.8388)\tloss 0.9720 (0.9720)\tgrad_norm 0.0000 (0.0000)\tloss_scale 16384.0000 (16384.0000)\tmem 11003MB\n",
            "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3060 closing signal SIGTERM\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 709, in run\n",
            "    result = self._invoke_run(role)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 850, in _invoke_run\n",
            "    time.sleep(monitor_interval)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 62, in _terminate_process_handler\n",
            "    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\n",
            "torch.distributed.elastic.multiprocessing.api.SignalException: Process 3048 got signal: 2\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/launch.py\", line 195, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/launch.py\", line 191, in main\n",
            "    launch(args)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/launch.py\", line 176, in launch\n",
            "    run(args)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 753, in run\n",
            "    elastic_launch(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/launcher/api.py\", line 132, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/launcher/api.py\", line 237, in launch_agent\n",
            "    result = agent.run()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/elastic/metrics/api.py\", line 129, in wrapper\n",
            "    result = f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 715, in run\n",
            "    log.warning(f\"Received {e.sigval} death signal, shutting down workers\")\n",
            "  File \"/usr/lib/python3.9/logging/__init__.py\", line 1458, in warning\n",
            "    self._log(WARNING, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.9/logging/__init__.py\", line 1587, in _log\n",
            "    record = self.makeRecord(self.name, level, fn, lno, msg, args,\n",
            "  File \"/usr/lib/python3.9/logging/__init__.py\", line 1556, in makeRecord\n",
            "    rv = _logRecordFactory(name, level, fn, lno, msg, args, exc_info, func,\n",
            "  File \"/usr/lib/python3.9/logging/__init__.py\", line 289, in __init__\n",
            "    self.msg = msg\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 62, in _terminate_process_handler\n",
            "    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\n",
            "torch.distributed.elastic.multiprocessing.api.SignalException: Process 3048 got signal: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "%cp -r Swin-Transformer/output drive/MyDrive/Swin-Transformer/output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfRNPLsR9ztd",
        "outputId": "144a213f-06bc-4d6a-dd5b-fdf17dd42517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    }
  ]
}
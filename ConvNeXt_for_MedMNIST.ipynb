{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yulinlina/MedMnist/blob/main/ConvNeXt_for_MedMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LniKjqdogsrH"
      },
      "source": [
        "Use this notebook to finetune a ConvNeXt-tiny model on CIFAR 10 dataset. The [official ConvNeXt repository](https://github.com/facebookresearch/ConvNeXt) is instrumented with [Weights and Biases](https://wandb.ai/site). You can now easily log your train/test metrics and version control your model checkpoints to Weigths and Biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JS4ffXFRnRr"
      },
      "source": [
        "# ⚽️ Installation and Setup\n",
        "\n",
        "The following installation instruction is based on [INSTALL.md](https://github.com/facebookresearch/ConvNeXt/blob/main/INSTALL.md) provided by the official ConvNeXt repository. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YbEGpKrDKC5",
        "outputId": "c3f39b2b-db75-47ce-942b-62d62d5c6320"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m893.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.8.0+cu111 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.8.0+cu111 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 KB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 KB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.1/189.1 KB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "#运行前先在\"代码执行程序\"中选择\"更改运行时类型\"为GPU\n",
        "!pip install -qq torch==1.8.0+cu111 torchvision==0.9.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install -qq wandb timm==0.3.2 six tensorboardX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDXQ-EpX9fsB"
      },
      "source": [
        "Download the official ConvNeXt respository. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmmHO1Cp4E90",
        "outputId": "257f678d-fa2a-49b4-9fe3-3cf796f55f70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ConvNeXt'...\n",
            "remote: Enumerating objects: 252, done.\u001b[K\n",
            "remote: Counting objects: 100% (249/249), done.\u001b[K\n",
            "remote: Compressing objects: 100% (117/117), done.\u001b[K\n",
            "remote: Total 252 (delta 129), reused 193 (delta 111), pack-reused 3\u001b[K\n",
            "Receiving objects: 100% (252/252), 69.37 KiB | 13.87 MiB/s, done.\n",
            "Resolving deltas: 100% (129/129), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/ConvNeXt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoVwkQ0v80KW"
      },
      "source": [
        "# 🏀 Download the Dataset\n",
        "\n",
        "We will be finetuning on CIFAR-10 dataset. To use any custom dataset (CIFAR-10 here) the format of the dataset should be as shown below:\n",
        "\n",
        "```\n",
        "/path/to/dataset/\n",
        "  train/\n",
        "    class1/\n",
        "      img1.jpeg\n",
        "    class2/\n",
        "      img2.jpeg\n",
        "  val/\n",
        "    class1/\n",
        "      img3.jpeg\n",
        "    class2/\n",
        "      img4.jpeg\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_NEEJn9XPxs"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade git+https://github.com/MedMNIST/MedMNIST.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "8fd623f5422c456892d3e2e5c8cdffff",
            "b6d51f17295f4e54b81a2f8730cebbce",
            "531ae418cce84942b290a584569b5878",
            "cfd80982fb9844e5ab035c5505c04664",
            "ce3bd591f14240e4a756f1708aaca9f0",
            "85b2fd6ef7dc4bdbb604d62c6b2df211",
            "d7c0194462fd459498157e893f811d08",
            "5daa861090304af49cecb7eb6240640b",
            "d17399043f524461853b14abc7d110a9",
            "9bc3d9f3ba8a40c1b07a5a50fdb20578",
            "d5a05c90211d4b1baac6e272d212c41a"
          ]
        },
        "id": "WVkMG91pXVOa",
        "outputId": "e9a6876e-af5f-44d7-ad1b-4c534cc3b1ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://zenodo.org/record/6496656/files/dermamnist.npz?download=1 to /root/.medmnist/dermamnist.npz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/19725078 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fd623f5422c456892d3e2e5c8cdffff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/dermamnist.npz\n",
            "Using downloaded and verified file: /root/.medmnist/dermamnist.npz\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator\n",
        "data_flag = 'dermamnist'\n",
        "# data_flag = 'breastmnist'\n",
        "download = True\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "# preprocessing\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "# load the data\n",
        "train_dataset = DataClass(split='train', transform=data_transform, download=download)\n",
        "test_dataset = DataClass(split='test', transform=data_transform, download=download)\n",
        "\n",
        "pil_dataset = DataClass(split='train', download=download)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18CQpAO5X-Lr",
        "outputId": "8eb93f96-0fb8-4b38-a62b-f00ebdfc578c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dermamnist train...\n",
            "100% 7007/7007 [00:01<00:00, 6257.47it/s]\n",
            "Saving dermamnist val...\n",
            "100% 1003/1003 [00:00<00:00, 6674.26it/s]\n",
            "Saving dermamnist test...\n",
            "100% 2005/2005 [00:00<00:00, 6371.27it/s]\n"
          ]
        }
      ],
      "source": [
        "!python -m medmnist save --flag=dermamnist --folder=MedMNIST/ --postfix=jpeg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#以下是数据集格式整理脚本，目的是把数据集变成类似CIFAR-10的格式，忽略mv: cannot stat 'val802_6.jpeg': No such file or directory等等输出即可\n",
        "%cd /content/MedMNIST/dermamnist/\n",
        "%mkdir train val test\n",
        "%cd /content/MedMNIST/dermamnist/train/\n",
        "%mkdir class1 class2 class3 class4 class5 class6 class7\n",
        "%cd /content/MedMNIST/dermamnist/test/\n",
        "%mkdir class1 class2 class3 class4 class5 class6 class7\n",
        "%cd /content/MedMNIST/dermamnist/val/\n",
        "%mkdir class1 class2 class3 class4 class5 class6 class7\n",
        "%cd /content/MedMNIST/dermamnist/\n",
        "%mv train{0..7006}_0.jpeg /content/MedMNIST/dermamnist/train/class1/\n",
        "%mv train{0..7006}_1.jpeg /content/MedMNIST/dermamnist/train/class2/\n",
        "%mv train{0..7006}_2.jpeg /content/MedMNIST/dermamnist/train/class3/\n",
        "%mv train{0..7006}_3.jpeg /content/MedMNIST/dermamnist/train/class4/\n",
        "%mv train{0..7006}_4.jpeg /content/MedMNIST/dermamnist/train/class5/\n",
        "%mv train{0..7006}_5.jpeg /content/MedMNIST/dermamnist/train/class6/\n",
        "%mv train{0..7006}_6.jpeg /content/MedMNIST/dermamnist/train/class7/\n",
        "%cd /content/MedMNIST/dermamnist/\n",
        "%mv test{0..2004}_0.jpeg /content/MedMNIST/dermamnist/test/class1/\n",
        "%mv test{0..2004}_1.jpeg /content/MedMNIST/dermamnist/test/class2/\n",
        "%mv test{0..2004}_2.jpeg /content/MedMNIST/dermamnist/test/class3/\n",
        "%mv test{0..2004}_3.jpeg /content/MedMNIST/dermamnist/test/class4/\n",
        "%mv test{0..2004}_4.jpeg /content/MedMNIST/dermamnist/test/class5/\n",
        "%mv test{0..2004}_5.jpeg /content/MedMNIST/dermamnist/test/class6/\n",
        "%mv test{0..2004}_6.jpeg /content/MedMNIST/dermamnist/test/class7/\n",
        "%cd /content/MedMNIST/dermamnist/\n",
        "%mv val{0..1002}_0.jpeg /content/MedMNIST/dermamnist/val/class1/\n",
        "%mv val{0..1002}_1.jpeg /content/MedMNIST/dermamnist/val/class2/\n",
        "%mv val{0..1002}_2.jpeg /content/MedMNIST/dermamnist/val/class3/\n",
        "%mv val{0..1002}_3.jpeg /content/MedMNIST/dermamnist/val/class4/\n",
        "%mv val{0..1002}_4.jpeg /content/MedMNIST/dermamnist/val/class5/\n",
        "%mv val{0..1002}_5.jpeg /content/MedMNIST/dermamnist/val/class6/\n",
        "%mv val{0..1002}_6.jpeg /content/MedMNIST/dermamnist/val/class7/"
      ],
      "metadata": {
        "id": "GN_gu6p1ql14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6qUVfL29tH1"
      },
      "source": [
        "# 🏈 Download Pretrained Weights\n",
        "\n",
        "We will be finetuning the ConvNeXt Tiny model pretrained on ImageNet 1K dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYPDl5bT8LZ5",
        "outputId": "74867019-1d07-4e8e-8957-61c24487cbd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ConvNeXt\n",
            "--2023-03-27 08:22:53--  https://dl.fbaipublicfiles.com/convnext/convnext_small_22k_224.pth\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 52.84.251.106, 52.84.251.27, 52.84.251.15, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|52.84.251.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 265112135 (253M) [binary/octet-stream]\n",
            "Saving to: ‘convnext_small_22k_224.pth’\n",
            "\n",
            "convnext_small_22k_ 100%[===================>] 252.83M  23.9MB/s    in 12s     \n",
            "\n",
            "2023-03-27 08:23:06 (20.7 MB/s) - ‘convnext_small_22k_224.pth’ saved [265112135/265112135]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#先检查一下/content/MedMNIST/dermamnist文件夹是否把所有图片归类到train val test\n",
        "%cd /content/ConvNeXt/\n",
        "#下面是下载预训练模型，需要用到在Imagenet-1k上预训练模型，否则效果不好(可以去掉试试)\n",
        "!wget https://dl.fbaipublicfiles.com/convnext/convnext_small_22k_224.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSPgPCjp-Lro"
      },
      "source": [
        "# 🎾 Train with Weights and Biases\n",
        "\n",
        "If you want to log the train and evaluation metrics using Weights and Biases pass `--enable_wandb true`. \n",
        "\n",
        "You can also save the finetuned checkpoints as version controlled W&B [Artifacts](https://docs.wandb.ai/guides/artifacts) if you pass `--wandb_ckpt true`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8sNl2Mb6x8_",
        "outputId": "92e700e9-ff78-4f56-95de-2a6bde5f9353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not using distributed mode\n",
            "Namespace(batch_size=64, epochs=30, update_freq=1, model='convnext_small', drop_path=0, input_size=224, layer_scale_init_value=1e-06, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, model_ema_eval=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.05, weight_decay_end=None, lr=0.0004, layer_decay=1.0, min_lr=1e-06, warmup_epochs=0, warmup_steps=-1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', crop_pct=None, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.0, cutmix=0.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='convnext_small_22k_224.pth', head_init_scale=1.0, model_key='model|module', model_prefix='', data_path='/content/MedMNIST/dermamnist/train', eval_data_path='/content/MedMNIST/dermamnist/test', nb_classes=7, imagenet_default_mean_and_std=True, data_set='image_folder', output_dir='model_ckpt', log_dir=None, device='cuda', seed=0, resume='', auto_resume=True, save_ckpt=True, save_ckpt_freq=1, save_ckpt_num=3, start_epoch=0, eval=False, dist_eval=True, disable_eval=False, num_workers=8, pin_mem=True, world_size=1, local_rank=-1, dist_on_itp=False, dist_url='env://', use_amp=False, enable_wandb=True, project='convnext', wandb_ckpt=True, distributed=False)\n",
            "Transform = \n",
            "RandomResizedCropAndInterpolation(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BICUBIC)\n",
            "RandomHorizontalFlip(p=0.5)\n",
            "<timm.data.auto_augment.RandAugment object at 0x7efc2e0ab160>\n",
            "ToTensor()\n",
            "Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
            "<timm.data.random_erasing.RandomErasing object at 0x7efc2e0ab4c0>\n",
            "---------------------------\n",
            "Number of the class = 7\n",
            "Transform = \n",
            "Resize(size=256, interpolation=bicubic)\n",
            "CenterCrop(size=(224, 224))\n",
            "ToTensor()\n",
            "Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "---------------------------\n",
            "Number of the class = 7\n",
            "Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7efc2dbecd90>\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m1768041412\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/ConvNeXt/wandb/run-20230327_082333-eu2zgjhp\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdesert-smoke-11\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/1768041412/convnext\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/1768041412/convnext/runs/eu2zgjhp\u001b[0m\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Load ckpt from convnext_small_22k_224.pth\n",
            "Load state_dict by model_key = model\n",
            "Removing key head.weight from pretrained checkpoint\n",
            "Removing key head.bias from pretrained checkpoint\n",
            "Weights of ConvNeXt not initialized from pretrained model: ['head.weight', 'head.bias']\n",
            "Model = ConvNeXt(\n",
            "  (downsample_layers): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
            "      (1): LayerNorm()\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): LayerNorm()\n",
            "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "  )\n",
            "  (stages): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (3): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (4): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (5): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (6): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (7): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (8): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (9): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (10): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (11): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (12): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (13): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (14): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (15): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (16): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (17): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (18): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (19): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (20): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (21): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (22): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (23): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (24): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (25): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (26): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
            "        (norm): LayerNorm()\n",
            "        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (act): GELU()\n",
            "        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "  (head): Linear(in_features=768, out_features=7, bias=True)\n",
            ")\n",
            "number of params: 49460071\n",
            "LR = 0.00040000\n",
            "Batch size = 64\n",
            "Update frequent = 1\n",
            "Number of training examples = 7007\n",
            "Number of training training per epoch = 109\n",
            "Param groups = {\n",
            "  \"decay\": {\n",
            "    \"weight_decay\": 0.05,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.weight\",\n",
            "      \"downsample_layers.1.1.weight\",\n",
            "      \"downsample_layers.2.1.weight\",\n",
            "      \"downsample_layers.3.1.weight\",\n",
            "      \"stages.0.0.dwconv.weight\",\n",
            "      \"stages.0.0.pwconv1.weight\",\n",
            "      \"stages.0.0.pwconv2.weight\",\n",
            "      \"stages.0.1.dwconv.weight\",\n",
            "      \"stages.0.1.pwconv1.weight\",\n",
            "      \"stages.0.1.pwconv2.weight\",\n",
            "      \"stages.0.2.dwconv.weight\",\n",
            "      \"stages.0.2.pwconv1.weight\",\n",
            "      \"stages.0.2.pwconv2.weight\",\n",
            "      \"stages.1.0.dwconv.weight\",\n",
            "      \"stages.1.0.pwconv1.weight\",\n",
            "      \"stages.1.0.pwconv2.weight\",\n",
            "      \"stages.1.1.dwconv.weight\",\n",
            "      \"stages.1.1.pwconv1.weight\",\n",
            "      \"stages.1.1.pwconv2.weight\",\n",
            "      \"stages.1.2.dwconv.weight\",\n",
            "      \"stages.1.2.pwconv1.weight\",\n",
            "      \"stages.1.2.pwconv2.weight\",\n",
            "      \"stages.2.0.dwconv.weight\",\n",
            "      \"stages.2.0.pwconv1.weight\",\n",
            "      \"stages.2.0.pwconv2.weight\",\n",
            "      \"stages.2.1.dwconv.weight\",\n",
            "      \"stages.2.1.pwconv1.weight\",\n",
            "      \"stages.2.1.pwconv2.weight\",\n",
            "      \"stages.2.2.dwconv.weight\",\n",
            "      \"stages.2.2.pwconv1.weight\",\n",
            "      \"stages.2.2.pwconv2.weight\",\n",
            "      \"stages.2.3.dwconv.weight\",\n",
            "      \"stages.2.3.pwconv1.weight\",\n",
            "      \"stages.2.3.pwconv2.weight\",\n",
            "      \"stages.2.4.dwconv.weight\",\n",
            "      \"stages.2.4.pwconv1.weight\",\n",
            "      \"stages.2.4.pwconv2.weight\",\n",
            "      \"stages.2.5.dwconv.weight\",\n",
            "      \"stages.2.5.pwconv1.weight\",\n",
            "      \"stages.2.5.pwconv2.weight\",\n",
            "      \"stages.2.6.dwconv.weight\",\n",
            "      \"stages.2.6.pwconv1.weight\",\n",
            "      \"stages.2.6.pwconv2.weight\",\n",
            "      \"stages.2.7.dwconv.weight\",\n",
            "      \"stages.2.7.pwconv1.weight\",\n",
            "      \"stages.2.7.pwconv2.weight\",\n",
            "      \"stages.2.8.dwconv.weight\",\n",
            "      \"stages.2.8.pwconv1.weight\",\n",
            "      \"stages.2.8.pwconv2.weight\",\n",
            "      \"stages.2.9.dwconv.weight\",\n",
            "      \"stages.2.9.pwconv1.weight\",\n",
            "      \"stages.2.9.pwconv2.weight\",\n",
            "      \"stages.2.10.dwconv.weight\",\n",
            "      \"stages.2.10.pwconv1.weight\",\n",
            "      \"stages.2.10.pwconv2.weight\",\n",
            "      \"stages.2.11.dwconv.weight\",\n",
            "      \"stages.2.11.pwconv1.weight\",\n",
            "      \"stages.2.11.pwconv2.weight\",\n",
            "      \"stages.2.12.dwconv.weight\",\n",
            "      \"stages.2.12.pwconv1.weight\",\n",
            "      \"stages.2.12.pwconv2.weight\",\n",
            "      \"stages.2.13.dwconv.weight\",\n",
            "      \"stages.2.13.pwconv1.weight\",\n",
            "      \"stages.2.13.pwconv2.weight\",\n",
            "      \"stages.2.14.dwconv.weight\",\n",
            "      \"stages.2.14.pwconv1.weight\",\n",
            "      \"stages.2.14.pwconv2.weight\",\n",
            "      \"stages.2.15.dwconv.weight\",\n",
            "      \"stages.2.15.pwconv1.weight\",\n",
            "      \"stages.2.15.pwconv2.weight\",\n",
            "      \"stages.2.16.dwconv.weight\",\n",
            "      \"stages.2.16.pwconv1.weight\",\n",
            "      \"stages.2.16.pwconv2.weight\",\n",
            "      \"stages.2.17.dwconv.weight\",\n",
            "      \"stages.2.17.pwconv1.weight\",\n",
            "      \"stages.2.17.pwconv2.weight\",\n",
            "      \"stages.2.18.dwconv.weight\",\n",
            "      \"stages.2.18.pwconv1.weight\",\n",
            "      \"stages.2.18.pwconv2.weight\",\n",
            "      \"stages.2.19.dwconv.weight\",\n",
            "      \"stages.2.19.pwconv1.weight\",\n",
            "      \"stages.2.19.pwconv2.weight\",\n",
            "      \"stages.2.20.dwconv.weight\",\n",
            "      \"stages.2.20.pwconv1.weight\",\n",
            "      \"stages.2.20.pwconv2.weight\",\n",
            "      \"stages.2.21.dwconv.weight\",\n",
            "      \"stages.2.21.pwconv1.weight\",\n",
            "      \"stages.2.21.pwconv2.weight\",\n",
            "      \"stages.2.22.dwconv.weight\",\n",
            "      \"stages.2.22.pwconv1.weight\",\n",
            "      \"stages.2.22.pwconv2.weight\",\n",
            "      \"stages.2.23.dwconv.weight\",\n",
            "      \"stages.2.23.pwconv1.weight\",\n",
            "      \"stages.2.23.pwconv2.weight\",\n",
            "      \"stages.2.24.dwconv.weight\",\n",
            "      \"stages.2.24.pwconv1.weight\",\n",
            "      \"stages.2.24.pwconv2.weight\",\n",
            "      \"stages.2.25.dwconv.weight\",\n",
            "      \"stages.2.25.pwconv1.weight\",\n",
            "      \"stages.2.25.pwconv2.weight\",\n",
            "      \"stages.2.26.dwconv.weight\",\n",
            "      \"stages.2.26.pwconv1.weight\",\n",
            "      \"stages.2.26.pwconv2.weight\",\n",
            "      \"stages.3.0.dwconv.weight\",\n",
            "      \"stages.3.0.pwconv1.weight\",\n",
            "      \"stages.3.0.pwconv2.weight\",\n",
            "      \"stages.3.1.dwconv.weight\",\n",
            "      \"stages.3.1.pwconv1.weight\",\n",
            "      \"stages.3.1.pwconv2.weight\",\n",
            "      \"stages.3.2.dwconv.weight\",\n",
            "      \"stages.3.2.pwconv1.weight\",\n",
            "      \"stages.3.2.pwconv2.weight\",\n",
            "      \"head.weight\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  },\n",
            "  \"no_decay\": {\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"params\": [\n",
            "      \"downsample_layers.0.0.bias\",\n",
            "      \"downsample_layers.0.1.weight\",\n",
            "      \"downsample_layers.0.1.bias\",\n",
            "      \"downsample_layers.1.0.weight\",\n",
            "      \"downsample_layers.1.0.bias\",\n",
            "      \"downsample_layers.1.1.bias\",\n",
            "      \"downsample_layers.2.0.weight\",\n",
            "      \"downsample_layers.2.0.bias\",\n",
            "      \"downsample_layers.2.1.bias\",\n",
            "      \"downsample_layers.3.0.weight\",\n",
            "      \"downsample_layers.3.0.bias\",\n",
            "      \"downsample_layers.3.1.bias\",\n",
            "      \"stages.0.0.gamma\",\n",
            "      \"stages.0.0.dwconv.bias\",\n",
            "      \"stages.0.0.norm.weight\",\n",
            "      \"stages.0.0.norm.bias\",\n",
            "      \"stages.0.0.pwconv1.bias\",\n",
            "      \"stages.0.0.pwconv2.bias\",\n",
            "      \"stages.0.1.gamma\",\n",
            "      \"stages.0.1.dwconv.bias\",\n",
            "      \"stages.0.1.norm.weight\",\n",
            "      \"stages.0.1.norm.bias\",\n",
            "      \"stages.0.1.pwconv1.bias\",\n",
            "      \"stages.0.1.pwconv2.bias\",\n",
            "      \"stages.0.2.gamma\",\n",
            "      \"stages.0.2.dwconv.bias\",\n",
            "      \"stages.0.2.norm.weight\",\n",
            "      \"stages.0.2.norm.bias\",\n",
            "      \"stages.0.2.pwconv1.bias\",\n",
            "      \"stages.0.2.pwconv2.bias\",\n",
            "      \"stages.1.0.gamma\",\n",
            "      \"stages.1.0.dwconv.bias\",\n",
            "      \"stages.1.0.norm.weight\",\n",
            "      \"stages.1.0.norm.bias\",\n",
            "      \"stages.1.0.pwconv1.bias\",\n",
            "      \"stages.1.0.pwconv2.bias\",\n",
            "      \"stages.1.1.gamma\",\n",
            "      \"stages.1.1.dwconv.bias\",\n",
            "      \"stages.1.1.norm.weight\",\n",
            "      \"stages.1.1.norm.bias\",\n",
            "      \"stages.1.1.pwconv1.bias\",\n",
            "      \"stages.1.1.pwconv2.bias\",\n",
            "      \"stages.1.2.gamma\",\n",
            "      \"stages.1.2.dwconv.bias\",\n",
            "      \"stages.1.2.norm.weight\",\n",
            "      \"stages.1.2.norm.bias\",\n",
            "      \"stages.1.2.pwconv1.bias\",\n",
            "      \"stages.1.2.pwconv2.bias\",\n",
            "      \"stages.2.0.gamma\",\n",
            "      \"stages.2.0.dwconv.bias\",\n",
            "      \"stages.2.0.norm.weight\",\n",
            "      \"stages.2.0.norm.bias\",\n",
            "      \"stages.2.0.pwconv1.bias\",\n",
            "      \"stages.2.0.pwconv2.bias\",\n",
            "      \"stages.2.1.gamma\",\n",
            "      \"stages.2.1.dwconv.bias\",\n",
            "      \"stages.2.1.norm.weight\",\n",
            "      \"stages.2.1.norm.bias\",\n",
            "      \"stages.2.1.pwconv1.bias\",\n",
            "      \"stages.2.1.pwconv2.bias\",\n",
            "      \"stages.2.2.gamma\",\n",
            "      \"stages.2.2.dwconv.bias\",\n",
            "      \"stages.2.2.norm.weight\",\n",
            "      \"stages.2.2.norm.bias\",\n",
            "      \"stages.2.2.pwconv1.bias\",\n",
            "      \"stages.2.2.pwconv2.bias\",\n",
            "      \"stages.2.3.gamma\",\n",
            "      \"stages.2.3.dwconv.bias\",\n",
            "      \"stages.2.3.norm.weight\",\n",
            "      \"stages.2.3.norm.bias\",\n",
            "      \"stages.2.3.pwconv1.bias\",\n",
            "      \"stages.2.3.pwconv2.bias\",\n",
            "      \"stages.2.4.gamma\",\n",
            "      \"stages.2.4.dwconv.bias\",\n",
            "      \"stages.2.4.norm.weight\",\n",
            "      \"stages.2.4.norm.bias\",\n",
            "      \"stages.2.4.pwconv1.bias\",\n",
            "      \"stages.2.4.pwconv2.bias\",\n",
            "      \"stages.2.5.gamma\",\n",
            "      \"stages.2.5.dwconv.bias\",\n",
            "      \"stages.2.5.norm.weight\",\n",
            "      \"stages.2.5.norm.bias\",\n",
            "      \"stages.2.5.pwconv1.bias\",\n",
            "      \"stages.2.5.pwconv2.bias\",\n",
            "      \"stages.2.6.gamma\",\n",
            "      \"stages.2.6.dwconv.bias\",\n",
            "      \"stages.2.6.norm.weight\",\n",
            "      \"stages.2.6.norm.bias\",\n",
            "      \"stages.2.6.pwconv1.bias\",\n",
            "      \"stages.2.6.pwconv2.bias\",\n",
            "      \"stages.2.7.gamma\",\n",
            "      \"stages.2.7.dwconv.bias\",\n",
            "      \"stages.2.7.norm.weight\",\n",
            "      \"stages.2.7.norm.bias\",\n",
            "      \"stages.2.7.pwconv1.bias\",\n",
            "      \"stages.2.7.pwconv2.bias\",\n",
            "      \"stages.2.8.gamma\",\n",
            "      \"stages.2.8.dwconv.bias\",\n",
            "      \"stages.2.8.norm.weight\",\n",
            "      \"stages.2.8.norm.bias\",\n",
            "      \"stages.2.8.pwconv1.bias\",\n",
            "      \"stages.2.8.pwconv2.bias\",\n",
            "      \"stages.2.9.gamma\",\n",
            "      \"stages.2.9.dwconv.bias\",\n",
            "      \"stages.2.9.norm.weight\",\n",
            "      \"stages.2.9.norm.bias\",\n",
            "      \"stages.2.9.pwconv1.bias\",\n",
            "      \"stages.2.9.pwconv2.bias\",\n",
            "      \"stages.2.10.gamma\",\n",
            "      \"stages.2.10.dwconv.bias\",\n",
            "      \"stages.2.10.norm.weight\",\n",
            "      \"stages.2.10.norm.bias\",\n",
            "      \"stages.2.10.pwconv1.bias\",\n",
            "      \"stages.2.10.pwconv2.bias\",\n",
            "      \"stages.2.11.gamma\",\n",
            "      \"stages.2.11.dwconv.bias\",\n",
            "      \"stages.2.11.norm.weight\",\n",
            "      \"stages.2.11.norm.bias\",\n",
            "      \"stages.2.11.pwconv1.bias\",\n",
            "      \"stages.2.11.pwconv2.bias\",\n",
            "      \"stages.2.12.gamma\",\n",
            "      \"stages.2.12.dwconv.bias\",\n",
            "      \"stages.2.12.norm.weight\",\n",
            "      \"stages.2.12.norm.bias\",\n",
            "      \"stages.2.12.pwconv1.bias\",\n",
            "      \"stages.2.12.pwconv2.bias\",\n",
            "      \"stages.2.13.gamma\",\n",
            "      \"stages.2.13.dwconv.bias\",\n",
            "      \"stages.2.13.norm.weight\",\n",
            "      \"stages.2.13.norm.bias\",\n",
            "      \"stages.2.13.pwconv1.bias\",\n",
            "      \"stages.2.13.pwconv2.bias\",\n",
            "      \"stages.2.14.gamma\",\n",
            "      \"stages.2.14.dwconv.bias\",\n",
            "      \"stages.2.14.norm.weight\",\n",
            "      \"stages.2.14.norm.bias\",\n",
            "      \"stages.2.14.pwconv1.bias\",\n",
            "      \"stages.2.14.pwconv2.bias\",\n",
            "      \"stages.2.15.gamma\",\n",
            "      \"stages.2.15.dwconv.bias\",\n",
            "      \"stages.2.15.norm.weight\",\n",
            "      \"stages.2.15.norm.bias\",\n",
            "      \"stages.2.15.pwconv1.bias\",\n",
            "      \"stages.2.15.pwconv2.bias\",\n",
            "      \"stages.2.16.gamma\",\n",
            "      \"stages.2.16.dwconv.bias\",\n",
            "      \"stages.2.16.norm.weight\",\n",
            "      \"stages.2.16.norm.bias\",\n",
            "      \"stages.2.16.pwconv1.bias\",\n",
            "      \"stages.2.16.pwconv2.bias\",\n",
            "      \"stages.2.17.gamma\",\n",
            "      \"stages.2.17.dwconv.bias\",\n",
            "      \"stages.2.17.norm.weight\",\n",
            "      \"stages.2.17.norm.bias\",\n",
            "      \"stages.2.17.pwconv1.bias\",\n",
            "      \"stages.2.17.pwconv2.bias\",\n",
            "      \"stages.2.18.gamma\",\n",
            "      \"stages.2.18.dwconv.bias\",\n",
            "      \"stages.2.18.norm.weight\",\n",
            "      \"stages.2.18.norm.bias\",\n",
            "      \"stages.2.18.pwconv1.bias\",\n",
            "      \"stages.2.18.pwconv2.bias\",\n",
            "      \"stages.2.19.gamma\",\n",
            "      \"stages.2.19.dwconv.bias\",\n",
            "      \"stages.2.19.norm.weight\",\n",
            "      \"stages.2.19.norm.bias\",\n",
            "      \"stages.2.19.pwconv1.bias\",\n",
            "      \"stages.2.19.pwconv2.bias\",\n",
            "      \"stages.2.20.gamma\",\n",
            "      \"stages.2.20.dwconv.bias\",\n",
            "      \"stages.2.20.norm.weight\",\n",
            "      \"stages.2.20.norm.bias\",\n",
            "      \"stages.2.20.pwconv1.bias\",\n",
            "      \"stages.2.20.pwconv2.bias\",\n",
            "      \"stages.2.21.gamma\",\n",
            "      \"stages.2.21.dwconv.bias\",\n",
            "      \"stages.2.21.norm.weight\",\n",
            "      \"stages.2.21.norm.bias\",\n",
            "      \"stages.2.21.pwconv1.bias\",\n",
            "      \"stages.2.21.pwconv2.bias\",\n",
            "      \"stages.2.22.gamma\",\n",
            "      \"stages.2.22.dwconv.bias\",\n",
            "      \"stages.2.22.norm.weight\",\n",
            "      \"stages.2.22.norm.bias\",\n",
            "      \"stages.2.22.pwconv1.bias\",\n",
            "      \"stages.2.22.pwconv2.bias\",\n",
            "      \"stages.2.23.gamma\",\n",
            "      \"stages.2.23.dwconv.bias\",\n",
            "      \"stages.2.23.norm.weight\",\n",
            "      \"stages.2.23.norm.bias\",\n",
            "      \"stages.2.23.pwconv1.bias\",\n",
            "      \"stages.2.23.pwconv2.bias\",\n",
            "      \"stages.2.24.gamma\",\n",
            "      \"stages.2.24.dwconv.bias\",\n",
            "      \"stages.2.24.norm.weight\",\n",
            "      \"stages.2.24.norm.bias\",\n",
            "      \"stages.2.24.pwconv1.bias\",\n",
            "      \"stages.2.24.pwconv2.bias\",\n",
            "      \"stages.2.25.gamma\",\n",
            "      \"stages.2.25.dwconv.bias\",\n",
            "      \"stages.2.25.norm.weight\",\n",
            "      \"stages.2.25.norm.bias\",\n",
            "      \"stages.2.25.pwconv1.bias\",\n",
            "      \"stages.2.25.pwconv2.bias\",\n",
            "      \"stages.2.26.gamma\",\n",
            "      \"stages.2.26.dwconv.bias\",\n",
            "      \"stages.2.26.norm.weight\",\n",
            "      \"stages.2.26.norm.bias\",\n",
            "      \"stages.2.26.pwconv1.bias\",\n",
            "      \"stages.2.26.pwconv2.bias\",\n",
            "      \"stages.3.0.gamma\",\n",
            "      \"stages.3.0.dwconv.bias\",\n",
            "      \"stages.3.0.norm.weight\",\n",
            "      \"stages.3.0.norm.bias\",\n",
            "      \"stages.3.0.pwconv1.bias\",\n",
            "      \"stages.3.0.pwconv2.bias\",\n",
            "      \"stages.3.1.gamma\",\n",
            "      \"stages.3.1.dwconv.bias\",\n",
            "      \"stages.3.1.norm.weight\",\n",
            "      \"stages.3.1.norm.bias\",\n",
            "      \"stages.3.1.pwconv1.bias\",\n",
            "      \"stages.3.1.pwconv2.bias\",\n",
            "      \"stages.3.2.gamma\",\n",
            "      \"stages.3.2.dwconv.bias\",\n",
            "      \"stages.3.2.norm.weight\",\n",
            "      \"stages.3.2.norm.bias\",\n",
            "      \"stages.3.2.pwconv1.bias\",\n",
            "      \"stages.3.2.pwconv2.bias\",\n",
            "      \"norm.weight\",\n",
            "      \"norm.bias\",\n",
            "      \"head.bias\"\n",
            "    ],\n",
            "    \"lr_scale\": 1.0\n",
            "  }\n",
            "}\n",
            "Use Cosine LR scheduler\n",
            "Set warmup steps = 0\n",
            "Set warmup steps = 0\n",
            "Max WD = 0.0500000, Min WD = 0.0500000\n",
            "criterion = LabelSmoothingCrossEntropy()\n",
            "Auto resume checkpoint: \n",
            "Start training for 30 epochs\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [0]  [  0/109]  eta: 0:11:53  lr: 0.000400  min_lr: 0.000400  loss: 2.1648 (2.1648)  class_acc: 0.0000 (0.0000)  weight_decay: 0.0500 (0.0500)  time: 6.5444  data: 2.4924  max mem: 12492\n",
            "Epoch: [0]  [ 10/109]  eta: 0:03:09  lr: 0.000400  min_lr: 0.000400  loss: 1.3403 (1.4005)  class_acc: 0.6719 (0.6094)  weight_decay: 0.0500 (0.0500)  time: 1.9134  data: 0.2285  max mem: 12492\n",
            "Epoch: [0]  [ 20/109]  eta: 0:02:31  lr: 0.000400  min_lr: 0.000400  loss: 1.3184 (1.3637)  class_acc: 0.6562 (0.6302)  weight_decay: 0.0500 (0.0500)  time: 1.4586  data: 0.0020  max mem: 12492\n",
            "Epoch: [0]  [ 30/109]  eta: 0:02:08  lr: 0.000400  min_lr: 0.000400  loss: 1.2929 (1.3427)  class_acc: 0.6562 (0.6411)  weight_decay: 0.0500 (0.0500)  time: 1.4777  data: 0.0017  max mem: 12492\n",
            "Epoch: [0]  [ 40/109]  eta: 0:01:50  lr: 0.000400  min_lr: 0.000400  loss: 1.2708 (1.3209)  class_acc: 0.6719 (0.6540)  weight_decay: 0.0500 (0.0500)  time: 1.4985  data: 0.0012  max mem: 12492\n",
            "Epoch: [0]  [ 50/109]  eta: 0:01:33  lr: 0.000400  min_lr: 0.000400  loss: 1.2708 (1.3187)  class_acc: 0.6719 (0.6532)  weight_decay: 0.0500 (0.0500)  time: 1.5193  data: 0.0011  max mem: 12492\n",
            "Epoch: [0]  [ 60/109]  eta: 0:01:17  lr: 0.000400  min_lr: 0.000400  loss: 1.3014 (1.3183)  class_acc: 0.6250 (0.6532)  weight_decay: 0.0500 (0.0500)  time: 1.5433  data: 0.0012  max mem: 12492\n",
            "Epoch: [0]  [ 70/109]  eta: 0:01:01  lr: 0.000400  min_lr: 0.000400  loss: 1.2618 (1.3138)  class_acc: 0.6719 (0.6545)  weight_decay: 0.0500 (0.0500)  time: 1.5694  data: 0.0013  max mem: 12492\n",
            "Epoch: [0]  [ 80/109]  eta: 0:00:46  lr: 0.000399  min_lr: 0.000399  loss: 1.2548 (1.3050)  class_acc: 0.6875 (0.6576)  weight_decay: 0.0500 (0.0500)  time: 1.5984  data: 0.0023  max mem: 12492\n",
            "Epoch: [0]  [ 90/109]  eta: 0:00:30  lr: 0.000399  min_lr: 0.000399  loss: 1.1762 (1.2900)  class_acc: 0.7031 (0.6633)  weight_decay: 0.0500 (0.0500)  time: 1.6078  data: 0.0030  max mem: 12492\n",
            "Epoch: [0]  [100/109]  eta: 0:00:14  lr: 0.000399  min_lr: 0.000399  loss: 1.1762 (1.2821)  class_acc: 0.6875 (0.6662)  weight_decay: 0.0500 (0.0500)  time: 1.5924  data: 0.0018  max mem: 12492\n",
            "Epoch: [0]  [108/109]  eta: 0:00:01  lr: 0.000399  min_lr: 0.000399  loss: 1.2228 (1.2806)  class_acc: 0.6875 (0.6644)  weight_decay: 0.0500 (0.0500)  time: 1.5830  data: 0.0008  max mem: 12492\n",
            "Epoch: [0] Total time: 0:02:53 (1.5908 s / it)\n",
            "Averaged stats: lr: 0.000399  min_lr: 0.000399  loss: 1.2228 (1.2806)  class_acc: 0.6875 (0.6644)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:01:58  loss: 2.7120 (2.7120)  acc1: 0.0000 (0.0000)  acc5: 96.8750 (96.8750)  time: 5.6612  data: 3.7165  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:13  loss: 1.3959 (1.4015)  acc1: 2.0833 (40.0568)  acc5: 100.0000 (97.0644)  time: 1.2053  data: 0.3388  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.4003 (0.9632)  acc1: 100.0000 (66.9327)  acc5: 100.0000 (97.2070)  time: 0.7641  data: 0.0006  max mem: 12492\n",
            "Test: Total time: 0:00:21 (1.0120 s / it)\n",
            "* Acc@1 66.933 Acc@5 97.207 loss 0.963\n",
            "Accuracy of the model on the 2005 test images: 66.9%\n",
            "Max accuracy: 66.93%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [1]  [  0/109]  eta: 0:07:52  lr: 0.000399  min_lr: 0.000399  loss: 1.4776 (1.4776)  class_acc: 0.5781 (0.5781)  weight_decay: 0.0500 (0.0500)  time: 4.3309  data: 2.6467  max mem: 12492\n",
            "Epoch: [1]  [ 10/109]  eta: 0:03:04  lr: 0.000399  min_lr: 0.000399  loss: 1.2052 (1.2345)  class_acc: 0.6719 (0.6591)  weight_decay: 0.0500 (0.0500)  time: 1.8592  data: 0.2408  max mem: 12492\n",
            "Epoch: [1]  [ 20/109]  eta: 0:02:35  lr: 0.000398  min_lr: 0.000398  loss: 1.2315 (1.2413)  class_acc: 0.6562 (0.6555)  weight_decay: 0.0500 (0.0500)  time: 1.6150  data: 0.0003  max mem: 12492\n",
            "Epoch: [1]  [ 30/109]  eta: 0:02:13  lr: 0.000398  min_lr: 0.000398  loss: 1.2315 (1.2277)  class_acc: 0.6406 (0.6573)  weight_decay: 0.0500 (0.0500)  time: 1.6064  data: 0.0003  max mem: 12492\n",
            "Epoch: [1]  [ 40/109]  eta: 0:01:55  lr: 0.000398  min_lr: 0.000398  loss: 1.1703 (1.2136)  class_acc: 0.6875 (0.6677)  weight_decay: 0.0500 (0.0500)  time: 1.5879  data: 0.0005  max mem: 12492\n",
            "Epoch: [1]  [ 50/109]  eta: 0:01:37  lr: 0.000398  min_lr: 0.000398  loss: 1.1616 (1.2135)  class_acc: 0.6875 (0.6661)  weight_decay: 0.0500 (0.0500)  time: 1.5816  data: 0.0005  max mem: 12492\n",
            "Epoch: [1]  [ 60/109]  eta: 0:01:20  lr: 0.000397  min_lr: 0.000397  loss: 1.1979 (1.2110)  class_acc: 0.6406 (0.6657)  weight_decay: 0.0500 (0.0500)  time: 1.5873  data: 0.0005  max mem: 12492\n",
            "Epoch: [1]  [ 70/109]  eta: 0:01:03  lr: 0.000397  min_lr: 0.000397  loss: 1.1919 (1.2073)  class_acc: 0.6562 (0.6657)  weight_decay: 0.0500 (0.0500)  time: 1.5966  data: 0.0005  max mem: 12492\n",
            "Epoch: [1]  [ 80/109]  eta: 0:00:47  lr: 0.000397  min_lr: 0.000397  loss: 1.1563 (1.2064)  class_acc: 0.6562 (0.6680)  weight_decay: 0.0500 (0.0500)  time: 1.6006  data: 0.0008  max mem: 12492\n",
            "Epoch: [1]  [ 90/109]  eta: 0:00:30  lr: 0.000396  min_lr: 0.000396  loss: 1.1355 (1.1977)  class_acc: 0.7031 (0.6727)  weight_decay: 0.0500 (0.0500)  time: 1.5972  data: 0.0014  max mem: 12492\n",
            "Epoch: [1]  [100/109]  eta: 0:00:14  lr: 0.000396  min_lr: 0.000396  loss: 1.1270 (1.1950)  class_acc: 0.6875 (0.6740)  weight_decay: 0.0500 (0.0500)  time: 1.5898  data: 0.0008  max mem: 12492\n",
            "Epoch: [1]  [108/109]  eta: 0:00:01  lr: 0.000396  min_lr: 0.000396  loss: 1.1633 (1.1963)  class_acc: 0.6875 (0.6735)  weight_decay: 0.0500 (0.0500)  time: 1.5877  data: 0.0007  max mem: 12492\n",
            "Epoch: [1] Total time: 0:02:57 (1.6243 s / it)\n",
            "Averaged stats: lr: 0.000396  min_lr: 0.000396  loss: 1.1633 (1.1963)  class_acc: 0.6875 (0.6735)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:01:09  loss: 2.1195 (2.1195)  acc1: 9.3750 (9.3750)  acc5: 98.9583 (98.9583)  time: 3.3206  data: 2.4972  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:11  loss: 1.3223 (1.2198)  acc1: 30.2083 (47.1591)  acc5: 100.0000 (97.7273)  time: 1.0005  data: 0.2288  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.4150 (0.8706)  acc1: 97.9167 (70.0748)  acc5: 100.0000 (98.2544)  time: 0.7666  data: 0.0010  max mem: 12492\n",
            "Test: Total time: 0:00:18 (0.9018 s / it)\n",
            "* Acc@1 70.075 Acc@5 98.254 loss 0.871\n",
            "Accuracy of the model on the 2005 test images: 70.1%\n",
            "Max accuracy: 70.07%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [2]  [  0/109]  eta: 0:09:41  lr: 0.000396  min_lr: 0.000396  loss: 1.3474 (1.3474)  class_acc: 0.5938 (0.5938)  weight_decay: 0.0500 (0.0500)  time: 5.3359  data: 3.3795  max mem: 12492\n",
            "Epoch: [2]  [ 10/109]  eta: 0:03:12  lr: 0.000395  min_lr: 0.000395  loss: 1.1371 (1.1780)  class_acc: 0.6875 (0.6676)  weight_decay: 0.0500 (0.0500)  time: 1.9419  data: 0.3090  max mem: 12492\n",
            "Epoch: [2]  [ 20/109]  eta: 0:02:39  lr: 0.000395  min_lr: 0.000395  loss: 1.1612 (1.1910)  class_acc: 0.6562 (0.6659)  weight_decay: 0.0500 (0.0500)  time: 1.6111  data: 0.0012  max mem: 12492\n",
            "Epoch: [2]  [ 30/109]  eta: 0:02:16  lr: 0.000394  min_lr: 0.000394  loss: 1.1792 (1.1809)  class_acc: 0.6562 (0.6668)  weight_decay: 0.0500 (0.0500)  time: 1.6111  data: 0.0008  max mem: 12492\n",
            "Epoch: [2]  [ 40/109]  eta: 0:01:56  lr: 0.000394  min_lr: 0.000394  loss: 1.1302 (1.1640)  class_acc: 0.6875 (0.6764)  weight_decay: 0.0500 (0.0500)  time: 1.5958  data: 0.0015  max mem: 12492\n",
            "Epoch: [2]  [ 50/109]  eta: 0:01:38  lr: 0.000393  min_lr: 0.000393  loss: 1.1181 (1.1650)  class_acc: 0.6875 (0.6743)  weight_decay: 0.0500 (0.0500)  time: 1.5870  data: 0.0017  max mem: 12492\n",
            "Epoch: [2]  [ 60/109]  eta: 0:01:21  lr: 0.000393  min_lr: 0.000393  loss: 1.1717 (1.1699)  class_acc: 0.6562 (0.6747)  weight_decay: 0.0500 (0.0500)  time: 1.5900  data: 0.0014  max mem: 12492\n",
            "Epoch: [2]  [ 70/109]  eta: 0:01:04  lr: 0.000392  min_lr: 0.000392  loss: 1.1553 (1.1661)  class_acc: 0.6719 (0.6752)  weight_decay: 0.0500 (0.0500)  time: 1.5973  data: 0.0017  max mem: 12492\n",
            "Epoch: [2]  [ 80/109]  eta: 0:00:47  lr: 0.000392  min_lr: 0.000392  loss: 1.1209 (1.1659)  class_acc: 0.6719 (0.6767)  weight_decay: 0.0500 (0.0500)  time: 1.5998  data: 0.0016  max mem: 12492\n",
            "Epoch: [2]  [ 90/109]  eta: 0:00:31  lr: 0.000391  min_lr: 0.000391  loss: 1.0922 (1.1556)  class_acc: 0.7188 (0.6829)  weight_decay: 0.0500 (0.0500)  time: 1.5994  data: 0.0013  max mem: 12492\n",
            "Epoch: [2]  [100/109]  eta: 0:00:14  lr: 0.000391  min_lr: 0.000391  loss: 1.0922 (1.1549)  class_acc: 0.7188 (0.6836)  weight_decay: 0.0500 (0.0500)  time: 1.5966  data: 0.0009  max mem: 12492\n",
            "Epoch: [2]  [108/109]  eta: 0:00:01  lr: 0.000390  min_lr: 0.000390  loss: 1.1034 (1.1564)  class_acc: 0.7031 (0.6821)  weight_decay: 0.0500 (0.0500)  time: 1.5936  data: 0.0001  max mem: 12492\n",
            "Epoch: [2] Total time: 0:02:58 (1.6353 s / it)\n",
            "Averaged stats: lr: 0.000390  min_lr: 0.000390  loss: 1.1034 (1.1564)  class_acc: 0.7031 (0.6821)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:01:16  loss: 1.4742 (1.4742)  acc1: 51.0417 (51.0417)  acc5: 98.9583 (98.9583)  time: 3.6469  data: 2.8250  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:11  loss: 1.2902 (1.1653)  acc1: 48.9583 (52.9356)  acc5: 100.0000 (98.2955)  time: 1.0309  data: 0.2570  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.4714 (0.8630)  acc1: 90.6250 (70.5237)  acc5: 100.0000 (98.0050)  time: 0.7664  data: 0.0002  max mem: 12492\n",
            "Test: Total time: 0:00:19 (0.9171 s / it)\n",
            "* Acc@1 70.524 Acc@5 98.005 loss 0.863\n",
            "Accuracy of the model on the 2005 test images: 70.5%\n",
            "Max accuracy: 70.52%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [3]  [  0/109]  eta: 0:09:23  lr: 0.000390  min_lr: 0.000390  loss: 1.3223 (1.3223)  class_acc: 0.6094 (0.6094)  weight_decay: 0.0500 (0.0500)  time: 5.1730  data: 3.4024  max mem: 12492\n",
            "Epoch: [3]  [ 10/109]  eta: 0:03:11  lr: 0.000390  min_lr: 0.000390  loss: 1.1259 (1.1385)  class_acc: 0.6719 (0.6847)  weight_decay: 0.0500 (0.0500)  time: 1.9294  data: 0.3116  max mem: 12492\n",
            "Epoch: [3]  [ 20/109]  eta: 0:02:38  lr: 0.000389  min_lr: 0.000389  loss: 1.1658 (1.1520)  class_acc: 0.6562 (0.6801)  weight_decay: 0.0500 (0.0500)  time: 1.6120  data: 0.0017  max mem: 12492\n",
            "Epoch: [3]  [ 30/109]  eta: 0:02:16  lr: 0.000388  min_lr: 0.000388  loss: 1.1515 (1.1436)  class_acc: 0.6562 (0.6820)  weight_decay: 0.0500 (0.0500)  time: 1.6091  data: 0.0012  max mem: 12492\n",
            "Epoch: [3]  [ 40/109]  eta: 0:01:56  lr: 0.000388  min_lr: 0.000388  loss: 1.0884 (1.1331)  class_acc: 0.7031 (0.6890)  weight_decay: 0.0500 (0.0500)  time: 1.5943  data: 0.0010  max mem: 12492\n",
            "Epoch: [3]  [ 50/109]  eta: 0:01:38  lr: 0.000387  min_lr: 0.000387  loss: 1.0911 (1.1352)  class_acc: 0.7031 (0.6875)  weight_decay: 0.0500 (0.0500)  time: 1.5888  data: 0.0009  max mem: 12492\n",
            "Epoch: [3]  [ 60/109]  eta: 0:01:21  lr: 0.000386  min_lr: 0.000386  loss: 1.1363 (1.1345)  class_acc: 0.6719 (0.6865)  weight_decay: 0.0500 (0.0500)  time: 1.5912  data: 0.0017  max mem: 12492\n",
            "Epoch: [3]  [ 70/109]  eta: 0:01:04  lr: 0.000386  min_lr: 0.000386  loss: 1.1573 (1.1371)  class_acc: 0.6719 (0.6851)  weight_decay: 0.0500 (0.0500)  time: 1.5977  data: 0.0021  max mem: 12492\n",
            "Epoch: [3]  [ 80/109]  eta: 0:00:47  lr: 0.000385  min_lr: 0.000385  loss: 1.1508 (1.1354)  class_acc: 0.6719 (0.6879)  weight_decay: 0.0500 (0.0500)  time: 1.6003  data: 0.0017  max mem: 12492\n",
            "Epoch: [3]  [ 90/109]  eta: 0:00:31  lr: 0.000384  min_lr: 0.000384  loss: 1.0652 (1.1270)  class_acc: 0.7188 (0.6923)  weight_decay: 0.0500 (0.0500)  time: 1.5976  data: 0.0016  max mem: 12492\n",
            "Epoch: [3]  [100/109]  eta: 0:00:14  lr: 0.000383  min_lr: 0.000383  loss: 1.0575 (1.1260)  class_acc: 0.7188 (0.6932)  weight_decay: 0.0500 (0.0500)  time: 1.5938  data: 0.0012  max mem: 12492\n",
            "Epoch: [3]  [108/109]  eta: 0:00:01  lr: 0.000383  min_lr: 0.000383  loss: 1.1346 (1.1282)  class_acc: 0.7031 (0.6919)  weight_decay: 0.0500 (0.0500)  time: 1.5896  data: 0.0003  max mem: 12492\n",
            "Epoch: [3] Total time: 0:02:58 (1.6332 s / it)\n",
            "Averaged stats: lr: 0.000383  min_lr: 0.000383  loss: 1.1346 (1.1282)  class_acc: 0.7031 (0.6919)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:01:04  loss: 1.9306 (1.9306)  acc1: 13.5417 (13.5417)  acc5: 97.9167 (97.9167)  time: 3.0903  data: 2.2201  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:10  loss: 1.2201 (1.1334)  acc1: 42.7083 (54.7349)  acc5: 100.0000 (98.3902)  time: 0.9811  data: 0.2037  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.4174 (0.8143)  acc1: 93.7500 (72.8180)  acc5: 100.0000 (99.0025)  time: 0.7676  data: 0.0011  max mem: 12492\n",
            "Test: Total time: 0:00:18 (0.8913 s / it)\n",
            "* Acc@1 72.818 Acc@5 99.002 loss 0.814\n",
            "Accuracy of the model on the 2005 test images: 72.8%\n",
            "Max accuracy: 72.82%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [4]  [  0/109]  eta: 0:09:42  lr: 0.000383  min_lr: 0.000383  loss: 1.2714 (1.2714)  class_acc: 0.6562 (0.6562)  weight_decay: 0.0500 (0.0500)  time: 5.3454  data: 3.5190  max mem: 12492\n",
            "Epoch: [4]  [ 10/109]  eta: 0:03:12  lr: 0.000382  min_lr: 0.000382  loss: 1.1153 (1.1422)  class_acc: 0.6875 (0.6818)  weight_decay: 0.0500 (0.0500)  time: 1.9434  data: 0.3206  max mem: 12492\n",
            "Epoch: [4]  [ 20/109]  eta: 0:02:39  lr: 0.000381  min_lr: 0.000381  loss: 1.1304 (1.1475)  class_acc: 0.6875 (0.6830)  weight_decay: 0.0500 (0.0500)  time: 1.6121  data: 0.0008  max mem: 12492\n",
            "Epoch: [4]  [ 30/109]  eta: 0:02:16  lr: 0.000380  min_lr: 0.000380  loss: 1.1304 (1.1388)  class_acc: 0.6875 (0.6840)  weight_decay: 0.0500 (0.0500)  time: 1.6099  data: 0.0006  max mem: 12492\n",
            "Epoch: [4]  [ 40/109]  eta: 0:01:56  lr: 0.000380  min_lr: 0.000380  loss: 1.0890 (1.1222)  class_acc: 0.6875 (0.6940)  weight_decay: 0.0500 (0.0500)  time: 1.5926  data: 0.0005  max mem: 12492\n",
            "Epoch: [4]  [ 50/109]  eta: 0:01:38  lr: 0.000379  min_lr: 0.000379  loss: 1.0600 (1.1235)  class_acc: 0.7031 (0.6942)  weight_decay: 0.0500 (0.0500)  time: 1.5879  data: 0.0011  max mem: 12492\n",
            "Epoch: [4]  [ 60/109]  eta: 0:01:21  lr: 0.000378  min_lr: 0.000378  loss: 1.1249 (1.1259)  class_acc: 0.6719 (0.6924)  weight_decay: 0.0500 (0.0500)  time: 1.5910  data: 0.0013  max mem: 12492\n",
            "Epoch: [4]  [ 70/109]  eta: 0:01:04  lr: 0.000377  min_lr: 0.000377  loss: 1.0985 (1.1227)  class_acc: 0.6875 (0.6937)  weight_decay: 0.0500 (0.0500)  time: 1.5970  data: 0.0017  max mem: 12492\n",
            "Epoch: [4]  [ 80/109]  eta: 0:00:47  lr: 0.000376  min_lr: 0.000376  loss: 1.0705 (1.1178)  class_acc: 0.7031 (0.6937)  weight_decay: 0.0500 (0.0500)  time: 1.6016  data: 0.0027  max mem: 12492\n",
            "Epoch: [4]  [ 90/109]  eta: 0:00:31  lr: 0.000375  min_lr: 0.000375  loss: 1.0705 (1.1110)  class_acc: 0.7188 (0.6978)  weight_decay: 0.0500 (0.0500)  time: 1.5987  data: 0.0024  max mem: 12492\n",
            "Epoch: [4]  [100/109]  eta: 0:00:14  lr: 0.000374  min_lr: 0.000374  loss: 1.0709 (1.1074)  class_acc: 0.7188 (0.6996)  weight_decay: 0.0500 (0.0500)  time: 1.5931  data: 0.0007  max mem: 12492\n",
            "Epoch: [4]  [108/109]  eta: 0:00:01  lr: 0.000373  min_lr: 0.000373  loss: 1.0794 (1.1083)  class_acc: 0.7031 (0.6977)  weight_decay: 0.0500 (0.0500)  time: 1.5887  data: 0.0003  max mem: 12492\n",
            "Epoch: [4] Total time: 0:02:58 (1.6342 s / it)\n",
            "Averaged stats: lr: 0.000373  min_lr: 0.000373  loss: 1.0794 (1.1083)  class_acc: 0.7031 (0.6977)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:00:56  loss: 2.0297 (2.0297)  acc1: 12.5000 (12.5000)  acc5: 97.9167 (97.9167)  time: 2.6948  data: 1.8744  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:10  loss: 1.2138 (1.0948)  acc1: 52.0833 (57.1970)  acc5: 100.0000 (98.6742)  time: 0.9465  data: 0.1714  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.3546 (0.7658)  acc1: 93.7500 (74.2145)  acc5: 100.0000 (99.1521)  time: 0.7679  data: 0.0006  max mem: 12492\n",
            "Test: Total time: 0:00:18 (0.8818 s / it)\n",
            "* Acc@1 74.214 Acc@5 99.152 loss 0.766\n",
            "Accuracy of the model on the 2005 test images: 74.2%\n",
            "Max accuracy: 74.21%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [5]  [  0/109]  eta: 0:08:26  lr: 0.000373  min_lr: 0.000373  loss: 1.1917 (1.1917)  class_acc: 0.6562 (0.6562)  weight_decay: 0.0500 (0.0500)  time: 4.6425  data: 2.9270  max mem: 12492\n",
            "Epoch: [5]  [ 10/109]  eta: 0:03:05  lr: 0.000372  min_lr: 0.000372  loss: 1.0200 (1.0926)  class_acc: 0.7188 (0.7003)  weight_decay: 0.0500 (0.0500)  time: 1.8785  data: 0.2672  max mem: 12492\n",
            "Epoch: [5]  [ 20/109]  eta: 0:02:36  lr: 0.000371  min_lr: 0.000371  loss: 1.1398 (1.1201)  class_acc: 0.7031 (0.6949)  weight_decay: 0.0500 (0.0500)  time: 1.6097  data: 0.0010  max mem: 12492\n",
            "Epoch: [5]  [ 30/109]  eta: 0:02:14  lr: 0.000370  min_lr: 0.000370  loss: 1.1008 (1.1080)  class_acc: 0.6875 (0.6905)  weight_decay: 0.0500 (0.0500)  time: 1.6094  data: 0.0009  max mem: 12492\n",
            "Epoch: [5]  [ 40/109]  eta: 0:01:55  lr: 0.000369  min_lr: 0.000369  loss: 1.0370 (1.0959)  class_acc: 0.7031 (0.7008)  weight_decay: 0.0500 (0.0500)  time: 1.5958  data: 0.0020  max mem: 12492\n",
            "Epoch: [5]  [ 50/109]  eta: 0:01:37  lr: 0.000368  min_lr: 0.000368  loss: 1.0784 (1.0969)  class_acc: 0.7188 (0.6985)  weight_decay: 0.0500 (0.0500)  time: 1.5879  data: 0.0025  max mem: 12492\n",
            "Epoch: [5]  [ 60/109]  eta: 0:01:20  lr: 0.000367  min_lr: 0.000367  loss: 1.1073 (1.0994)  class_acc: 0.7031 (0.6980)  weight_decay: 0.0500 (0.0500)  time: 1.5901  data: 0.0015  max mem: 12492\n",
            "Epoch: [5]  [ 70/109]  eta: 0:01:04  lr: 0.000366  min_lr: 0.000366  loss: 1.0929 (1.0975)  class_acc: 0.6875 (0.6981)  weight_decay: 0.0500 (0.0500)  time: 1.5968  data: 0.0015  max mem: 12492\n",
            "Epoch: [5]  [ 80/109]  eta: 0:00:47  lr: 0.000365  min_lr: 0.000365  loss: 1.0708 (1.0966)  class_acc: 0.7031 (0.6991)  weight_decay: 0.0500 (0.0500)  time: 1.6004  data: 0.0028  max mem: 12492\n",
            "Epoch: [5]  [ 90/109]  eta: 0:00:31  lr: 0.000364  min_lr: 0.000364  loss: 1.0545 (1.0875)  class_acc: 0.7188 (0.7042)  weight_decay: 0.0500 (0.0500)  time: 1.5990  data: 0.0028  max mem: 12492\n",
            "Epoch: [5]  [100/109]  eta: 0:00:14  lr: 0.000363  min_lr: 0.000363  loss: 1.0258 (1.0832)  class_acc: 0.7344 (0.7073)  weight_decay: 0.0500 (0.0500)  time: 1.5930  data: 0.0011  max mem: 12492\n",
            "Epoch: [5]  [108/109]  eta: 0:00:01  lr: 0.000362  min_lr: 0.000362  loss: 1.0366 (1.0871)  class_acc: 0.7188 (0.7044)  weight_decay: 0.0500 (0.0500)  time: 1.5905  data: 0.0002  max mem: 12492\n",
            "Epoch: [5] Total time: 0:02:57 (1.6278 s / it)\n",
            "Averaged stats: lr: 0.000362  min_lr: 0.000362  loss: 1.0366 (1.0871)  class_acc: 0.7188 (0.7044)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:01:21  loss: 1.7562 (1.7562)  acc1: 27.0833 (27.0833)  acc5: 100.0000 (100.0000)  time: 3.8594  data: 3.0364  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:11  loss: 1.2117 (1.0772)  acc1: 41.6667 (57.0076)  acc5: 100.0000 (99.0530)  time: 1.0569  data: 0.2772  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.3721 (0.7474)  acc1: 94.7917 (74.7132)  acc5: 100.0000 (99.4015)  time: 0.7699  data: 0.0007  max mem: 12492\n",
            "Test: Total time: 0:00:19 (0.9395 s / it)\n",
            "* Acc@1 74.713 Acc@5 99.401 loss 0.747\n",
            "Accuracy of the model on the 2005 test images: 74.7%\n",
            "Max accuracy: 74.71%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [6]  [  0/109]  eta: 0:07:57  lr: 0.000362  min_lr: 0.000362  loss: 1.2508 (1.2508)  class_acc: 0.6250 (0.6250)  weight_decay: 0.0500 (0.0500)  time: 4.3848  data: 2.7513  max mem: 12492\n",
            "Epoch: [6]  [ 10/109]  eta: 0:03:04  lr: 0.000361  min_lr: 0.000361  loss: 1.0531 (1.0945)  class_acc: 0.7188 (0.7159)  weight_decay: 0.0500 (0.0500)  time: 1.8615  data: 0.2531  max mem: 12492\n",
            "Epoch: [6]  [ 20/109]  eta: 0:02:35  lr: 0.000360  min_lr: 0.000360  loss: 1.1035 (1.1069)  class_acc: 0.6875 (0.6994)  weight_decay: 0.0500 (0.0500)  time: 1.6130  data: 0.0025  max mem: 12492\n",
            "Epoch: [6]  [ 30/109]  eta: 0:02:14  lr: 0.000358  min_lr: 0.000358  loss: 1.1068 (1.1028)  class_acc: 0.6875 (0.6996)  weight_decay: 0.0500 (0.0500)  time: 1.6091  data: 0.0016  max mem: 12492\n",
            "Epoch: [6]  [ 40/109]  eta: 0:01:55  lr: 0.000357  min_lr: 0.000357  loss: 1.0574 (1.0892)  class_acc: 0.7188 (0.7058)  weight_decay: 0.0500 (0.0500)  time: 1.5953  data: 0.0010  max mem: 12492\n",
            "Epoch: [6]  [ 50/109]  eta: 0:01:37  lr: 0.000356  min_lr: 0.000356  loss: 1.0460 (1.0877)  class_acc: 0.7188 (0.7044)  weight_decay: 0.0500 (0.0500)  time: 1.5876  data: 0.0005  max mem: 12492\n",
            "Epoch: [6]  [ 60/109]  eta: 0:01:20  lr: 0.000355  min_lr: 0.000355  loss: 1.0971 (1.0859)  class_acc: 0.7031 (0.7034)  weight_decay: 0.0500 (0.0500)  time: 1.5906  data: 0.0021  max mem: 12492\n",
            "Epoch: [6]  [ 70/109]  eta: 0:01:03  lr: 0.000354  min_lr: 0.000354  loss: 1.0986 (1.0854)  class_acc: 0.7031 (0.7036)  weight_decay: 0.0500 (0.0500)  time: 1.5974  data: 0.0020  max mem: 12492\n",
            "Epoch: [6]  [ 80/109]  eta: 0:00:47  lr: 0.000352  min_lr: 0.000352  loss: 1.0984 (1.0864)  class_acc: 0.7031 (0.7031)  weight_decay: 0.0500 (0.0500)  time: 1.5995  data: 0.0011  max mem: 12492\n",
            "Epoch: [6]  [ 90/109]  eta: 0:00:30  lr: 0.000351  min_lr: 0.000351  loss: 1.0627 (1.0802)  class_acc: 0.7344 (0.7071)  weight_decay: 0.0500 (0.0500)  time: 1.5964  data: 0.0019  max mem: 12492\n",
            "Epoch: [6]  [100/109]  eta: 0:00:14  lr: 0.000350  min_lr: 0.000350  loss: 1.0446 (1.0761)  class_acc: 0.7344 (0.7098)  weight_decay: 0.0500 (0.0500)  time: 1.5918  data: 0.0015  max mem: 12492\n",
            "Epoch: [6]  [108/109]  eta: 0:00:01  lr: 0.000349  min_lr: 0.000349  loss: 1.0483 (1.0796)  class_acc: 0.7188 (0.7070)  weight_decay: 0.0500 (0.0500)  time: 1.5897  data: 0.0006  max mem: 12492\n",
            "Epoch: [6] Total time: 0:02:57 (1.6254 s / it)\n",
            "Averaged stats: lr: 0.000349  min_lr: 0.000349  loss: 1.0483 (1.0796)  class_acc: 0.7188 (0.7070)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:01:33  loss: 1.6273 (1.6273)  acc1: 39.5833 (39.5833)  acc5: 98.9583 (98.9583)  time: 4.4691  data: 3.6232  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:12  loss: 1.0834 (1.0250)  acc1: 47.9167 (60.2273)  acc5: 100.0000 (98.8636)  time: 1.1046  data: 0.3296  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.4202 (0.7489)  acc1: 92.7083 (75.4115)  acc5: 100.0000 (99.2020)  time: 0.7657  data: 0.0002  max mem: 12492\n",
            "Test: Total time: 0:00:20 (0.9610 s / it)\n",
            "* Acc@1 75.411 Acc@5 99.202 loss 0.749\n",
            "Accuracy of the model on the 2005 test images: 75.4%\n",
            "Max accuracy: 75.41%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [7]  [  0/109]  eta: 0:06:45  lr: 0.000349  min_lr: 0.000349  loss: 1.2632 (1.2632)  class_acc: 0.5781 (0.5781)  weight_decay: 0.0500 (0.0500)  time: 3.7208  data: 1.9428  max mem: 12492\n",
            "Epoch: [7]  [ 10/109]  eta: 0:02:58  lr: 0.000347  min_lr: 0.000347  loss: 1.0460 (1.1091)  class_acc: 0.6719 (0.6804)  weight_decay: 0.0500 (0.0500)  time: 1.8019  data: 0.1788  max mem: 12492\n",
            "Epoch: [7]  [ 20/109]  eta: 0:02:32  lr: 0.000346  min_lr: 0.000346  loss: 1.0784 (1.1159)  class_acc: 0.6719 (0.6778)  weight_decay: 0.0500 (0.0500)  time: 1.6141  data: 0.0023  max mem: 12492\n",
            "Epoch: [7]  [ 30/109]  eta: 0:02:12  lr: 0.000345  min_lr: 0.000345  loss: 1.0901 (1.0956)  class_acc: 0.7031 (0.6946)  weight_decay: 0.0500 (0.0500)  time: 1.6100  data: 0.0015  max mem: 12492\n",
            "Epoch: [7]  [ 40/109]  eta: 0:01:54  lr: 0.000344  min_lr: 0.000344  loss: 1.0204 (1.0767)  class_acc: 0.7188 (0.7039)  weight_decay: 0.0500 (0.0500)  time: 1.5969  data: 0.0018  max mem: 12492\n",
            "Epoch: [7]  [ 50/109]  eta: 0:01:36  lr: 0.000342  min_lr: 0.000342  loss: 1.0302 (1.0741)  class_acc: 0.7188 (0.7044)  weight_decay: 0.0500 (0.0500)  time: 1.5899  data: 0.0021  max mem: 12492\n",
            "Epoch: [7]  [ 60/109]  eta: 0:01:20  lr: 0.000341  min_lr: 0.000341  loss: 1.0822 (1.0745)  class_acc: 0.6875 (0.7031)  weight_decay: 0.0500 (0.0500)  time: 1.5922  data: 0.0015  max mem: 12492\n",
            "Epoch: [7]  [ 70/109]  eta: 0:01:03  lr: 0.000339  min_lr: 0.000339  loss: 1.0749 (1.0740)  class_acc: 0.7031 (0.7038)  weight_decay: 0.0500 (0.0500)  time: 1.5991  data: 0.0021  max mem: 12492\n",
            "Epoch: [7]  [ 80/109]  eta: 0:00:47  lr: 0.000338  min_lr: 0.000338  loss: 1.0525 (1.0737)  class_acc: 0.7031 (0.7052)  weight_decay: 0.0500 (0.0500)  time: 1.6008  data: 0.0027  max mem: 12492\n",
            "Epoch: [7]  [ 90/109]  eta: 0:00:30  lr: 0.000337  min_lr: 0.000337  loss: 1.0278 (1.0663)  class_acc: 0.7188 (0.7084)  weight_decay: 0.0500 (0.0500)  time: 1.5988  data: 0.0025  max mem: 12492\n",
            "Epoch: [7]  [100/109]  eta: 0:00:14  lr: 0.000335  min_lr: 0.000335  loss: 1.0013 (1.0631)  class_acc: 0.7344 (0.7102)  weight_decay: 0.0500 (0.0500)  time: 1.5974  data: 0.0021  max mem: 12492\n",
            "Epoch: [7]  [108/109]  eta: 0:00:01  lr: 0.000334  min_lr: 0.000334  loss: 1.0741 (1.0659)  class_acc: 0.7031 (0.7090)  weight_decay: 0.0500 (0.0500)  time: 1.5952  data: 0.0014  max mem: 12492\n",
            "Epoch: [7] Total time: 0:02:56 (1.6229 s / it)\n",
            "Averaged stats: lr: 0.000334  min_lr: 0.000334  loss: 1.0741 (1.0659)  class_acc: 0.7031 (0.7090)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:01:07  loss: 1.6127 (1.6127)  acc1: 42.7083 (42.7083)  acc5: 100.0000 (100.0000)  time: 3.1941  data: 2.3852  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:10  loss: 0.9353 (1.0117)  acc1: 60.4167 (61.8371)  acc5: 100.0000 (98.7689)  time: 0.9893  data: 0.2174  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.4771 (0.7758)  acc1: 88.5417 (74.7132)  acc5: 100.0000 (99.1022)  time: 0.7662  data: 0.0004  max mem: 12492\n",
            "Test: Total time: 0:00:18 (0.8984 s / it)\n",
            "* Acc@1 74.713 Acc@5 99.102 loss 0.776\n",
            "Accuracy of the model on the 2005 test images: 74.7%\n",
            "Max accuracy: 75.41%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [8]  [  0/109]  eta: 0:07:28  lr: 0.000334  min_lr: 0.000334  loss: 1.1674 (1.1674)  class_acc: 0.6562 (0.6562)  weight_decay: 0.0500 (0.0500)  time: 4.1129  data: 2.4335  max mem: 12492\n",
            "Epoch: [8]  [ 10/109]  eta: 0:03:01  lr: 0.000333  min_lr: 0.000333  loss: 1.0883 (1.0981)  class_acc: 0.7031 (0.7045)  weight_decay: 0.0500 (0.0500)  time: 1.8345  data: 0.2220  max mem: 12492\n",
            "Epoch: [8]  [ 20/109]  eta: 0:02:33  lr: 0.000331  min_lr: 0.000331  loss: 1.0514 (1.0879)  class_acc: 0.7031 (0.7031)  weight_decay: 0.0500 (0.0500)  time: 1.6093  data: 0.0007  max mem: 12492\n",
            "Epoch: [8]  [ 30/109]  eta: 0:02:13  lr: 0.000330  min_lr: 0.000330  loss: 1.0489 (1.0720)  class_acc: 0.7031 (0.7046)  weight_decay: 0.0500 (0.0500)  time: 1.6051  data: 0.0008  max mem: 12492\n",
            "Epoch: [8]  [ 40/109]  eta: 0:01:54  lr: 0.000328  min_lr: 0.000328  loss: 1.0278 (1.0612)  class_acc: 0.7344 (0.7111)  weight_decay: 0.0500 (0.0500)  time: 1.5951  data: 0.0014  max mem: 12492\n",
            "Epoch: [8]  [ 50/109]  eta: 0:01:37  lr: 0.000327  min_lr: 0.000327  loss: 1.0340 (1.0570)  class_acc: 0.7344 (0.7105)  weight_decay: 0.0500 (0.0500)  time: 1.5901  data: 0.0015  max mem: 12492\n",
            "Epoch: [8]  [ 60/109]  eta: 0:01:20  lr: 0.000325  min_lr: 0.000325  loss: 1.0418 (1.0533)  class_acc: 0.7188 (0.7129)  weight_decay: 0.0500 (0.0500)  time: 1.5936  data: 0.0016  max mem: 12492\n",
            "Epoch: [8]  [ 70/109]  eta: 0:01:03  lr: 0.000324  min_lr: 0.000324  loss: 1.0405 (1.0540)  class_acc: 0.7188 (0.7132)  weight_decay: 0.0500 (0.0500)  time: 1.5998  data: 0.0011  max mem: 12492\n",
            "Epoch: [8]  [ 80/109]  eta: 0:00:47  lr: 0.000322  min_lr: 0.000322  loss: 1.0482 (1.0527)  class_acc: 0.7188 (0.7143)  weight_decay: 0.0500 (0.0500)  time: 1.5992  data: 0.0014  max mem: 12492\n",
            "Epoch: [8]  [ 90/109]  eta: 0:00:30  lr: 0.000321  min_lr: 0.000321  loss: 1.0421 (1.0491)  class_acc: 0.7500 (0.7186)  weight_decay: 0.0500 (0.0500)  time: 1.5955  data: 0.0027  max mem: 12492\n",
            "Epoch: [8]  [100/109]  eta: 0:00:14  lr: 0.000319  min_lr: 0.000319  loss: 0.9905 (1.0463)  class_acc: 0.7656 (0.7211)  weight_decay: 0.0500 (0.0500)  time: 1.5912  data: 0.0015  max mem: 12492\n",
            "Epoch: [8]  [108/109]  eta: 0:00:01  lr: 0.000318  min_lr: 0.000318  loss: 1.0330 (1.0491)  class_acc: 0.7344 (0.7203)  weight_decay: 0.0500 (0.0500)  time: 1.5894  data: 0.0007  max mem: 12492\n",
            "Epoch: [8] Total time: 0:02:57 (1.6241 s / it)\n",
            "Averaged stats: lr: 0.000318  min_lr: 0.000318  loss: 1.0330 (1.0491)  class_acc: 0.7344 (0.7203)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:00:55  loss: 1.8025 (1.8025)  acc1: 25.0000 (25.0000)  acc5: 98.9583 (98.9583)  time: 2.6593  data: 1.8332  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:10  loss: 0.9440 (0.9926)  acc1: 61.4583 (61.8371)  acc5: 100.0000 (98.7689)  time: 0.9439  data: 0.1675  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.4134 (0.7359)  acc1: 89.5833 (74.7132)  acc5: 100.0000 (99.0025)  time: 0.7691  data: 0.0005  max mem: 12492\n",
            "Test: Total time: 0:00:18 (0.8731 s / it)\n",
            "* Acc@1 74.713 Acc@5 99.002 loss 0.736\n",
            "Accuracy of the model on the 2005 test images: 74.7%\n",
            "Max accuracy: 75.41%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [9]  [  0/109]  eta: 0:07:02  lr: 0.000318  min_lr: 0.000318  loss: 1.1176 (1.1176)  class_acc: 0.6250 (0.6250)  weight_decay: 0.0500 (0.0500)  time: 3.8724  data: 2.0666  max mem: 12492\n",
            "Epoch: [9]  [ 10/109]  eta: 0:02:59  lr: 0.000316  min_lr: 0.000316  loss: 1.0676 (1.0309)  class_acc: 0.7031 (0.7145)  weight_decay: 0.0500 (0.0500)  time: 1.8108  data: 0.1893  max mem: 12492\n",
            "Epoch: [9]  [ 20/109]  eta: 0:02:32  lr: 0.000315  min_lr: 0.000315  loss: 1.0676 (1.0592)  class_acc: 0.6875 (0.7031)  weight_decay: 0.0500 (0.0500)  time: 1.6071  data: 0.0014  max mem: 12492\n",
            "Epoch: [9]  [ 30/109]  eta: 0:02:12  lr: 0.000313  min_lr: 0.000313  loss: 1.0432 (1.0421)  class_acc: 0.7031 (0.7112)  weight_decay: 0.0500 (0.0500)  time: 1.6039  data: 0.0007  max mem: 12492\n",
            "Epoch: [9]  [ 40/109]  eta: 0:01:54  lr: 0.000311  min_lr: 0.000311  loss: 0.9953 (1.0362)  class_acc: 0.7344 (0.7172)  weight_decay: 0.0500 (0.0500)  time: 1.5950  data: 0.0011  max mem: 12492\n",
            "Epoch: [9]  [ 50/109]  eta: 0:01:37  lr: 0.000310  min_lr: 0.000310  loss: 1.0307 (1.0370)  class_acc: 0.7188 (0.7157)  weight_decay: 0.0500 (0.0500)  time: 1.5929  data: 0.0015  max mem: 12492\n",
            "Epoch: [9]  [ 60/109]  eta: 0:01:20  lr: 0.000308  min_lr: 0.000308  loss: 1.0382 (1.0392)  class_acc: 0.7031 (0.7157)  weight_decay: 0.0500 (0.0500)  time: 1.5948  data: 0.0009  max mem: 12492\n",
            "Epoch: [9]  [ 70/109]  eta: 0:01:03  lr: 0.000307  min_lr: 0.000307  loss: 1.0381 (1.0362)  class_acc: 0.7188 (0.7179)  weight_decay: 0.0500 (0.0500)  time: 1.5983  data: 0.0022  max mem: 12492\n",
            "Epoch: [9]  [ 80/109]  eta: 0:00:47  lr: 0.000305  min_lr: 0.000305  loss: 0.9811 (1.0345)  class_acc: 0.7344 (0.7193)  weight_decay: 0.0500 (0.0500)  time: 1.5995  data: 0.0025  max mem: 12492\n",
            "Epoch: [9]  [ 90/109]  eta: 0:00:30  lr: 0.000303  min_lr: 0.000303  loss: 1.0089 (1.0305)  class_acc: 0.7500 (0.7241)  weight_decay: 0.0500 (0.0500)  time: 1.5990  data: 0.0020  max mem: 12492\n",
            "Epoch: [9]  [100/109]  eta: 0:00:14  lr: 0.000302  min_lr: 0.000302  loss: 0.9952 (1.0286)  class_acc: 0.7500 (0.7259)  weight_decay: 0.0500 (0.0500)  time: 1.5992  data: 0.0014  max mem: 12492\n",
            "Epoch: [9]  [108/109]  eta: 0:00:01  lr: 0.000300  min_lr: 0.000300  loss: 1.0114 (1.0304)  class_acc: 0.7344 (0.7252)  weight_decay: 0.0500 (0.0500)  time: 1.6000  data: 0.0005  max mem: 12492\n",
            "Epoch: [9] Total time: 0:02:56 (1.6238 s / it)\n",
            "Averaged stats: lr: 0.000300  min_lr: 0.000300  loss: 1.0114 (1.0304)  class_acc: 0.7344 (0.7252)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:01:10  loss: 1.6693 (1.6693)  acc1: 37.5000 (37.5000)  acc5: 98.9583 (98.9583)  time: 3.3379  data: 2.5118  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:11  loss: 0.9402 (0.9403)  acc1: 60.4167 (65.8144)  acc5: 100.0000 (98.9583)  time: 1.0062  data: 0.2301  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.3813 (0.6896)  acc1: 89.5833 (76.8579)  acc5: 100.0000 (99.3017)  time: 0.7696  data: 0.0010  max mem: 12492\n",
            "Test: Total time: 0:00:19 (0.9067 s / it)\n",
            "* Acc@1 76.858 Acc@5 99.302 loss 0.690\n",
            "Accuracy of the model on the 2005 test images: 76.9%\n",
            "Max accuracy: 76.86%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [10]  [  0/109]  eta: 0:07:16  lr: 0.000300  min_lr: 0.000300  loss: 1.1985 (1.1985)  class_acc: 0.5781 (0.5781)  weight_decay: 0.0500 (0.0500)  time: 4.0064  data: 2.1012  max mem: 12492\n",
            "Epoch: [10]  [ 10/109]  eta: 0:03:01  lr: 0.000299  min_lr: 0.000299  loss: 1.0346 (1.0302)  class_acc: 0.7344 (0.7358)  weight_decay: 0.0500 (0.0500)  time: 1.8370  data: 0.1930  max mem: 12492\n",
            "Epoch: [10]  [ 20/109]  eta: 0:02:34  lr: 0.000297  min_lr: 0.000297  loss: 1.0236 (1.0386)  class_acc: 0.7188 (0.7262)  weight_decay: 0.0500 (0.0500)  time: 1.6192  data: 0.0021  max mem: 12492\n",
            "Epoch: [10]  [ 30/109]  eta: 0:02:13  lr: 0.000295  min_lr: 0.000295  loss: 1.0540 (1.0429)  class_acc: 0.7188 (0.7248)  weight_decay: 0.0500 (0.0500)  time: 1.6098  data: 0.0014  max mem: 12492\n",
            "Epoch: [10]  [ 40/109]  eta: 0:01:54  lr: 0.000294  min_lr: 0.000294  loss: 1.0187 (1.0235)  class_acc: 0.7344 (0.7306)  weight_decay: 0.0500 (0.0500)  time: 1.5954  data: 0.0016  max mem: 12492\n",
            "Epoch: [10]  [ 50/109]  eta: 0:01:37  lr: 0.000292  min_lr: 0.000292  loss: 0.9719 (1.0233)  class_acc: 0.7344 (0.7292)  weight_decay: 0.0500 (0.0500)  time: 1.5888  data: 0.0018  max mem: 12492\n",
            "Epoch: [10]  [ 60/109]  eta: 0:01:20  lr: 0.000290  min_lr: 0.000290  loss: 1.0280 (1.0256)  class_acc: 0.7188 (0.7257)  weight_decay: 0.0500 (0.0500)  time: 1.5922  data: 0.0021  max mem: 12492\n",
            "Epoch: [10]  [ 70/109]  eta: 0:01:03  lr: 0.000288  min_lr: 0.000288  loss: 1.0050 (1.0232)  class_acc: 0.7188 (0.7245)  weight_decay: 0.0500 (0.0500)  time: 1.5991  data: 0.0025  max mem: 12492\n",
            "Epoch: [10]  [ 80/109]  eta: 0:00:47  lr: 0.000287  min_lr: 0.000287  loss: 1.0030 (1.0216)  class_acc: 0.7344 (0.7272)  weight_decay: 0.0500 (0.0500)  time: 1.6021  data: 0.0017  max mem: 12492\n",
            "Epoch: [10]  [ 90/109]  eta: 0:00:30  lr: 0.000285  min_lr: 0.000285  loss: 0.9825 (1.0188)  class_acc: 0.7500 (0.7297)  weight_decay: 0.0500 (0.0500)  time: 1.5984  data: 0.0012  max mem: 12492\n",
            "Epoch: [10]  [100/109]  eta: 0:00:14  lr: 0.000283  min_lr: 0.000283  loss: 0.9862 (1.0178)  class_acc: 0.7500 (0.7314)  weight_decay: 0.0500 (0.0500)  time: 1.5921  data: 0.0005  max mem: 12492\n",
            "Epoch: [10]  [108/109]  eta: 0:00:01  lr: 0.000282  min_lr: 0.000282  loss: 0.9891 (1.0179)  class_acc: 0.7500 (0.7312)  weight_decay: 0.0500 (0.0500)  time: 1.5902  data: 0.0001  max mem: 12492\n",
            "Epoch: [10] Total time: 0:02:57 (1.6243 s / it)\n",
            "Averaged stats: lr: 0.000282  min_lr: 0.000282  loss: 0.9891 (1.0179)  class_acc: 0.7500 (0.7312)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:01:04  loss: 1.4583 (1.4583)  acc1: 48.9583 (48.9583)  acc5: 98.9583 (98.9583)  time: 3.0756  data: 2.2216  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:10  loss: 0.8629 (0.9628)  acc1: 60.4167 (62.2159)  acc5: 100.0000 (99.0530)  time: 0.9749  data: 0.2024  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.4711 (0.7397)  acc1: 87.5000 (74.1646)  acc5: 100.0000 (99.4514)  time: 0.7646  data: 0.0003  max mem: 12492\n",
            "Test: Total time: 0:00:18 (0.8885 s / it)\n",
            "* Acc@1 74.165 Acc@5 99.451 loss 0.740\n",
            "Accuracy of the model on the 2005 test images: 74.2%\n",
            "Max accuracy: 76.86%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [11]  [  0/109]  eta: 0:08:23  lr: 0.000282  min_lr: 0.000282  loss: 1.1276 (1.1276)  class_acc: 0.6406 (0.6406)  weight_decay: 0.0500 (0.0500)  time: 4.6172  data: 2.7743  max mem: 12492\n",
            "Epoch: [11]  [ 10/109]  eta: 0:03:07  lr: 0.000280  min_lr: 0.000280  loss: 1.0476 (1.0222)  class_acc: 0.7344 (0.7330)  weight_decay: 0.0500 (0.0500)  time: 1.8943  data: 0.2526  max mem: 12492\n",
            "Epoch: [11]  [ 20/109]  eta: 0:02:36  lr: 0.000278  min_lr: 0.000278  loss: 1.0250 (1.0289)  class_acc: 0.7344 (0.7277)  weight_decay: 0.0500 (0.0500)  time: 1.6203  data: 0.0017  max mem: 12492\n",
            "Epoch: [11]  [ 30/109]  eta: 0:02:15  lr: 0.000276  min_lr: 0.000276  loss: 1.0125 (1.0196)  class_acc: 0.7344 (0.7344)  weight_decay: 0.0500 (0.0500)  time: 1.6098  data: 0.0024  max mem: 12492\n",
            "Epoch: [11]  [ 40/109]  eta: 0:01:55  lr: 0.000275  min_lr: 0.000275  loss: 0.9787 (1.0145)  class_acc: 0.7344 (0.7344)  weight_decay: 0.0500 (0.0500)  time: 1.5941  data: 0.0016  max mem: 12492\n",
            "Epoch: [11]  [ 50/109]  eta: 0:01:38  lr: 0.000273  min_lr: 0.000273  loss: 0.9969 (1.0156)  class_acc: 0.7344 (0.7356)  weight_decay: 0.0500 (0.0500)  time: 1.5872  data: 0.0015  max mem: 12492\n",
            "Epoch: [11]  [ 60/109]  eta: 0:01:20  lr: 0.000271  min_lr: 0.000271  loss: 1.0152 (1.0120)  class_acc: 0.7344 (0.7351)  weight_decay: 0.0500 (0.0500)  time: 1.5920  data: 0.0016  max mem: 12492\n",
            "Epoch: [11]  [ 70/109]  eta: 0:01:04  lr: 0.000269  min_lr: 0.000269  loss: 1.0227 (1.0172)  class_acc: 0.7188 (0.7331)  weight_decay: 0.0500 (0.0500)  time: 1.5989  data: 0.0017  max mem: 12492\n",
            "Epoch: [11]  [ 80/109]  eta: 0:00:47  lr: 0.000267  min_lr: 0.000267  loss: 1.0283 (1.0169)  class_acc: 0.7188 (0.7338)  weight_decay: 0.0500 (0.0500)  time: 1.6006  data: 0.0019  max mem: 12492\n",
            "Epoch: [11]  [ 90/109]  eta: 0:00:31  lr: 0.000266  min_lr: 0.000266  loss: 0.9717 (1.0100)  class_acc: 0.7500 (0.7368)  weight_decay: 0.0500 (0.0500)  time: 1.5993  data: 0.0018  max mem: 12492\n",
            "Epoch: [11]  [100/109]  eta: 0:00:14  lr: 0.000264  min_lr: 0.000264  loss: 0.9363 (1.0087)  class_acc: 0.7500 (0.7359)  weight_decay: 0.0500 (0.0500)  time: 1.5969  data: 0.0009  max mem: 12492\n",
            "Epoch: [11]  [108/109]  eta: 0:00:01  lr: 0.000262  min_lr: 0.000262  loss: 1.0063 (1.0107)  class_acc: 0.7500 (0.7361)  weight_decay: 0.0500 (0.0500)  time: 1.5958  data: 0.0002  max mem: 12492\n",
            "Epoch: [11] Total time: 0:02:57 (1.6310 s / it)\n",
            "Averaged stats: lr: 0.000262  min_lr: 0.000262  loss: 1.0063 (1.0107)  class_acc: 0.7500 (0.7361)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:00:56  loss: 1.5548 (1.5548)  acc1: 45.8333 (45.8333)  acc5: 98.9583 (98.9583)  time: 2.6943  data: 1.9012  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:10  loss: 0.9112 (0.9469)  acc1: 62.5000 (63.5417)  acc5: 100.0000 (98.8636)  time: 0.9469  data: 0.1740  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.3881 (0.6936)  acc1: 89.5833 (76.0599)  acc5: 100.0000 (99.3017)  time: 0.7674  data: 0.0007  max mem: 12492\n",
            "Test: Total time: 0:00:18 (0.8716 s / it)\n",
            "* Acc@1 76.060 Acc@5 99.302 loss 0.694\n",
            "Accuracy of the model on the 2005 test images: 76.1%\n",
            "Max accuracy: 76.86%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [12]  [  0/109]  eta: 0:10:27  lr: 0.000262  min_lr: 0.000262  loss: 1.0727 (1.0727)  class_acc: 0.6719 (0.6719)  weight_decay: 0.0500 (0.0500)  time: 5.7591  data: 3.8360  max mem: 12492\n",
            "Epoch: [12]  [ 10/109]  eta: 0:03:15  lr: 0.000260  min_lr: 0.000260  loss: 1.0207 (1.0247)  class_acc: 0.7344 (0.7287)  weight_decay: 0.0500 (0.0500)  time: 1.9798  data: 0.3514  max mem: 12492\n",
            "Epoch: [12]  [ 20/109]  eta: 0:02:40  lr: 0.000258  min_lr: 0.000258  loss: 1.0257 (1.0378)  class_acc: 0.7344 (0.7195)  weight_decay: 0.0500 (0.0500)  time: 1.6089  data: 0.0021  max mem: 12492\n",
            "Epoch: [12]  [ 30/109]  eta: 0:02:17  lr: 0.000257  min_lr: 0.000257  loss: 1.0257 (1.0267)  class_acc: 0.7344 (0.7248)  weight_decay: 0.0500 (0.0500)  time: 1.6114  data: 0.0016  max mem: 12492\n",
            "Epoch: [12]  [ 40/109]  eta: 0:01:57  lr: 0.000255  min_lr: 0.000255  loss: 0.9658 (1.0153)  class_acc: 0.7344 (0.7332)  weight_decay: 0.0500 (0.0500)  time: 1.6007  data: 0.0013  max mem: 12492\n",
            "Epoch: [12]  [ 50/109]  eta: 0:01:39  lr: 0.000253  min_lr: 0.000253  loss: 0.9501 (1.0042)  class_acc: 0.7500 (0.7393)  weight_decay: 0.0500 (0.0500)  time: 1.5932  data: 0.0011  max mem: 12492\n",
            "Epoch: [12]  [ 60/109]  eta: 0:01:21  lr: 0.000251  min_lr: 0.000251  loss: 0.9975 (1.0075)  class_acc: 0.7500 (0.7364)  weight_decay: 0.0500 (0.0500)  time: 1.5939  data: 0.0023  max mem: 12492\n",
            "Epoch: [12]  [ 70/109]  eta: 0:01:04  lr: 0.000249  min_lr: 0.000249  loss: 1.0201 (1.0066)  class_acc: 0.7188 (0.7377)  weight_decay: 0.0500 (0.0500)  time: 1.5986  data: 0.0023  max mem: 12492\n",
            "Epoch: [12]  [ 80/109]  eta: 0:00:47  lr: 0.000247  min_lr: 0.000247  loss: 1.0009 (1.0059)  class_acc: 0.7344 (0.7382)  weight_decay: 0.0500 (0.0500)  time: 1.6005  data: 0.0015  max mem: 12492\n",
            "Epoch: [12]  [ 90/109]  eta: 0:00:31  lr: 0.000246  min_lr: 0.000246  loss: 0.9732 (1.0004)  class_acc: 0.7656 (0.7411)  weight_decay: 0.0500 (0.0500)  time: 1.6018  data: 0.0022  max mem: 12492\n",
            "Epoch: [12]  [100/109]  eta: 0:00:14  lr: 0.000244  min_lr: 0.000244  loss: 0.9740 (0.9981)  class_acc: 0.7656 (0.7429)  weight_decay: 0.0500 (0.0500)  time: 1.6012  data: 0.0019  max mem: 12492\n",
            "Epoch: [12]  [108/109]  eta: 0:00:01  lr: 0.000242  min_lr: 0.000242  loss: 0.9740 (0.9987)  class_acc: 0.7656 (0.7435)  weight_decay: 0.0500 (0.0500)  time: 1.5987  data: 0.0005  max mem: 12492\n",
            "Epoch: [12] Total time: 0:02:58 (1.6416 s / it)\n",
            "Averaged stats: lr: 0.000242  min_lr: 0.000242  loss: 0.9740 (0.9987)  class_acc: 0.7656 (0.7435)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:01:33  loss: 1.4863 (1.4863)  acc1: 50.0000 (50.0000)  acc5: 100.0000 (100.0000)  time: 4.4468  data: 3.6362  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:12  loss: 0.8572 (0.9133)  acc1: 61.4583 (66.5720)  acc5: 100.0000 (99.3371)  time: 1.1058  data: 0.3308  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.3573 (0.6637)  acc1: 90.6250 (78.2544)  acc5: 100.0000 (99.6010)  time: 0.7691  data: 0.0002  max mem: 12492\n",
            "Test: Total time: 0:00:20 (0.9660 s / it)\n",
            "* Acc@1 78.254 Acc@5 99.601 loss 0.664\n",
            "Accuracy of the model on the 2005 test images: 78.3%\n",
            "Max accuracy: 78.25%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [13]  [  0/109]  eta: 0:06:59  lr: 0.000242  min_lr: 0.000242  loss: 1.0833 (1.0833)  class_acc: 0.6875 (0.6875)  weight_decay: 0.0500 (0.0500)  time: 3.8511  data: 2.0864  max mem: 12492\n",
            "Epoch: [13]  [ 10/109]  eta: 0:02:59  lr: 0.000240  min_lr: 0.000240  loss: 0.9600 (0.9925)  class_acc: 0.7344 (0.7401)  weight_decay: 0.0500 (0.0500)  time: 1.8154  data: 0.1913  max mem: 12492\n",
            "Epoch: [13]  [ 20/109]  eta: 0:02:33  lr: 0.000238  min_lr: 0.000238  loss: 0.9876 (1.0073)  class_acc: 0.7344 (0.7307)  weight_decay: 0.0500 (0.0500)  time: 1.6142  data: 0.0016  max mem: 12492\n",
            "Epoch: [13]  [ 30/109]  eta: 0:02:12  lr: 0.000236  min_lr: 0.000236  loss: 0.9939 (1.0000)  class_acc: 0.7344 (0.7349)  weight_decay: 0.0500 (0.0500)  time: 1.6101  data: 0.0010  max mem: 12492\n",
            "Epoch: [13]  [ 40/109]  eta: 0:01:54  lr: 0.000234  min_lr: 0.000234  loss: 0.9483 (0.9917)  class_acc: 0.7500 (0.7435)  weight_decay: 0.0500 (0.0500)  time: 1.5993  data: 0.0014  max mem: 12492\n",
            "Epoch: [13]  [ 50/109]  eta: 0:01:37  lr: 0.000233  min_lr: 0.000233  loss: 0.9813 (0.9988)  class_acc: 0.7344 (0.7381)  weight_decay: 0.0500 (0.0500)  time: 1.5903  data: 0.0021  max mem: 12492\n",
            "Epoch: [13]  [ 60/109]  eta: 0:01:20  lr: 0.000231  min_lr: 0.000231  loss: 1.0197 (0.9985)  class_acc: 0.7188 (0.7380)  weight_decay: 0.0500 (0.0500)  time: 1.5890  data: 0.0018  max mem: 12492\n",
            "Epoch: [13]  [ 70/109]  eta: 0:01:03  lr: 0.000229  min_lr: 0.000229  loss: 0.9974 (0.9956)  class_acc: 0.7344 (0.7405)  weight_decay: 0.0500 (0.0500)  time: 1.5962  data: 0.0015  max mem: 12492\n",
            "Epoch: [13]  [ 80/109]  eta: 0:00:47  lr: 0.000227  min_lr: 0.000227  loss: 0.9604 (0.9943)  class_acc: 0.7500 (0.7419)  weight_decay: 0.0500 (0.0500)  time: 1.6012  data: 0.0020  max mem: 12492\n",
            "Epoch: [13]  [ 90/109]  eta: 0:00:30  lr: 0.000225  min_lr: 0.000225  loss: 0.9525 (0.9902)  class_acc: 0.7500 (0.7440)  weight_decay: 0.0500 (0.0500)  time: 1.6010  data: 0.0021  max mem: 12492\n",
            "Epoch: [13]  [100/109]  eta: 0:00:14  lr: 0.000223  min_lr: 0.000223  loss: 0.9525 (0.9874)  class_acc: 0.7656 (0.7454)  weight_decay: 0.0500 (0.0500)  time: 1.5974  data: 0.0022  max mem: 12492\n",
            "Epoch: [13]  [108/109]  eta: 0:00:01  lr: 0.000222  min_lr: 0.000222  loss: 0.9724 (0.9904)  class_acc: 0.7344 (0.7435)  weight_decay: 0.0500 (0.0500)  time: 1.5939  data: 0.0013  max mem: 12492\n",
            "Epoch: [13] Total time: 0:02:56 (1.6234 s / it)\n",
            "Averaged stats: lr: 0.000222  min_lr: 0.000222  loss: 0.9724 (0.9904)  class_acc: 0.7344 (0.7435)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:01:33  loss: 1.5609 (1.5609)  acc1: 34.3750 (34.3750)  acc5: 100.0000 (100.0000)  time: 4.4339  data: 3.6135  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:12  loss: 0.8428 (0.8868)  acc1: 61.4583 (66.2879)  acc5: 100.0000 (99.2424)  time: 1.1013  data: 0.3288  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.3628 (0.6579)  acc1: 88.5417 (76.9576)  acc5: 100.0000 (99.5012)  time: 0.7665  data: 0.0003  max mem: 12492\n",
            "Test: Total time: 0:00:20 (0.9553 s / it)\n",
            "* Acc@1 76.958 Acc@5 99.501 loss 0.658\n",
            "Accuracy of the model on the 2005 test images: 77.0%\n",
            "Max accuracy: 78.25%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [14]  [  0/109]  eta: 0:07:18  lr: 0.000221  min_lr: 0.000221  loss: 1.0768 (1.0768)  class_acc: 0.7031 (0.7031)  weight_decay: 0.0500 (0.0500)  time: 4.0242  data: 2.2576  max mem: 12492\n",
            "Epoch: [14]  [ 10/109]  eta: 0:03:01  lr: 0.000219  min_lr: 0.000219  loss: 0.9326 (0.9819)  class_acc: 0.7812 (0.7557)  weight_decay: 0.0500 (0.0500)  time: 1.8318  data: 0.2063  max mem: 12492\n",
            "Epoch: [14]  [ 20/109]  eta: 0:02:33  lr: 0.000218  min_lr: 0.000218  loss: 0.9884 (0.9946)  class_acc: 0.7500 (0.7485)  weight_decay: 0.0500 (0.0500)  time: 1.6114  data: 0.0018  max mem: 12492\n",
            "Epoch: [14]  [ 30/109]  eta: 0:02:13  lr: 0.000216  min_lr: 0.000216  loss: 0.9884 (0.9828)  class_acc: 0.7500 (0.7520)  weight_decay: 0.0500 (0.0500)  time: 1.6032  data: 0.0021  max mem: 12492\n",
            "Epoch: [14]  [ 40/109]  eta: 0:01:54  lr: 0.000214  min_lr: 0.000214  loss: 0.9122 (0.9694)  class_acc: 0.7812 (0.7595)  weight_decay: 0.0500 (0.0500)  time: 1.5917  data: 0.0010  max mem: 12492\n",
            "Epoch: [14]  [ 50/109]  eta: 0:01:37  lr: 0.000212  min_lr: 0.000212  loss: 0.9187 (0.9640)  class_acc: 0.7812 (0.7623)  weight_decay: 0.0500 (0.0500)  time: 1.5898  data: 0.0007  max mem: 12492\n",
            "Epoch: [14]  [ 60/109]  eta: 0:01:20  lr: 0.000210  min_lr: 0.000210  loss: 0.9616 (0.9627)  class_acc: 0.7344 (0.7618)  weight_decay: 0.0500 (0.0500)  time: 1.5957  data: 0.0011  max mem: 12492\n",
            "Epoch: [14]  [ 70/109]  eta: 0:01:03  lr: 0.000208  min_lr: 0.000208  loss: 0.9568 (0.9621)  class_acc: 0.7656 (0.7639)  weight_decay: 0.0500 (0.0500)  time: 1.6000  data: 0.0018  max mem: 12492\n",
            "Epoch: [14]  [ 80/109]  eta: 0:00:47  lr: 0.000206  min_lr: 0.000206  loss: 0.9441 (0.9590)  class_acc: 0.7656 (0.7643)  weight_decay: 0.0500 (0.0500)  time: 1.6020  data: 0.0020  max mem: 12492\n",
            "Epoch: [14]  [ 90/109]  eta: 0:00:30  lr: 0.000204  min_lr: 0.000204  loss: 0.9098 (0.9567)  class_acc: 0.7656 (0.7656)  weight_decay: 0.0500 (0.0500)  time: 1.6023  data: 0.0021  max mem: 12492\n",
            "Epoch: [14]  [100/109]  eta: 0:00:14  lr: 0.000202  min_lr: 0.000202  loss: 0.9083 (0.9510)  class_acc: 0.7812 (0.7673)  weight_decay: 0.0500 (0.0500)  time: 1.5998  data: 0.0017  max mem: 12492\n",
            "Epoch: [14]  [108/109]  eta: 0:00:01  lr: 0.000201  min_lr: 0.000201  loss: 0.9346 (0.9550)  class_acc: 0.7656 (0.7646)  weight_decay: 0.0500 (0.0500)  time: 1.5979  data: 0.0008  max mem: 12492\n",
            "Epoch: [14] Total time: 0:02:57 (1.6264 s / it)\n",
            "Averaged stats: lr: 0.000201  min_lr: 0.000201  loss: 0.9346 (0.9550)  class_acc: 0.7656 (0.7646)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:01:12  loss: 1.4028 (1.4028)  acc1: 47.9167 (47.9167)  acc5: 98.9583 (98.9583)  time: 3.4616  data: 2.6675  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:11  loss: 0.8433 (0.8748)  acc1: 67.7083 (67.7083)  acc5: 100.0000 (98.9583)  time: 1.0155  data: 0.2427  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.4815 (0.6795)  acc1: 83.3333 (76.1097)  acc5: 100.0000 (99.3017)  time: 0.7684  data: 0.0002  max mem: 12492\n",
            "Test: Total time: 0:00:19 (0.9105 s / it)\n",
            "* Acc@1 76.110 Acc@5 99.302 loss 0.680\n",
            "Accuracy of the model on the 2005 test images: 76.1%\n",
            "Max accuracy: 78.25%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [15]  [  0/109]  eta: 0:07:25  lr: 0.000200  min_lr: 0.000200  loss: 1.0530 (1.0530)  class_acc: 0.6562 (0.6562)  weight_decay: 0.0500 (0.0500)  time: 4.0827  data: 2.4164  max mem: 12492\n",
            "Epoch: [15]  [ 10/109]  eta: 0:03:01  lr: 0.000199  min_lr: 0.000199  loss: 0.9414 (0.9760)  class_acc: 0.7500 (0.7401)  weight_decay: 0.0500 (0.0500)  time: 1.8316  data: 0.2223  max mem: 12492\n",
            "Epoch: [15]  [ 20/109]  eta: 0:02:33  lr: 0.000197  min_lr: 0.000197  loss: 0.9414 (0.9786)  class_acc: 0.7500 (0.7433)  weight_decay: 0.0500 (0.0500)  time: 1.6093  data: 0.0024  max mem: 12492\n",
            "Epoch: [15]  [ 30/109]  eta: 0:02:13  lr: 0.000195  min_lr: 0.000195  loss: 0.9403 (0.9685)  class_acc: 0.7656 (0.7490)  weight_decay: 0.0500 (0.0500)  time: 1.6054  data: 0.0017  max mem: 12492\n",
            "Epoch: [15]  [ 40/109]  eta: 0:01:54  lr: 0.000193  min_lr: 0.000193  loss: 0.9340 (0.9574)  class_acc: 0.7812 (0.7580)  weight_decay: 0.0500 (0.0500)  time: 1.5948  data: 0.0016  max mem: 12492\n",
            "Epoch: [15]  [ 50/109]  eta: 0:01:37  lr: 0.000191  min_lr: 0.000191  loss: 0.8844 (0.9528)  class_acc: 0.7812 (0.7567)  weight_decay: 0.0500 (0.0500)  time: 1.5930  data: 0.0015  max mem: 12492\n",
            "Epoch: [15]  [ 60/109]  eta: 0:01:20  lr: 0.000189  min_lr: 0.000189  loss: 0.9547 (0.9526)  class_acc: 0.7500 (0.7572)  weight_decay: 0.0500 (0.0500)  time: 1.5959  data: 0.0007  max mem: 12492\n",
            "Epoch: [15]  [ 70/109]  eta: 0:01:03  lr: 0.000187  min_lr: 0.000187  loss: 0.9411 (0.9490)  class_acc: 0.7656 (0.7603)  weight_decay: 0.0500 (0.0500)  time: 1.5982  data: 0.0006  max mem: 12492\n",
            "Epoch: [15]  [ 80/109]  eta: 0:00:47  lr: 0.000185  min_lr: 0.000185  loss: 0.9065 (0.9455)  class_acc: 0.7656 (0.7639)  weight_decay: 0.0500 (0.0500)  time: 1.6018  data: 0.0017  max mem: 12492\n",
            "Epoch: [15]  [ 90/109]  eta: 0:00:30  lr: 0.000183  min_lr: 0.000183  loss: 0.9118 (0.9413)  class_acc: 0.7812 (0.7641)  weight_decay: 0.0500 (0.0500)  time: 1.6036  data: 0.0029  max mem: 12492\n",
            "Epoch: [15]  [100/109]  eta: 0:00:14  lr: 0.000181  min_lr: 0.000181  loss: 0.9118 (0.9382)  class_acc: 0.7812 (0.7673)  weight_decay: 0.0500 (0.0500)  time: 1.6015  data: 0.0019  max mem: 12492\n",
            "Epoch: [15]  [108/109]  eta: 0:00:01  lr: 0.000180  min_lr: 0.000180  loss: 0.9381 (0.9404)  class_acc: 0.7812 (0.7673)  weight_decay: 0.0500 (0.0500)  time: 1.6011  data: 0.0008  max mem: 12492\n",
            "Epoch: [15] Total time: 0:02:57 (1.6271 s / it)\n",
            "Averaged stats: lr: 0.000180  min_lr: 0.000180  loss: 0.9381 (0.9404)  class_acc: 0.7812 (0.7673)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:01:13  loss: 1.4252 (1.4252)  acc1: 47.9167 (47.9167)  acc5: 100.0000 (100.0000)  time: 3.5219  data: 2.7286  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:11  loss: 0.7675 (0.8770)  acc1: 66.6667 (67.2349)  acc5: 100.0000 (99.2424)  time: 1.0212  data: 0.2483  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.4084 (0.6594)  acc1: 88.5417 (77.3067)  acc5: 100.0000 (99.4514)  time: 0.7695  data: 0.0002  max mem: 12492\n",
            "Test: Total time: 0:00:19 (0.9146 s / it)\n",
            "* Acc@1 77.307 Acc@5 99.451 loss 0.659\n",
            "Accuracy of the model on the 2005 test images: 77.3%\n",
            "Max accuracy: 78.25%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [16]  [  0/109]  eta: 0:07:18  lr: 0.000180  min_lr: 0.000180  loss: 1.1134 (1.1134)  class_acc: 0.6719 (0.6719)  weight_decay: 0.0500 (0.0500)  time: 4.0229  data: 2.1120  max mem: 12492\n",
            "Epoch: [16]  [ 10/109]  eta: 0:03:01  lr: 0.000178  min_lr: 0.000178  loss: 1.0274 (0.9845)  class_acc: 0.7188 (0.7528)  weight_decay: 0.0500 (0.0500)  time: 1.8295  data: 0.1933  max mem: 12492\n",
            "Epoch: [16]  [ 20/109]  eta: 0:02:33  lr: 0.000176  min_lr: 0.000176  loss: 0.9833 (0.9816)  class_acc: 0.7344 (0.7493)  weight_decay: 0.0500 (0.0500)  time: 1.6100  data: 0.0009  max mem: 12492\n",
            "Epoch: [16]  [ 30/109]  eta: 0:02:13  lr: 0.000174  min_lr: 0.000174  loss: 0.9459 (0.9624)  class_acc: 0.7656 (0.7550)  weight_decay: 0.0500 (0.0500)  time: 1.6059  data: 0.0011  max mem: 12492\n",
            "Epoch: [16]  [ 40/109]  eta: 0:01:54  lr: 0.000172  min_lr: 0.000172  loss: 0.8901 (0.9440)  class_acc: 0.7656 (0.7645)  weight_decay: 0.0500 (0.0500)  time: 1.5979  data: 0.0018  max mem: 12492\n",
            "Epoch: [16]  [ 50/109]  eta: 0:01:37  lr: 0.000170  min_lr: 0.000170  loss: 0.8755 (0.9348)  class_acc: 0.7969 (0.7699)  weight_decay: 0.0500 (0.0500)  time: 1.5939  data: 0.0018  max mem: 12492\n",
            "Epoch: [16]  [ 60/109]  eta: 0:01:20  lr: 0.000168  min_lr: 0.000168  loss: 0.8774 (0.9324)  class_acc: 0.7812 (0.7720)  weight_decay: 0.0500 (0.0500)  time: 1.5972  data: 0.0021  max mem: 12492\n",
            "Epoch: [16]  [ 70/109]  eta: 0:01:03  lr: 0.000166  min_lr: 0.000166  loss: 0.9503 (0.9348)  class_acc: 0.7656 (0.7709)  weight_decay: 0.0500 (0.0500)  time: 1.6019  data: 0.0014  max mem: 12492\n",
            "Epoch: [16]  [ 80/109]  eta: 0:00:47  lr: 0.000164  min_lr: 0.000164  loss: 0.9113 (0.9309)  class_acc: 0.7656 (0.7718)  weight_decay: 0.0500 (0.0500)  time: 1.6021  data: 0.0008  max mem: 12492\n",
            "Epoch: [16]  [ 90/109]  eta: 0:00:30  lr: 0.000163  min_lr: 0.000163  loss: 0.8928 (0.9282)  class_acc: 0.7812 (0.7730)  weight_decay: 0.0500 (0.0500)  time: 1.5991  data: 0.0015  max mem: 12492\n",
            "Epoch: [16]  [100/109]  eta: 0:00:14  lr: 0.000161  min_lr: 0.000161  loss: 0.9053 (0.9284)  class_acc: 0.7812 (0.7724)  weight_decay: 0.0500 (0.0500)  time: 1.5966  data: 0.0009  max mem: 12492\n",
            "Epoch: [16]  [108/109]  eta: 0:00:01  lr: 0.000159  min_lr: 0.000159  loss: 0.9061 (0.9281)  class_acc: 0.7812 (0.7731)  weight_decay: 0.0500 (0.0500)  time: 1.5972  data: 0.0008  max mem: 12492\n",
            "Epoch: [16] Total time: 0:02:57 (1.6254 s / it)\n",
            "Averaged stats: lr: 0.000159  min_lr: 0.000159  loss: 0.9061 (0.9281)  class_acc: 0.7812 (0.7731)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:00:57  loss: 1.3433 (1.3433)  acc1: 46.8750 (46.8750)  acc5: 98.9583 (98.9583)  time: 2.7217  data: 1.8897  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:10  loss: 0.9109 (0.8589)  acc1: 63.5417 (68.8447)  acc5: 100.0000 (99.0530)  time: 0.9507  data: 0.1726  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.4226 (0.6457)  acc1: 86.4583 (78.1047)  acc5: 100.0000 (99.3017)  time: 0.7705  data: 0.0005  max mem: 12492\n",
            "Test: Total time: 0:00:18 (0.8774 s / it)\n",
            "* Acc@1 78.105 Acc@5 99.302 loss 0.646\n",
            "Accuracy of the model on the 2005 test images: 78.1%\n",
            "Max accuracy: 78.25%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [17]  [  0/109]  eta: 0:07:46  lr: 0.000159  min_lr: 0.000159  loss: 0.9829 (0.9829)  class_acc: 0.7188 (0.7188)  weight_decay: 0.0500 (0.0500)  time: 4.2816  data: 2.4020  max mem: 12492\n",
            "Epoch: [17]  [ 10/109]  eta: 0:03:03  lr: 0.000157  min_lr: 0.000157  loss: 0.9356 (0.9459)  class_acc: 0.7656 (0.7713)  weight_decay: 0.0500 (0.0500)  time: 1.8516  data: 0.2215  max mem: 12492\n",
            "Epoch: [17]  [ 20/109]  eta: 0:02:34  lr: 0.000155  min_lr: 0.000155  loss: 0.9327 (0.9412)  class_acc: 0.7656 (0.7649)  weight_decay: 0.0500 (0.0500)  time: 1.6108  data: 0.0018  max mem: 12492\n",
            "Epoch: [17]  [ 30/109]  eta: 0:02:13  lr: 0.000153  min_lr: 0.000153  loss: 0.9264 (0.9326)  class_acc: 0.7656 (0.7681)  weight_decay: 0.0500 (0.0500)  time: 1.6074  data: 0.0013  max mem: 12492\n",
            "Epoch: [17]  [ 40/109]  eta: 0:01:55  lr: 0.000152  min_lr: 0.000152  loss: 0.8872 (0.9206)  class_acc: 0.7969 (0.7759)  weight_decay: 0.0500 (0.0500)  time: 1.5978  data: 0.0021  max mem: 12492\n",
            "Epoch: [17]  [ 50/109]  eta: 0:01:37  lr: 0.000150  min_lr: 0.000150  loss: 0.8799 (0.9169)  class_acc: 0.7969 (0.7760)  weight_decay: 0.0500 (0.0500)  time: 1.5918  data: 0.0019  max mem: 12492\n",
            "Epoch: [17]  [ 60/109]  eta: 0:01:20  lr: 0.000148  min_lr: 0.000148  loss: 0.9380 (0.9192)  class_acc: 0.7656 (0.7748)  weight_decay: 0.0500 (0.0500)  time: 1.5923  data: 0.0016  max mem: 12492\n",
            "Epoch: [17]  [ 70/109]  eta: 0:01:03  lr: 0.000146  min_lr: 0.000146  loss: 0.9179 (0.9170)  class_acc: 0.7812 (0.7775)  weight_decay: 0.0500 (0.0500)  time: 1.5945  data: 0.0011  max mem: 12492\n",
            "Epoch: [17]  [ 80/109]  eta: 0:00:47  lr: 0.000144  min_lr: 0.000144  loss: 0.9059 (0.9167)  class_acc: 0.7812 (0.7772)  weight_decay: 0.0500 (0.0500)  time: 1.5963  data: 0.0009  max mem: 12492\n",
            "Epoch: [17]  [ 90/109]  eta: 0:00:30  lr: 0.000142  min_lr: 0.000142  loss: 0.8916 (0.9086)  class_acc: 0.7812 (0.7797)  weight_decay: 0.0500 (0.0500)  time: 1.5986  data: 0.0010  max mem: 12492\n",
            "Epoch: [17]  [100/109]  eta: 0:00:14  lr: 0.000140  min_lr: 0.000140  loss: 0.8440 (0.9066)  class_acc: 0.7969 (0.7812)  weight_decay: 0.0500 (0.0500)  time: 1.5983  data: 0.0005  max mem: 12492\n",
            "Epoch: [17]  [108/109]  eta: 0:00:01  lr: 0.000139  min_lr: 0.000139  loss: 0.8931 (0.9093)  class_acc: 0.7812 (0.7800)  weight_decay: 0.0500 (0.0500)  time: 1.5979  data: 0.0002  max mem: 12492\n",
            "Epoch: [17] Total time: 0:02:57 (1.6262 s / it)\n",
            "Averaged stats: lr: 0.000139  min_lr: 0.000139  loss: 0.8931 (0.9093)  class_acc: 0.7812 (0.7800)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:01:17  loss: 1.1760 (1.1760)  acc1: 52.0833 (52.0833)  acc5: 98.9583 (98.9583)  time: 3.6842  data: 2.8791  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:11  loss: 0.9856 (0.8232)  acc1: 59.3750 (68.4659)  acc5: 100.0000 (98.9583)  time: 1.0390  data: 0.2644  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.4012 (0.6192)  acc1: 87.5000 (78.4539)  acc5: 100.0000 (99.3017)  time: 0.7710  data: 0.0015  max mem: 12492\n",
            "Test: Total time: 0:00:19 (0.9314 s / it)\n",
            "* Acc@1 78.454 Acc@5 99.302 loss 0.619\n",
            "Accuracy of the model on the 2005 test images: 78.5%\n",
            "Max accuracy: 78.45%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [18]  [  0/109]  eta: 0:09:00  lr: 0.000139  min_lr: 0.000139  loss: 0.9840 (0.9840)  class_acc: 0.7344 (0.7344)  weight_decay: 0.0500 (0.0500)  time: 4.9542  data: 3.2697  max mem: 12492\n",
            "Epoch: [18]  [ 10/109]  eta: 0:03:09  lr: 0.000137  min_lr: 0.000137  loss: 0.8923 (0.9104)  class_acc: 0.7969 (0.7798)  weight_decay: 0.0500 (0.0500)  time: 1.9103  data: 0.3005  max mem: 12492\n",
            "Epoch: [18]  [ 20/109]  eta: 0:02:37  lr: 0.000135  min_lr: 0.000135  loss: 0.8964 (0.9252)  class_acc: 0.7656 (0.7760)  weight_decay: 0.0500 (0.0500)  time: 1.6123  data: 0.0025  max mem: 12492\n",
            "Epoch: [18]  [ 30/109]  eta: 0:02:15  lr: 0.000133  min_lr: 0.000133  loss: 0.9223 (0.9175)  class_acc: 0.7656 (0.7797)  weight_decay: 0.0500 (0.0500)  time: 1.6100  data: 0.0017  max mem: 12492\n",
            "Epoch: [18]  [ 40/109]  eta: 0:01:56  lr: 0.000132  min_lr: 0.000132  loss: 0.8495 (0.8980)  class_acc: 0.8125 (0.7877)  weight_decay: 0.0500 (0.0500)  time: 1.5948  data: 0.0016  max mem: 12492\n",
            "Epoch: [18]  [ 50/109]  eta: 0:01:38  lr: 0.000130  min_lr: 0.000130  loss: 0.8417 (0.8984)  class_acc: 0.8125 (0.7886)  weight_decay: 0.0500 (0.0500)  time: 1.5885  data: 0.0009  max mem: 12492\n",
            "Epoch: [18]  [ 60/109]  eta: 0:01:21  lr: 0.000128  min_lr: 0.000128  loss: 0.8722 (0.8976)  class_acc: 0.7969 (0.7879)  weight_decay: 0.0500 (0.0500)  time: 1.5934  data: 0.0014  max mem: 12492\n",
            "Epoch: [18]  [ 70/109]  eta: 0:01:04  lr: 0.000126  min_lr: 0.000126  loss: 0.8853 (0.8994)  class_acc: 0.7969 (0.7879)  weight_decay: 0.0500 (0.0500)  time: 1.5991  data: 0.0017  max mem: 12492\n",
            "Epoch: [18]  [ 80/109]  eta: 0:00:47  lr: 0.000124  min_lr: 0.000124  loss: 0.8648 (0.8919)  class_acc: 0.7969 (0.7915)  weight_decay: 0.0500 (0.0500)  time: 1.5999  data: 0.0014  max mem: 12492\n",
            "Epoch: [18]  [ 90/109]  eta: 0:00:31  lr: 0.000123  min_lr: 0.000123  loss: 0.8641 (0.8900)  class_acc: 0.8125 (0.7929)  weight_decay: 0.0500 (0.0500)  time: 1.6007  data: 0.0021  max mem: 12492\n",
            "Epoch: [18]  [100/109]  eta: 0:00:14  lr: 0.000121  min_lr: 0.000121  loss: 0.8807 (0.8871)  class_acc: 0.7969 (0.7938)  weight_decay: 0.0500 (0.0500)  time: 1.5972  data: 0.0019  max mem: 12492\n",
            "Epoch: [18]  [108/109]  eta: 0:00:01  lr: 0.000120  min_lr: 0.000120  loss: 0.8838 (0.8879)  class_acc: 0.7969 (0.7933)  weight_decay: 0.0500 (0.0500)  time: 1.5917  data: 0.0007  max mem: 12492\n",
            "Epoch: [18] Total time: 0:02:57 (1.6321 s / it)\n",
            "Averaged stats: lr: 0.000120  min_lr: 0.000120  loss: 0.8838 (0.8879)  class_acc: 0.7969 (0.7933)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:01:21  loss: 1.4385 (1.4385)  acc1: 47.9167 (47.9167)  acc5: 98.9583 (98.9583)  time: 3.9009  data: 3.0531  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:11  loss: 0.9979 (0.8779)  acc1: 55.2083 (67.7083)  acc5: 98.9583 (98.7689)  time: 1.0548  data: 0.2779  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.3600 (0.6336)  acc1: 88.5417 (78.3042)  acc5: 100.0000 (99.2020)  time: 0.7679  data: 0.0003  max mem: 12492\n",
            "Test: Total time: 0:00:19 (0.9361 s / it)\n",
            "* Acc@1 78.304 Acc@5 99.202 loss 0.634\n",
            "Accuracy of the model on the 2005 test images: 78.3%\n",
            "Max accuracy: 78.45%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [19]  [  0/109]  eta: 0:08:08  lr: 0.000119  min_lr: 0.000119  loss: 0.9212 (0.9212)  class_acc: 0.7812 (0.7812)  weight_decay: 0.0500 (0.0500)  time: 4.4836  data: 2.7999  max mem: 12492\n",
            "Epoch: [19]  [ 10/109]  eta: 0:03:05  lr: 0.000118  min_lr: 0.000118  loss: 0.9073 (0.9102)  class_acc: 0.7812 (0.7827)  weight_decay: 0.0500 (0.0500)  time: 1.8715  data: 0.2559  max mem: 12492\n",
            "Epoch: [19]  [ 20/109]  eta: 0:02:35  lr: 0.000116  min_lr: 0.000116  loss: 0.9073 (0.9123)  class_acc: 0.7656 (0.7835)  weight_decay: 0.0500 (0.0500)  time: 1.6116  data: 0.0023  max mem: 12492\n",
            "Epoch: [19]  [ 30/109]  eta: 0:02:14  lr: 0.000114  min_lr: 0.000114  loss: 0.8668 (0.8982)  class_acc: 0.8125 (0.7873)  weight_decay: 0.0500 (0.0500)  time: 1.6052  data: 0.0017  max mem: 12492\n",
            "Epoch: [19]  [ 40/109]  eta: 0:01:55  lr: 0.000112  min_lr: 0.000112  loss: 0.8544 (0.8817)  class_acc: 0.8125 (0.7946)  weight_decay: 0.0500 (0.0500)  time: 1.5954  data: 0.0006  max mem: 12492\n",
            "Epoch: [19]  [ 50/109]  eta: 0:01:37  lr: 0.000111  min_lr: 0.000111  loss: 0.8264 (0.8758)  class_acc: 0.8281 (0.7978)  weight_decay: 0.0500 (0.0500)  time: 1.5937  data: 0.0011  max mem: 12492\n",
            "Epoch: [19]  [ 60/109]  eta: 0:01:20  lr: 0.000109  min_lr: 0.000109  loss: 0.8426 (0.8763)  class_acc: 0.8125 (0.7997)  weight_decay: 0.0500 (0.0500)  time: 1.5961  data: 0.0015  max mem: 12492\n",
            "Epoch: [19]  [ 70/109]  eta: 0:01:04  lr: 0.000107  min_lr: 0.000107  loss: 0.8626 (0.8763)  class_acc: 0.7969 (0.7995)  weight_decay: 0.0500 (0.0500)  time: 1.5989  data: 0.0014  max mem: 12492\n",
            "Epoch: [19]  [ 80/109]  eta: 0:00:47  lr: 0.000106  min_lr: 0.000106  loss: 0.8626 (0.8751)  class_acc: 0.7969 (0.8009)  weight_decay: 0.0500 (0.0500)  time: 1.6013  data: 0.0022  max mem: 12492\n",
            "Epoch: [19]  [ 90/109]  eta: 0:00:31  lr: 0.000104  min_lr: 0.000104  loss: 0.8370 (0.8696)  class_acc: 0.8125 (0.8022)  weight_decay: 0.0500 (0.0500)  time: 1.6030  data: 0.0026  max mem: 12492\n",
            "Epoch: [19]  [100/109]  eta: 0:00:14  lr: 0.000102  min_lr: 0.000102  loss: 0.8049 (0.8652)  class_acc: 0.8281 (0.8045)  weight_decay: 0.0500 (0.0500)  time: 1.6008  data: 0.0014  max mem: 12492\n",
            "Epoch: [19]  [108/109]  eta: 0:00:01  lr: 0.000101  min_lr: 0.000101  loss: 0.8282 (0.8684)  class_acc: 0.8281 (0.8045)  weight_decay: 0.0500 (0.0500)  time: 1.5979  data: 0.0005  max mem: 12492\n",
            "Epoch: [19] Total time: 0:02:57 (1.6316 s / it)\n",
            "Averaged stats: lr: 0.000101  min_lr: 0.000101  loss: 0.8282 (0.8684)  class_acc: 0.8281 (0.8045)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:01:15  loss: 1.4023 (1.4023)  acc1: 48.9583 (48.9583)  acc5: 100.0000 (100.0000)  time: 3.5941  data: 2.7891  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:11  loss: 1.0244 (0.8933)  acc1: 57.2917 (66.0985)  acc5: 98.9583 (98.8636)  time: 1.0263  data: 0.2537  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.3350 (0.6271)  acc1: 90.6250 (78.3541)  acc5: 100.0000 (99.2519)  time: 0.7681  data: 0.0002  max mem: 12492\n",
            "Test: Total time: 0:00:19 (0.9177 s / it)\n",
            "* Acc@1 78.354 Acc@5 99.252 loss 0.627\n",
            "Accuracy of the model on the 2005 test images: 78.4%\n",
            "Max accuracy: 78.45%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [20]  [  0/109]  eta: 0:07:44  lr: 0.000101  min_lr: 0.000101  loss: 0.9024 (0.9024)  class_acc: 0.7656 (0.7656)  weight_decay: 0.0500 (0.0500)  time: 4.2606  data: 2.5808  max mem: 12492\n",
            "Epoch: [20]  [ 10/109]  eta: 0:03:03  lr: 0.000099  min_lr: 0.000099  loss: 0.8206 (0.8684)  class_acc: 0.8125 (0.7969)  weight_decay: 0.0500 (0.0500)  time: 1.8533  data: 0.2374  max mem: 12492\n",
            "Epoch: [20]  [ 20/109]  eta: 0:02:34  lr: 0.000097  min_lr: 0.000097  loss: 0.8471 (0.8649)  class_acc: 0.7969 (0.8051)  weight_decay: 0.0500 (0.0500)  time: 1.6145  data: 0.0031  max mem: 12492\n",
            "Epoch: [20]  [ 30/109]  eta: 0:02:14  lr: 0.000096  min_lr: 0.000096  loss: 0.8477 (0.8517)  class_acc: 0.7969 (0.8080)  weight_decay: 0.0500 (0.0500)  time: 1.6101  data: 0.0021  max mem: 12492\n",
            "Epoch: [20]  [ 40/109]  eta: 0:01:55  lr: 0.000094  min_lr: 0.000094  loss: 0.8355 (0.8532)  class_acc: 0.8125 (0.8095)  weight_decay: 0.0500 (0.0500)  time: 1.5992  data: 0.0013  max mem: 12492\n",
            "Epoch: [20]  [ 50/109]  eta: 0:01:37  lr: 0.000093  min_lr: 0.000093  loss: 0.8459 (0.8526)  class_acc: 0.7969 (0.8070)  weight_decay: 0.0500 (0.0500)  time: 1.5940  data: 0.0016  max mem: 12492\n",
            "Epoch: [20]  [ 60/109]  eta: 0:01:20  lr: 0.000091  min_lr: 0.000091  loss: 0.8459 (0.8495)  class_acc: 0.7812 (0.8056)  weight_decay: 0.0500 (0.0500)  time: 1.5956  data: 0.0014  max mem: 12492\n",
            "Epoch: [20]  [ 70/109]  eta: 0:01:03  lr: 0.000089  min_lr: 0.000089  loss: 0.8577 (0.8528)  class_acc: 0.7969 (0.8050)  weight_decay: 0.0500 (0.0500)  time: 1.6001  data: 0.0009  max mem: 12492\n",
            "Epoch: [20]  [ 80/109]  eta: 0:00:47  lr: 0.000088  min_lr: 0.000088  loss: 0.8577 (0.8530)  class_acc: 0.8125 (0.8069)  weight_decay: 0.0500 (0.0500)  time: 1.6036  data: 0.0019  max mem: 12492\n",
            "Epoch: [20]  [ 90/109]  eta: 0:00:31  lr: 0.000086  min_lr: 0.000086  loss: 0.8023 (0.8481)  class_acc: 0.8125 (0.8082)  weight_decay: 0.0500 (0.0500)  time: 1.6021  data: 0.0022  max mem: 12492\n",
            "Epoch: [20]  [100/109]  eta: 0:00:14  lr: 0.000085  min_lr: 0.000085  loss: 0.8150 (0.8483)  class_acc: 0.8125 (0.8085)  weight_decay: 0.0500 (0.0500)  time: 1.5975  data: 0.0009  max mem: 12492\n",
            "Epoch: [20]  [108/109]  eta: 0:00:01  lr: 0.000083  min_lr: 0.000083  loss: 0.8300 (0.8492)  class_acc: 0.8125 (0.8089)  weight_decay: 0.0500 (0.0500)  time: 1.5970  data: 0.0005  max mem: 12492\n",
            "Epoch: [20] Total time: 0:02:57 (1.6297 s / it)\n",
            "Averaged stats: lr: 0.000083  min_lr: 0.000083  loss: 0.8300 (0.8492)  class_acc: 0.8125 (0.8089)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:01:01  loss: 1.0732 (1.0732)  acc1: 56.2500 (56.2500)  acc5: 98.9583 (98.9583)  time: 2.9312  data: 2.1293  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:10  loss: 1.0601 (0.8349)  acc1: 60.4167 (68.7500)  acc5: 98.9583 (98.7689)  time: 0.9664  data: 0.1939  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.3659 (0.6101)  acc1: 90.6250 (79.2519)  acc5: 100.0000 (99.2020)  time: 0.7671  data: 0.0002  max mem: 12492\n",
            "Test: Total time: 0:00:18 (0.8837 s / it)\n",
            "* Acc@1 79.252 Acc@5 99.202 loss 0.610\n",
            "Accuracy of the model on the 2005 test images: 79.3%\n",
            "Max accuracy: 79.25%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [21]  [  0/109]  eta: 0:06:18  lr: 0.000083  min_lr: 0.000083  loss: 0.9270 (0.9270)  class_acc: 0.7500 (0.7500)  weight_decay: 0.0500 (0.0500)  time: 3.4744  data: 1.6697  max mem: 12492\n",
            "Epoch: [21]  [ 10/109]  eta: 0:02:56  lr: 0.000082  min_lr: 0.000082  loss: 0.9053 (0.8838)  class_acc: 0.7969 (0.7940)  weight_decay: 0.0500 (0.0500)  time: 1.7854  data: 0.1550  max mem: 12492\n",
            "Epoch: [21]  [ 20/109]  eta: 0:02:31  lr: 0.000080  min_lr: 0.000080  loss: 0.8657 (0.8807)  class_acc: 0.7969 (0.7924)  weight_decay: 0.0500 (0.0500)  time: 1.6175  data: 0.0025  max mem: 12492\n",
            "Epoch: [21]  [ 30/109]  eta: 0:02:12  lr: 0.000079  min_lr: 0.000079  loss: 0.8494 (0.8535)  class_acc: 0.8125 (0.8080)  weight_decay: 0.0500 (0.0500)  time: 1.6095  data: 0.0008  max mem: 12492\n",
            "Epoch: [21]  [ 40/109]  eta: 0:01:54  lr: 0.000077  min_lr: 0.000077  loss: 0.8084 (0.8434)  class_acc: 0.8438 (0.8155)  weight_decay: 0.0500 (0.0500)  time: 1.5978  data: 0.0008  max mem: 12492\n",
            "Epoch: [21]  [ 50/109]  eta: 0:01:36  lr: 0.000076  min_lr: 0.000076  loss: 0.8084 (0.8389)  class_acc: 0.8125 (0.8171)  weight_decay: 0.0500 (0.0500)  time: 1.5922  data: 0.0012  max mem: 12492\n",
            "Epoch: [21]  [ 60/109]  eta: 0:01:20  lr: 0.000074  min_lr: 0.000074  loss: 0.8159 (0.8423)  class_acc: 0.7969 (0.8140)  weight_decay: 0.0500 (0.0500)  time: 1.5947  data: 0.0016  max mem: 12492\n",
            "Epoch: [21]  [ 70/109]  eta: 0:01:03  lr: 0.000073  min_lr: 0.000073  loss: 0.8278 (0.8429)  class_acc: 0.7969 (0.8134)  weight_decay: 0.0500 (0.0500)  time: 1.6006  data: 0.0016  max mem: 12492\n",
            "Epoch: [21]  [ 80/109]  eta: 0:00:47  lr: 0.000071  min_lr: 0.000071  loss: 0.8278 (0.8432)  class_acc: 0.8281 (0.8150)  weight_decay: 0.0500 (0.0500)  time: 1.6022  data: 0.0020  max mem: 12492\n",
            "Epoch: [21]  [ 90/109]  eta: 0:00:30  lr: 0.000070  min_lr: 0.000070  loss: 0.8128 (0.8375)  class_acc: 0.8438 (0.8183)  weight_decay: 0.0500 (0.0500)  time: 1.6004  data: 0.0021  max mem: 12492\n",
            "Epoch: [21]  [100/109]  eta: 0:00:14  lr: 0.000068  min_lr: 0.000068  loss: 0.7983 (0.8366)  class_acc: 0.8438 (0.8192)  weight_decay: 0.0500 (0.0500)  time: 1.5965  data: 0.0007  max mem: 12492\n",
            "Epoch: [21]  [108/109]  eta: 0:00:01  lr: 0.000067  min_lr: 0.000067  loss: 0.8125 (0.8358)  class_acc: 0.8281 (0.8204)  weight_decay: 0.0500 (0.0500)  time: 1.5947  data: 0.0001  max mem: 12492\n",
            "Epoch: [21] Total time: 0:02:56 (1.6212 s / it)\n",
            "Averaged stats: lr: 0.000067  min_lr: 0.000067  loss: 0.8125 (0.8358)  class_acc: 0.8281 (0.8204)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:01:05  loss: 1.2071 (1.2071)  acc1: 52.0833 (52.0833)  acc5: 98.9583 (98.9583)  time: 3.1130  data: 2.2950  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:10  loss: 0.8396 (0.8353)  acc1: 63.5417 (69.2235)  acc5: 98.9583 (98.6742)  time: 0.9818  data: 0.2097  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.3295 (0.5973)  acc1: 90.6250 (79.8504)  acc5: 100.0000 (99.1521)  time: 0.7669  data: 0.0007  max mem: 12492\n",
            "Test: Total time: 0:00:18 (0.8926 s / it)\n",
            "* Acc@1 79.850 Acc@5 99.152 loss 0.597\n",
            "Accuracy of the model on the 2005 test images: 79.9%\n",
            "Max accuracy: 79.85%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [22]  [  0/109]  eta: 0:09:05  lr: 0.000067  min_lr: 0.000067  loss: 0.7859 (0.7859)  class_acc: 0.8594 (0.8594)  weight_decay: 0.0500 (0.0500)  time: 5.0011  data: 3.1699  max mem: 12492\n",
            "Epoch: [22]  [ 10/109]  eta: 0:03:10  lr: 0.000066  min_lr: 0.000066  loss: 0.8051 (0.8409)  class_acc: 0.8125 (0.7997)  weight_decay: 0.0500 (0.0500)  time: 1.9215  data: 0.2908  max mem: 12492\n",
            "Epoch: [22]  [ 20/109]  eta: 0:02:38  lr: 0.000064  min_lr: 0.000064  loss: 0.8291 (0.8435)  class_acc: 0.8125 (0.8021)  weight_decay: 0.0500 (0.0500)  time: 1.6167  data: 0.0025  max mem: 12492\n",
            "Epoch: [22]  [ 30/109]  eta: 0:02:15  lr: 0.000063  min_lr: 0.000063  loss: 0.8291 (0.8368)  class_acc: 0.8125 (0.8065)  weight_decay: 0.0500 (0.0500)  time: 1.6106  data: 0.0019  max mem: 12492\n",
            "Epoch: [22]  [ 40/109]  eta: 0:01:56  lr: 0.000061  min_lr: 0.000061  loss: 0.8074 (0.8287)  class_acc: 0.8281 (0.8136)  weight_decay: 0.0500 (0.0500)  time: 1.5960  data: 0.0019  max mem: 12492\n",
            "Epoch: [22]  [ 50/109]  eta: 0:01:38  lr: 0.000060  min_lr: 0.000060  loss: 0.7913 (0.8203)  class_acc: 0.8281 (0.8208)  weight_decay: 0.0500 (0.0500)  time: 1.5905  data: 0.0018  max mem: 12492\n",
            "Epoch: [22]  [ 60/109]  eta: 0:01:21  lr: 0.000059  min_lr: 0.000059  loss: 0.7919 (0.8193)  class_acc: 0.8281 (0.8243)  weight_decay: 0.0500 (0.0500)  time: 1.5935  data: 0.0017  max mem: 12492\n",
            "Epoch: [22]  [ 70/109]  eta: 0:01:04  lr: 0.000057  min_lr: 0.000057  loss: 0.8083 (0.8212)  class_acc: 0.8125 (0.8222)  weight_decay: 0.0500 (0.0500)  time: 1.6005  data: 0.0014  max mem: 12492\n",
            "Epoch: [22]  [ 80/109]  eta: 0:00:47  lr: 0.000056  min_lr: 0.000056  loss: 0.8025 (0.8170)  class_acc: 0.8281 (0.8250)  weight_decay: 0.0500 (0.0500)  time: 1.6032  data: 0.0020  max mem: 12492\n",
            "Epoch: [22]  [ 90/109]  eta: 0:00:31  lr: 0.000055  min_lr: 0.000055  loss: 0.7693 (0.8087)  class_acc: 0.8594 (0.8293)  weight_decay: 0.0500 (0.0500)  time: 1.6001  data: 0.0021  max mem: 12492\n",
            "Epoch: [22]  [100/109]  eta: 0:00:14  lr: 0.000053  min_lr: 0.000053  loss: 0.7277 (0.8072)  class_acc: 0.8594 (0.8294)  weight_decay: 0.0500 (0.0500)  time: 1.5954  data: 0.0007  max mem: 12492\n",
            "Epoch: [22]  [108/109]  eta: 0:00:01  lr: 0.000052  min_lr: 0.000052  loss: 0.7816 (0.8108)  class_acc: 0.8281 (0.8278)  weight_decay: 0.0500 (0.0500)  time: 1.5935  data: 0.0001  max mem: 12492\n",
            "Epoch: [22] Total time: 0:02:58 (1.6345 s / it)\n",
            "Averaged stats: lr: 0.000052  min_lr: 0.000052  loss: 0.7816 (0.8108)  class_acc: 0.8281 (0.8278)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:01:17  loss: 1.1725 (1.1725)  acc1: 55.2083 (55.2083)  acc5: 98.9583 (98.9583)  time: 3.6724  data: 2.8532  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:11  loss: 0.9237 (0.8255)  acc1: 62.5000 (70.3598)  acc5: 98.9583 (98.3902)  time: 1.0346  data: 0.2604  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.4529 (0.6443)  acc1: 84.3750 (77.9551)  acc5: 98.9583 (98.8529)  time: 0.7697  data: 0.0006  max mem: 12492\n",
            "Test: Total time: 0:00:19 (0.9311 s / it)\n",
            "* Acc@1 77.955 Acc@5 98.853 loss 0.644\n",
            "Accuracy of the model on the 2005 test images: 78.0%\n",
            "Max accuracy: 79.85%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [23]  [  0/109]  eta: 0:09:39  lr: 0.000052  min_lr: 0.000052  loss: 0.8585 (0.8585)  class_acc: 0.8125 (0.8125)  weight_decay: 0.0500 (0.0500)  time: 5.3176  data: 3.5060  max mem: 12492\n",
            "Epoch: [23]  [ 10/109]  eta: 0:03:12  lr: 0.000051  min_lr: 0.000051  loss: 0.7995 (0.8089)  class_acc: 0.8281 (0.8366)  weight_decay: 0.0500 (0.0500)  time: 1.9468  data: 0.3204  max mem: 12492\n",
            "Epoch: [23]  [ 20/109]  eta: 0:02:39  lr: 0.000050  min_lr: 0.000050  loss: 0.7995 (0.8209)  class_acc: 0.8281 (0.8318)  weight_decay: 0.0500 (0.0500)  time: 1.6123  data: 0.0015  max mem: 12492\n",
            "Epoch: [23]  [ 30/109]  eta: 0:02:16  lr: 0.000048  min_lr: 0.000048  loss: 0.7964 (0.8051)  class_acc: 0.8281 (0.8367)  weight_decay: 0.0500 (0.0500)  time: 1.6073  data: 0.0007  max mem: 12492\n",
            "Epoch: [23]  [ 40/109]  eta: 0:01:56  lr: 0.000047  min_lr: 0.000047  loss: 0.7625 (0.7968)  class_acc: 0.8594 (0.8403)  weight_decay: 0.0500 (0.0500)  time: 1.5958  data: 0.0004  max mem: 12492\n",
            "Epoch: [23]  [ 50/109]  eta: 0:01:38  lr: 0.000046  min_lr: 0.000046  loss: 0.7539 (0.7915)  class_acc: 0.8438 (0.8410)  weight_decay: 0.0500 (0.0500)  time: 1.5930  data: 0.0009  max mem: 12492\n",
            "Epoch: [23]  [ 60/109]  eta: 0:01:21  lr: 0.000045  min_lr: 0.000045  loss: 0.8148 (0.7921)  class_acc: 0.8281 (0.8394)  weight_decay: 0.0500 (0.0500)  time: 1.5976  data: 0.0019  max mem: 12492\n",
            "Epoch: [23]  [ 70/109]  eta: 0:01:04  lr: 0.000044  min_lr: 0.000044  loss: 0.8106 (0.7952)  class_acc: 0.8281 (0.8378)  weight_decay: 0.0500 (0.0500)  time: 1.6017  data: 0.0019  max mem: 12492\n",
            "Epoch: [23]  [ 80/109]  eta: 0:00:47  lr: 0.000042  min_lr: 0.000042  loss: 0.7663 (0.7886)  class_acc: 0.8594 (0.8426)  weight_decay: 0.0500 (0.0500)  time: 1.6021  data: 0.0012  max mem: 12492\n",
            "Epoch: [23]  [ 90/109]  eta: 0:00:31  lr: 0.000041  min_lr: 0.000041  loss: 0.7483 (0.7831)  class_acc: 0.8594 (0.8458)  weight_decay: 0.0500 (0.0500)  time: 1.6005  data: 0.0012  max mem: 12492\n",
            "Epoch: [23]  [100/109]  eta: 0:00:14  lr: 0.000040  min_lr: 0.000040  loss: 0.7527 (0.7822)  class_acc: 0.8438 (0.8453)  weight_decay: 0.0500 (0.0500)  time: 1.5971  data: 0.0007  max mem: 12492\n",
            "Epoch: [23]  [108/109]  eta: 0:00:01  lr: 0.000039  min_lr: 0.000039  loss: 0.7696 (0.7840)  class_acc: 0.8438 (0.8440)  weight_decay: 0.0500 (0.0500)  time: 1.5950  data: 0.0001  max mem: 12492\n",
            "Epoch: [23] Total time: 0:02:58 (1.6374 s / it)\n",
            "Averaged stats: lr: 0.000039  min_lr: 0.000039  loss: 0.7696 (0.7840)  class_acc: 0.8438 (0.8440)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:01:48  loss: 1.1591 (1.1591)  acc1: 55.2083 (55.2083)  acc5: 98.9583 (98.9583)  time: 5.1539  data: 4.3043  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:12  loss: 0.9491 (0.8006)  acc1: 61.4583 (71.7803)  acc5: 98.9583 (98.5795)  time: 1.1668  data: 0.3923  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.3673 (0.5994)  acc1: 88.5417 (80.6484)  acc5: 98.9583 (98.9027)  time: 0.7668  data: 0.0006  max mem: 12492\n",
            "Test: Total time: 0:00:20 (0.9947 s / it)\n",
            "* Acc@1 80.648 Acc@5 98.903 loss 0.599\n",
            "Accuracy of the model on the 2005 test images: 80.6%\n",
            "Max accuracy: 80.65%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [24]  [  0/109]  eta: 0:08:00  lr: 0.000039  min_lr: 0.000039  loss: 0.8968 (0.8968)  class_acc: 0.8281 (0.8281)  weight_decay: 0.0500 (0.0500)  time: 4.4097  data: 2.7928  max mem: 12492\n",
            "Epoch: [24]  [ 10/109]  eta: 0:03:04  lr: 0.000038  min_lr: 0.000038  loss: 0.7973 (0.8124)  class_acc: 0.8125 (0.8338)  weight_decay: 0.0500 (0.0500)  time: 1.8652  data: 0.2551  max mem: 12492\n",
            "Epoch: [24]  [ 20/109]  eta: 0:02:35  lr: 0.000037  min_lr: 0.000037  loss: 0.7923 (0.8151)  class_acc: 0.8125 (0.8318)  weight_decay: 0.0500 (0.0500)  time: 1.6158  data: 0.0013  max mem: 12492\n",
            "Epoch: [24]  [ 30/109]  eta: 0:02:14  lr: 0.000036  min_lr: 0.000036  loss: 0.7923 (0.8085)  class_acc: 0.8438 (0.8337)  weight_decay: 0.0500 (0.0500)  time: 1.6123  data: 0.0011  max mem: 12492\n",
            "Epoch: [24]  [ 40/109]  eta: 0:01:55  lr: 0.000035  min_lr: 0.000035  loss: 0.7808 (0.8040)  class_acc: 0.8438 (0.8361)  weight_decay: 0.0500 (0.0500)  time: 1.5979  data: 0.0009  max mem: 12492\n",
            "Epoch: [24]  [ 50/109]  eta: 0:01:37  lr: 0.000034  min_lr: 0.000034  loss: 0.7808 (0.8032)  class_acc: 0.8438 (0.8392)  weight_decay: 0.0500 (0.0500)  time: 1.5920  data: 0.0017  max mem: 12492\n",
            "Epoch: [24]  [ 60/109]  eta: 0:01:20  lr: 0.000033  min_lr: 0.000033  loss: 0.7305 (0.7944)  class_acc: 0.8594 (0.8425)  weight_decay: 0.0500 (0.0500)  time: 1.5951  data: 0.0018  max mem: 12492\n",
            "Epoch: [24]  [ 70/109]  eta: 0:01:04  lr: 0.000032  min_lr: 0.000032  loss: 0.7517 (0.7932)  class_acc: 0.8438 (0.8431)  weight_decay: 0.0500 (0.0500)  time: 1.6010  data: 0.0009  max mem: 12492\n",
            "Epoch: [24]  [ 80/109]  eta: 0:00:47  lr: 0.000031  min_lr: 0.000031  loss: 0.7483 (0.7885)  class_acc: 0.8438 (0.8445)  weight_decay: 0.0500 (0.0500)  time: 1.6020  data: 0.0009  max mem: 12492\n",
            "Epoch: [24]  [ 90/109]  eta: 0:00:31  lr: 0.000030  min_lr: 0.000030  loss: 0.7320 (0.7829)  class_acc: 0.8750 (0.8470)  weight_decay: 0.0500 (0.0500)  time: 1.5972  data: 0.0012  max mem: 12492\n",
            "Epoch: [24]  [100/109]  eta: 0:00:14  lr: 0.000029  min_lr: 0.000029  loss: 0.7294 (0.7789)  class_acc: 0.8750 (0.8487)  weight_decay: 0.0500 (0.0500)  time: 1.5926  data: 0.0013  max mem: 12492\n",
            "Epoch: [24]  [108/109]  eta: 0:00:01  lr: 0.000028  min_lr: 0.000028  loss: 0.7668 (0.7813)  class_acc: 0.8594 (0.8463)  weight_decay: 0.0500 (0.0500)  time: 1.5950  data: 0.0008  max mem: 12492\n",
            "Epoch: [24] Total time: 0:02:57 (1.6303 s / it)\n",
            "Averaged stats: lr: 0.000028  min_lr: 0.000028  loss: 0.7668 (0.7813)  class_acc: 0.8594 (0.8463)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:01:04  loss: 1.2263 (1.2263)  acc1: 55.2083 (55.2083)  acc5: 97.9167 (97.9167)  time: 3.0551  data: 2.2499  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:10  loss: 0.9517 (0.8284)  acc1: 64.5833 (70.1705)  acc5: 98.9583 (98.5795)  time: 0.9798  data: 0.2071  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.3195 (0.5934)  acc1: 89.5833 (80.0998)  acc5: 100.0000 (99.0524)  time: 0.7695  data: 0.0015  max mem: 12492\n",
            "Test: Total time: 0:00:18 (0.8916 s / it)\n",
            "* Acc@1 80.100 Acc@5 99.052 loss 0.593\n",
            "Accuracy of the model on the 2005 test images: 80.1%\n",
            "Max accuracy: 80.65%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [25]  [  0/109]  eta: 0:07:27  lr: 0.000028  min_lr: 0.000028  loss: 0.8230 (0.8230)  class_acc: 0.8438 (0.8438)  weight_decay: 0.0500 (0.0500)  time: 4.1034  data: 2.3738  max mem: 12492\n",
            "Epoch: [25]  [ 10/109]  eta: 0:03:01  lr: 0.000027  min_lr: 0.000027  loss: 0.8115 (0.8113)  class_acc: 0.8281 (0.8210)  weight_decay: 0.0500 (0.0500)  time: 1.8337  data: 0.2172  max mem: 12492\n",
            "Epoch: [25]  [ 20/109]  eta: 0:02:33  lr: 0.000026  min_lr: 0.000026  loss: 0.7948 (0.7969)  class_acc: 0.8281 (0.8348)  weight_decay: 0.0500 (0.0500)  time: 1.6092  data: 0.0016  max mem: 12492\n",
            "Epoch: [25]  [ 30/109]  eta: 0:02:13  lr: 0.000025  min_lr: 0.000025  loss: 0.7840 (0.7888)  class_acc: 0.8438 (0.8443)  weight_decay: 0.0500 (0.0500)  time: 1.6068  data: 0.0009  max mem: 12492\n",
            "Epoch: [25]  [ 40/109]  eta: 0:01:54  lr: 0.000024  min_lr: 0.000024  loss: 0.7840 (0.7940)  class_acc: 0.8281 (0.8430)  weight_decay: 0.0500 (0.0500)  time: 1.5968  data: 0.0003  max mem: 12492\n",
            "Epoch: [25]  [ 50/109]  eta: 0:01:37  lr: 0.000023  min_lr: 0.000023  loss: 0.7780 (0.7869)  class_acc: 0.8281 (0.8453)  weight_decay: 0.0500 (0.0500)  time: 1.5938  data: 0.0010  max mem: 12492\n",
            "Epoch: [25]  [ 60/109]  eta: 0:01:20  lr: 0.000022  min_lr: 0.000022  loss: 0.7291 (0.7840)  class_acc: 0.8594 (0.8461)  weight_decay: 0.0500 (0.0500)  time: 1.5998  data: 0.0020  max mem: 12492\n",
            "Epoch: [25]  [ 70/109]  eta: 0:01:03  lr: 0.000021  min_lr: 0.000021  loss: 0.7764 (0.7835)  class_acc: 0.8438 (0.8446)  weight_decay: 0.0500 (0.0500)  time: 1.6045  data: 0.0019  max mem: 12492\n",
            "Epoch: [25]  [ 80/109]  eta: 0:00:47  lr: 0.000021  min_lr: 0.000021  loss: 0.7718 (0.7817)  class_acc: 0.8438 (0.8459)  weight_decay: 0.0500 (0.0500)  time: 1.6035  data: 0.0017  max mem: 12492\n",
            "Epoch: [25]  [ 90/109]  eta: 0:00:30  lr: 0.000020  min_lr: 0.000020  loss: 0.7417 (0.7730)  class_acc: 0.8750 (0.8503)  weight_decay: 0.0500 (0.0500)  time: 1.5987  data: 0.0019  max mem: 12492\n",
            "Epoch: [25]  [100/109]  eta: 0:00:14  lr: 0.000019  min_lr: 0.000019  loss: 0.7442 (0.7713)  class_acc: 0.8750 (0.8501)  weight_decay: 0.0500 (0.0500)  time: 1.5965  data: 0.0015  max mem: 12492\n",
            "Epoch: [25]  [108/109]  eta: 0:00:01  lr: 0.000018  min_lr: 0.000018  loss: 0.7554 (0.7748)  class_acc: 0.8438 (0.8482)  weight_decay: 0.0500 (0.0500)  time: 1.5990  data: 0.0011  max mem: 12492\n",
            "Epoch: [25] Total time: 0:02:57 (1.6276 s / it)\n",
            "Averaged stats: lr: 0.000018  min_lr: 0.000018  loss: 0.7554 (0.7748)  class_acc: 0.8438 (0.8482)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:00:56  loss: 1.2879 (1.2879)  acc1: 56.2500 (56.2500)  acc5: 96.8750 (96.8750)  time: 2.6946  data: 1.8263  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:10  loss: 1.0915 (0.8367)  acc1: 64.5833 (70.6439)  acc5: 97.9167 (98.1061)  time: 0.9511  data: 0.1662  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.3316 (0.5990)  acc1: 91.6667 (80.6983)  acc5: 98.9583 (98.7531)  time: 0.7732  data: 0.0002  max mem: 12492\n",
            "Test: Total time: 0:00:18 (0.8779 s / it)\n",
            "* Acc@1 80.698 Acc@5 98.753 loss 0.599\n",
            "Accuracy of the model on the 2005 test images: 80.7%\n",
            "Max accuracy: 80.70%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [26]  [  0/109]  eta: 0:07:07  lr: 0.000018  min_lr: 0.000018  loss: 0.9032 (0.9032)  class_acc: 0.8438 (0.8438)  weight_decay: 0.0500 (0.0500)  time: 3.9229  data: 2.0642  max mem: 12492\n",
            "Epoch: [26]  [ 10/109]  eta: 0:03:00  lr: 0.000017  min_lr: 0.000017  loss: 0.7888 (0.8087)  class_acc: 0.8438 (0.8352)  weight_decay: 0.0500 (0.0500)  time: 1.8219  data: 0.1897  max mem: 12492\n",
            "Epoch: [26]  [ 20/109]  eta: 0:02:33  lr: 0.000017  min_lr: 0.000017  loss: 0.7740 (0.7917)  class_acc: 0.8438 (0.8385)  weight_decay: 0.0500 (0.0500)  time: 1.6129  data: 0.0016  max mem: 12492\n",
            "Epoch: [26]  [ 30/109]  eta: 0:02:13  lr: 0.000016  min_lr: 0.000016  loss: 0.7637 (0.7788)  class_acc: 0.8438 (0.8448)  weight_decay: 0.0500 (0.0500)  time: 1.6091  data: 0.0012  max mem: 12492\n",
            "Epoch: [26]  [ 40/109]  eta: 0:01:54  lr: 0.000015  min_lr: 0.000015  loss: 0.7460 (0.7667)  class_acc: 0.8594 (0.8495)  weight_decay: 0.0500 (0.0500)  time: 1.6008  data: 0.0013  max mem: 12492\n",
            "Epoch: [26]  [ 50/109]  eta: 0:01:37  lr: 0.000015  min_lr: 0.000015  loss: 0.7387 (0.7626)  class_acc: 0.8750 (0.8523)  weight_decay: 0.0500 (0.0500)  time: 1.5947  data: 0.0013  max mem: 12492\n",
            "Epoch: [26]  [ 60/109]  eta: 0:01:20  lr: 0.000014  min_lr: 0.000014  loss: 0.7496 (0.7631)  class_acc: 0.8594 (0.8527)  weight_decay: 0.0500 (0.0500)  time: 1.5937  data: 0.0009  max mem: 12492\n",
            "Epoch: [26]  [ 70/109]  eta: 0:01:03  lr: 0.000013  min_lr: 0.000013  loss: 0.7564 (0.7622)  class_acc: 0.8594 (0.8528)  weight_decay: 0.0500 (0.0500)  time: 1.5986  data: 0.0018  max mem: 12492\n",
            "Epoch: [26]  [ 80/109]  eta: 0:00:47  lr: 0.000013  min_lr: 0.000013  loss: 0.7501 (0.7616)  class_acc: 0.8594 (0.8544)  weight_decay: 0.0500 (0.0500)  time: 1.6001  data: 0.0026  max mem: 12492\n",
            "Epoch: [26]  [ 90/109]  eta: 0:00:30  lr: 0.000012  min_lr: 0.000012  loss: 0.7452 (0.7593)  class_acc: 0.8750 (0.8559)  weight_decay: 0.0500 (0.0500)  time: 1.5978  data: 0.0016  max mem: 12492\n",
            "Epoch: [26]  [100/109]  eta: 0:00:14  lr: 0.000011  min_lr: 0.000011  loss: 0.7226 (0.7558)  class_acc: 0.8594 (0.8567)  weight_decay: 0.0500 (0.0500)  time: 1.5980  data: 0.0006  max mem: 12492\n",
            "Epoch: [26]  [108/109]  eta: 0:00:01  lr: 0.000011  min_lr: 0.000011  loss: 0.7470 (0.7594)  class_acc: 0.8594 (0.8552)  weight_decay: 0.0500 (0.0500)  time: 1.5991  data: 0.0001  max mem: 12492\n",
            "Epoch: [26] Total time: 0:02:57 (1.6250 s / it)\n",
            "Averaged stats: lr: 0.000011  min_lr: 0.000011  loss: 0.7470 (0.7594)  class_acc: 0.8594 (0.8552)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:01:15  loss: 1.2161 (1.2161)  acc1: 56.2500 (56.2500)  acc5: 98.9583 (98.9583)  time: 3.5839  data: 2.7830  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:11  loss: 1.1192 (0.8730)  acc1: 64.5833 (69.5076)  acc5: 98.9583 (98.3902)  time: 1.0292  data: 0.2534  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.3171 (0.6045)  acc1: 91.6667 (80.5985)  acc5: 98.9583 (98.9526)  time: 0.7714  data: 0.0003  max mem: 12492\n",
            "Test: Total time: 0:00:19 (0.9196 s / it)\n",
            "* Acc@1 80.599 Acc@5 98.953 loss 0.605\n",
            "Accuracy of the model on the 2005 test images: 80.6%\n",
            "Max accuracy: 80.70%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [27]  [  0/109]  eta: 0:08:40  lr: 0.000011  min_lr: 0.000011  loss: 0.8151 (0.8151)  class_acc: 0.8281 (0.8281)  weight_decay: 0.0500 (0.0500)  time: 4.7777  data: 2.9217  max mem: 12492\n",
            "Epoch: [27]  [ 10/109]  eta: 0:03:08  lr: 0.000010  min_lr: 0.000010  loss: 0.7761 (0.7839)  class_acc: 0.8594 (0.8537)  weight_decay: 0.0500 (0.0500)  time: 1.9001  data: 0.2677  max mem: 12492\n",
            "Epoch: [27]  [ 20/109]  eta: 0:02:36  lr: 0.000010  min_lr: 0.000010  loss: 0.7631 (0.7785)  class_acc: 0.8594 (0.8549)  weight_decay: 0.0500 (0.0500)  time: 1.6129  data: 0.0015  max mem: 12492\n",
            "Epoch: [27]  [ 30/109]  eta: 0:02:15  lr: 0.000009  min_lr: 0.000009  loss: 0.7589 (0.7772)  class_acc: 0.8438 (0.8533)  weight_decay: 0.0500 (0.0500)  time: 1.6083  data: 0.0015  max mem: 12492\n",
            "Epoch: [27]  [ 40/109]  eta: 0:01:56  lr: 0.000009  min_lr: 0.000009  loss: 0.7589 (0.7710)  class_acc: 0.8594 (0.8563)  weight_decay: 0.0500 (0.0500)  time: 1.5979  data: 0.0023  max mem: 12492\n",
            "Epoch: [27]  [ 50/109]  eta: 0:01:38  lr: 0.000008  min_lr: 0.000008  loss: 0.6990 (0.7621)  class_acc: 0.8750 (0.8588)  weight_decay: 0.0500 (0.0500)  time: 1.5946  data: 0.0014  max mem: 12492\n",
            "Epoch: [27]  [ 60/109]  eta: 0:01:21  lr: 0.000008  min_lr: 0.000008  loss: 0.6990 (0.7613)  class_acc: 0.8750 (0.8604)  weight_decay: 0.0500 (0.0500)  time: 1.5980  data: 0.0015  max mem: 12492\n",
            "Epoch: [27]  [ 70/109]  eta: 0:01:04  lr: 0.000007  min_lr: 0.000007  loss: 0.7441 (0.7639)  class_acc: 0.8594 (0.8581)  weight_decay: 0.0500 (0.0500)  time: 1.6028  data: 0.0025  max mem: 12492\n",
            "Epoch: [27]  [ 80/109]  eta: 0:00:47  lr: 0.000007  min_lr: 0.000007  loss: 0.7407 (0.7627)  class_acc: 0.8594 (0.8586)  weight_decay: 0.0500 (0.0500)  time: 1.6061  data: 0.0025  max mem: 12492\n",
            "Epoch: [27]  [ 90/109]  eta: 0:00:31  lr: 0.000006  min_lr: 0.000006  loss: 0.7334 (0.7562)  class_acc: 0.8750 (0.8609)  weight_decay: 0.0500 (0.0500)  time: 1.6031  data: 0.0021  max mem: 12492\n",
            "Epoch: [27]  [100/109]  eta: 0:00:14  lr: 0.000006  min_lr: 0.000006  loss: 0.7034 (0.7536)  class_acc: 0.8750 (0.8615)  weight_decay: 0.0500 (0.0500)  time: 1.5986  data: 0.0013  max mem: 12492\n",
            "Epoch: [27]  [108/109]  eta: 0:00:01  lr: 0.000005  min_lr: 0.000005  loss: 0.7173 (0.7539)  class_acc: 0.8594 (0.8615)  weight_decay: 0.0500 (0.0500)  time: 1.5976  data: 0.0005  max mem: 12492\n",
            "Epoch: [27] Total time: 0:02:58 (1.6340 s / it)\n",
            "Averaged stats: lr: 0.000005  min_lr: 0.000005  loss: 0.7173 (0.7539)  class_acc: 0.8594 (0.8615)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:01:06  loss: 1.2713 (1.2713)  acc1: 56.2500 (56.2500)  acc5: 96.8750 (96.8750)  time: 3.1481  data: 2.3187  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:10  loss: 1.1309 (0.8674)  acc1: 64.5833 (69.2235)  acc5: 97.9167 (98.1061)  time: 0.9882  data: 0.2125  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.3138 (0.6014)  acc1: 91.6667 (80.4988)  acc5: 98.9583 (98.8030)  time: 0.7688  data: 0.0010  max mem: 12492\n",
            "Test: Total time: 0:00:18 (0.9040 s / it)\n",
            "* Acc@1 80.499 Acc@5 98.803 loss 0.601\n",
            "Accuracy of the model on the 2005 test images: 80.5%\n",
            "Max accuracy: 80.70%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [28]  [  0/109]  eta: 0:09:14  lr: 0.000005  min_lr: 0.000005  loss: 0.9037 (0.9037)  class_acc: 0.7969 (0.7969)  weight_decay: 0.0500 (0.0500)  time: 5.0879  data: 3.2712  max mem: 12492\n",
            "Epoch: [28]  [ 10/109]  eta: 0:03:10  lr: 0.000005  min_lr: 0.000005  loss: 0.7906 (0.7870)  class_acc: 0.8594 (0.8423)  weight_decay: 0.0500 (0.0500)  time: 1.9212  data: 0.2991  max mem: 12492\n",
            "Epoch: [28]  [ 20/109]  eta: 0:02:38  lr: 0.000005  min_lr: 0.000005  loss: 0.7578 (0.7712)  class_acc: 0.8594 (0.8475)  weight_decay: 0.0500 (0.0500)  time: 1.6116  data: 0.0012  max mem: 12492\n",
            "Epoch: [28]  [ 30/109]  eta: 0:02:15  lr: 0.000004  min_lr: 0.000004  loss: 0.7416 (0.7606)  class_acc: 0.8594 (0.8548)  weight_decay: 0.0500 (0.0500)  time: 1.6112  data: 0.0004  max mem: 12492\n",
            "Epoch: [28]  [ 40/109]  eta: 0:01:56  lr: 0.000004  min_lr: 0.000004  loss: 0.7253 (0.7525)  class_acc: 0.8594 (0.8563)  weight_decay: 0.0500 (0.0500)  time: 1.5982  data: 0.0004  max mem: 12492\n",
            "Epoch: [28]  [ 50/109]  eta: 0:01:38  lr: 0.000004  min_lr: 0.000004  loss: 0.7167 (0.7488)  class_acc: 0.8594 (0.8597)  weight_decay: 0.0500 (0.0500)  time: 1.5906  data: 0.0004  max mem: 12492\n",
            "Epoch: [28]  [ 60/109]  eta: 0:01:21  lr: 0.000003  min_lr: 0.000003  loss: 0.7226 (0.7510)  class_acc: 0.8594 (0.8560)  weight_decay: 0.0500 (0.0500)  time: 1.5913  data: 0.0009  max mem: 12492\n",
            "Epoch: [28]  [ 70/109]  eta: 0:01:04  lr: 0.000003  min_lr: 0.000003  loss: 0.7653 (0.7490)  class_acc: 0.8594 (0.8583)  weight_decay: 0.0500 (0.0500)  time: 1.5985  data: 0.0018  max mem: 12492\n",
            "Epoch: [28]  [ 80/109]  eta: 0:00:47  lr: 0.000003  min_lr: 0.000003  loss: 0.7364 (0.7480)  class_acc: 0.8594 (0.8574)  weight_decay: 0.0500 (0.0500)  time: 1.6027  data: 0.0022  max mem: 12492\n",
            "Epoch: [28]  [ 90/109]  eta: 0:00:31  lr: 0.000003  min_lr: 0.000003  loss: 0.7229 (0.7429)  class_acc: 0.8594 (0.8613)  weight_decay: 0.0500 (0.0500)  time: 1.6004  data: 0.0017  max mem: 12492\n",
            "Epoch: [28]  [100/109]  eta: 0:00:14  lr: 0.000002  min_lr: 0.000002  loss: 0.7142 (0.7403)  class_acc: 0.8750 (0.8631)  weight_decay: 0.0500 (0.0500)  time: 1.5975  data: 0.0006  max mem: 12492\n",
            "Epoch: [28]  [108/109]  eta: 0:00:01  lr: 0.000002  min_lr: 0.000002  loss: 0.7444 (0.7454)  class_acc: 0.8438 (0.8611)  weight_decay: 0.0500 (0.0500)  time: 1.5964  data: 0.0001  max mem: 12492\n",
            "Epoch: [28] Total time: 0:02:58 (1.6346 s / it)\n",
            "Averaged stats: lr: 0.000002  min_lr: 0.000002  loss: 0.7444 (0.7454)  class_acc: 0.8438 (0.8611)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:01:12  loss: 1.2522 (1.2522)  acc1: 57.2917 (57.2917)  acc5: 96.8750 (96.8750)  time: 3.4434  data: 2.6076  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:11  loss: 1.1172 (0.8530)  acc1: 63.5417 (70.1705)  acc5: 97.9167 (98.1061)  time: 1.0294  data: 0.2518  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.3325 (0.6040)  acc1: 90.6250 (80.4988)  acc5: 98.9583 (98.7531)  time: 0.7774  data: 0.0082  max mem: 12492\n",
            "Test: Total time: 0:00:19 (0.9244 s / it)\n",
            "* Acc@1 80.499 Acc@5 98.753 loss 0.604\n",
            "Accuracy of the model on the 2005 test images: 80.5%\n",
            "Max accuracy: 80.70%\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "Epoch: [29]  [  0/109]  eta: 0:08:20  lr: 0.000002  min_lr: 0.000002  loss: 0.8030 (0.8030)  class_acc: 0.8281 (0.8281)  weight_decay: 0.0500 (0.0500)  time: 4.5941  data: 2.8148  max mem: 12492\n",
            "Epoch: [29]  [ 10/109]  eta: 0:03:06  lr: 0.000002  min_lr: 0.000002  loss: 0.7650 (0.7501)  class_acc: 0.8594 (0.8693)  weight_decay: 0.0500 (0.0500)  time: 1.8814  data: 0.2571  max mem: 12492\n",
            "Epoch: [29]  [ 20/109]  eta: 0:02:36  lr: 0.000002  min_lr: 0.000002  loss: 0.7538 (0.7570)  class_acc: 0.8594 (0.8624)  weight_decay: 0.0500 (0.0500)  time: 1.6114  data: 0.0009  max mem: 12492\n",
            "Epoch: [29]  [ 30/109]  eta: 0:02:14  lr: 0.000002  min_lr: 0.000002  loss: 0.7645 (0.7624)  class_acc: 0.8594 (0.8624)  weight_decay: 0.0500 (0.0500)  time: 1.6062  data: 0.0007  max mem: 12492\n",
            "Epoch: [29]  [ 40/109]  eta: 0:01:55  lr: 0.000001  min_lr: 0.000001  loss: 0.7645 (0.7611)  class_acc: 0.8594 (0.8609)  weight_decay: 0.0500 (0.0500)  time: 1.5964  data: 0.0019  max mem: 12492\n",
            "Epoch: [29]  [ 50/109]  eta: 0:01:38  lr: 0.000001  min_lr: 0.000001  loss: 0.7451 (0.7609)  class_acc: 0.8594 (0.8612)  weight_decay: 0.0500 (0.0500)  time: 1.5951  data: 0.0020  max mem: 12492\n",
            "Epoch: [29]  [ 60/109]  eta: 0:01:20  lr: 0.000001  min_lr: 0.000001  loss: 0.7558 (0.7612)  class_acc: 0.8594 (0.8604)  weight_decay: 0.0500 (0.0500)  time: 1.5979  data: 0.0014  max mem: 12492\n",
            "Epoch: [29]  [ 70/109]  eta: 0:01:04  lr: 0.000001  min_lr: 0.000001  loss: 0.7571 (0.7600)  class_acc: 0.8594 (0.8605)  weight_decay: 0.0500 (0.0500)  time: 1.6009  data: 0.0013  max mem: 12492\n",
            "Epoch: [29]  [ 80/109]  eta: 0:00:47  lr: 0.000001  min_lr: 0.000001  loss: 0.7571 (0.7618)  class_acc: 0.8594 (0.8601)  weight_decay: 0.0500 (0.0500)  time: 1.6035  data: 0.0015  max mem: 12492\n",
            "Epoch: [29]  [ 90/109]  eta: 0:00:31  lr: 0.000001  min_lr: 0.000001  loss: 0.7315 (0.7548)  class_acc: 0.8750 (0.8626)  weight_decay: 0.0500 (0.0500)  time: 1.6035  data: 0.0023  max mem: 12492\n",
            "Epoch: [29]  [100/109]  eta: 0:00:14  lr: 0.000001  min_lr: 0.000001  loss: 0.7218 (0.7537)  class_acc: 0.8750 (0.8625)  weight_decay: 0.0500 (0.0500)  time: 1.5992  data: 0.0014  max mem: 12492\n",
            "Epoch: [29]  [108/109]  eta: 0:00:01  lr: 0.000001  min_lr: 0.000001  loss: 0.7301 (0.7537)  class_acc: 0.8750 (0.8615)  weight_decay: 0.0500 (0.0500)  time: 1.5976  data: 0.0004  max mem: 12492\n",
            "Epoch: [29] Total time: 0:02:57 (1.6316 s / it)\n",
            "Averaged stats: lr: 0.000001  min_lr: 0.000001  loss: 0.7301 (0.7537)  class_acc: 0.8750 (0.8615)  weight_decay: 0.0500 (0.0500)\n",
            "Test:  [ 0/21]  eta: 0:01:28  loss: 1.2276 (1.2276)  acc1: 58.3333 (58.3333)  acc5: 97.9167 (97.9167)  time: 4.2248  data: 3.4049  max mem: 12492\n",
            "Test:  [10/21]  eta: 0:00:12  loss: 1.1066 (0.8535)  acc1: 64.5833 (70.2652)  acc5: 97.9167 (98.2955)  time: 1.0949  data: 0.3111  max mem: 12492\n",
            "Test:  [20/21]  eta: 0:00:00  loss: 0.3316 (0.6040)  acc1: 91.6667 (80.7481)  acc5: 98.9583 (98.8030)  time: 0.7740  data: 0.0009  max mem: 12492\n",
            "Test: Total time: 0:00:20 (0.9621 s / it)\n",
            "* Acc@1 80.748 Acc@5 98.803 loss 0.604\n",
            "Accuracy of the model on the 2005 test images: 80.7%\n",
            "Max accuracy: 80.75%\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./model_ckpt)... Done. 13.5s\n",
            "Training time 1:40:09\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc1 ▁▃▃▄▅▅▅▅▅▆▅▆▇▆▆▆▇▇▇▇▇█▇███████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc5 ▁▄▃▆▇▇▇▇▆▇█▇██▇█▇▇▇▇▇▇▆▆▆▆▆▆▆▆\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_loss █▆▆▅▄▄▄▄▄▃▄▃▂▂▃▂▂▁▂▂▁▁▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Global Train/train_class_acc ▁▁▂▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             Global Train/train_loss █▇▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Train/train_lr █████▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Train/train_min_lr █████▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     Global Train/train_weight_decay ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Rank-0 Batch Wise/global_train_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   Rank-0 Batch Wise/train_class_acc ▁▃▂▃▄▄▄▅▄▂▄▄▆▄▅▃▇▅▆▅▅▆▄▆▇▇▇▅▆▇█▇▇▇██▇▇█▆\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Rank-0 Batch Wise/train_loss ██▇▅▆▆█▆▇▅▅▆▅▆▅▆▃▅▄▅▆▅▄▃▃▅▆▂▁▃▄▃▃▂▄▂▂▂▃▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_max_lr ███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_min_lr ███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                               epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc1 80.74813\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc5 98.80299\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_loss 0.60398\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Global Train/train_class_acc 0.86153\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             Global Train/train_loss 0.75372\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Global Train/train_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Global Train/train_min_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     Global Train/train_weight_decay 0.05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Rank-0 Batch Wise/global_train_step 3269\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   Rank-0 Batch Wise/train_class_acc 0.90625\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Rank-0 Batch Wise/train_loss 0.64873\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_max_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_min_lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                               epoch 29\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                        n_parameters 49460071\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdesert-smoke-11\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/1768041412/convnext/runs/eu2zgjhp\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230327_082333-eu2zgjhp/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python main.py --epochs 30 \\\n",
        "                --model convnext_small \\\n",
        "                --data_set image_folder \\\n",
        "                --data_path /content/MedMNIST/dermamnist/train \\\n",
        "                --eval_data_path /content/MedMNIST/dermamnist/test \\\n",
        "                --nb_classes 7 \\\n",
        "                --num_workers 8 \\\n",
        "                --warmup_epochs 0 \\\n",
        "                --save_ckpt true \\\n",
        "                --output_dir model_ckpt \\\n",
        "                --cutmix 0 \\\n",
        "                --mixup 0 --lr 4e-4 \\\n",
        "                --enable_wandb true --wandb_ckpt true \\\n",
        "                --finetune convnext_small_22k_224.pth "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69gk2f00lVg8",
        "outputId": "d4eb9227-9c26-4119-a5db-6c4d1afc634a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#装载Google dirve\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgTYQhM7qiOX",
        "outputId": "59ead05d-edb4-4f5d-87c7-29d810cf7077"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "#保存\n",
        "%cd /content\n",
        "%cp -r MedMNIST drive/MyDrive/MedMNIST\n",
        "%cp -r ConVNeXt drive/MyDrive/ConVNeXt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "350MmZgtBVWy"
      },
      "source": [
        "# 🏐 Conclusion\n",
        "\n",
        "* **The above setting gives a top-1 accuracy of ~95%.**\n",
        "* The ConvNeXt repository comes with modern training regimes and is easy to finetune on any dataset. \n",
        "* The finetune model achieves competitive results. \n",
        "\n",
        "* By passing two arguments you get the following:\n",
        "\n",
        "  * Repository of all your experiments (train and test metrics) as a [W&B Project](https://docs.wandb.ai/ref/app/pages/project-page). You can easily compare experiments to find the best performing model.\n",
        "  * Hyperparameters (Configs) used to train individual models. \n",
        "  * System (CPU/GPU/Disk) metrics.\n",
        "  * Model checkpoints saved as W&B Artifacts. They are versioned and easy to share. \n",
        "\n",
        "  Check out the associated [W&B run page](https://wandb.ai/ayut/convnext/runs/16vi9e31). $→$"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8fd623f5422c456892d3e2e5c8cdffff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6d51f17295f4e54b81a2f8730cebbce",
              "IPY_MODEL_531ae418cce84942b290a584569b5878",
              "IPY_MODEL_cfd80982fb9844e5ab035c5505c04664"
            ],
            "layout": "IPY_MODEL_ce3bd591f14240e4a756f1708aaca9f0"
          }
        },
        "b6d51f17295f4e54b81a2f8730cebbce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85b2fd6ef7dc4bdbb604d62c6b2df211",
            "placeholder": "​",
            "style": "IPY_MODEL_d7c0194462fd459498157e893f811d08",
            "value": ""
          }
        },
        "531ae418cce84942b290a584569b5878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5daa861090304af49cecb7eb6240640b",
            "max": 19725078,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d17399043f524461853b14abc7d110a9",
            "value": 19725078
          }
        },
        "cfd80982fb9844e5ab035c5505c04664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bc3d9f3ba8a40c1b07a5a50fdb20578",
            "placeholder": "​",
            "style": "IPY_MODEL_d5a05c90211d4b1baac6e272d212c41a",
            "value": " 19725312/? [00:59&lt;00:00, 335680.41it/s]"
          }
        },
        "ce3bd591f14240e4a756f1708aaca9f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85b2fd6ef7dc4bdbb604d62c6b2df211": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7c0194462fd459498157e893f811d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5daa861090304af49cecb7eb6240640b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d17399043f524461853b14abc7d110a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9bc3d9f3ba8a40c1b07a5a50fdb20578": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5a05c90211d4b1baac6e272d212c41a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}